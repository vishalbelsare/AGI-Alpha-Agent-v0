[See docs/DISCLAIMER_SNIPPET.md](docs/DISCLAIMER_SNIPPET.md) This repository is a conceptual research prototype.
References to "AGI" and "superintelligence" describe aspirational goals and do not indicate the presence of a real
general intelligence. Use at your own risk. Nothing herein constitutes financial advice. MontrealAI and the maintainers
accept no liability for losses incurred from using this software.

**Ready to explore? [Launch the Î±â€‘AGI Insight demo](https://montrealai.github.io/AGI-Alpha-Agent-v0/alpha_agi_insight_v1/) to see it in action.**

### Quick Demo

Non-technical users can try the project with zero setup. Simply visit
<https://montrealai.github.io/AGI-Alpha-Agent-v0/alpha_agi_insight_v1/> in your
browser. The [README](docs/README.md#Î±â€‘agi-insight-v1-demo) explains how this
demo is built and deployed.

See [Quick Deployment](docs/HOSTING_INSTRUCTIONS.md#quick-deployment) for build and deployment details. The [ğŸ“š Docs workflow](.github/workflows/docs.yml) runs automatically on every push to `main` and publishes the updated site to GitHub Pages.

Full documentation: [https://montrealai.github.io/AGI-Alpha-Agent-v0/](https://montrealai.github.io/AGI-Alpha-Agent-v0/) (use the **Docs** link in the navigation bar)

The GitHub Pages site hosts the interactive demo under the `alpha_agi_insight_v1/` directory. Click **Docs** in the navigation bar for the full manual.

**View the interactive demo here:** <https://montrealai.github.io/AGI-Alpha-Agent-v0/alpha_agi_insight_v1/>

**Browse the visual demo gallery:** <https://montrealai.github.io/AGI-Alpha-Agent-v0/>

**Explore all demos:** <https://montrealai.github.io/AGI-Alpha-Agent-v0/alpha_factory_v1/demos/> â€“ run `./scripts/open_subdir_gallery.py` (or set `AF_GALLERY_URL` to your own mirror) for a local or online launch. Alternatively execute `make subdir-gallery-open` to build the gallery if needed and open it automatically.
All browser demos include a **mode toggle**. Choose **Offline** to run a Pyodide simulation directly in your browser or switch to **OpenAI API** when you provide a key. The key is stored only in memory.

**Important:** Run `npm run fetch-assets` before `npm install` or executing `./setup.sh` to download the browser demo assets. The helper fetches `wasm-gpt2.tar` from the canonical IPFS mirror and uses OpenAI's storage as a mirror when available. Set `WASM_GPT2_URL` to override the list of mirrors, `OPENAI_GPT2_BASE_URL` to change the OpenAI base path, or `OPENAI_GPT2_URL` to specify the full file URL, for example:

```bash
export WASM_GPT2_URL="https://w3s.link/ipfs/bafybeihdwdcefgh4dqkjv67uzcmw7ojee6xedzdetojuzjevtenxquvyku?download=1"
# Official mirror for the small GPTâ€‘2 model (124M parameters)
export OPENAI_GPT2_BASE_URL="https://openaipublic.blob.core.windows.net/gpt-2/models"
export OPENAI_GPT2_URL="https://openaipublic.blob.core.windows.net/gpt-2/models/124M/wasm-gpt2.tar"
```

If `npm run fetch-assets` fails with a 401 or 404 error, download the model
directly using:
```bash
python scripts/download_gpt2_small.py models
# Or download the files individually
curl -O https://openaipublic.blob.core.windows.net/gpt-2/models/124M/encoder.json
curl -O https://openaipublic.blob.core.windows.net/gpt-2/models/124M/hparams.json
curl -O https://openaipublic.blob.core.windows.net/gpt-2/models/124M/vocab.bpe
curl -O https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.index
curl -O https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.data-00000-of-00001
curl -O https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.meta
```
Verify `wasm-gpt2.tar` using checksum `sha384-PLACEHOLDER` before extracting.

See [insight_browser_v1/README.md](alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/README.md) for details. You can also retrieve the model directly with `python scripts/download_wasm_gpt2.py`, `python scripts/download_openai_gpt2.py 124M`, or `python scripts/download_gpt2_small.py`.

[![Launch \u03b1\u2011AGI Insight](https://img.shields.io/badge/Launch-%CE%B1%E2%80%91AGI%20Insight-blue?style=for-the-badge)](https://montrealai.github.io/AGI-Alpha-Agent-v0/alpha_agi_insight_v1/)

### Automatic Deployment

Pushes to `main` trigger the [Docs workflow](.github/workflows/docs.yml), which
runs [`scripts/edge_human_knowledge_pages_sprint.sh`](scripts/edge_human_knowledge_pages_sprint.sh) to rebuild
the Insight demo and MkDocs site. The workflow publishes the result to GitHub
Pages, so once it completes the live demo is available at
<https://montrealai.github.io/AGI-Alpha-Agent-v0/alpha_agi_insight_v1/> with no
extra setup required.

### Publish Demo Gallery

Ensure **PythonÂ 3.11+** and **NodeÂ 20+** are installed, then deploy the gallery
and docs with a single command:

```bash
make gallery-deploy
```
`make gallery-deploy` wraps [`scripts/deploy_gallery_pages.sh`](scripts/deploy_gallery_pages.sh),
which calls [`scripts/generate_gallery_html.py`](scripts/generate_gallery_html.py)
to refresh `docs/index.html` and update the `docs/gallery.html` redirect.

See [docs/GITHUB_PAGES_DEMO_TASKS.md](docs/GITHUB_PAGES_DEMO_TASKS.md) for a
detailed walkthrough. Once the build finishes, open the gallery locally with:

```bash
make gallery-open
```

Run `make gallery-build` to regenerate the site without deploying and open it
in one step.

Open an individual demo directly:

```bash
make demo-open DEMO=alpha_agi_business_v1
```

### Edge-of-Human-Knowledge Sprint

Run the wrapper to build and deploy the full GitHub Pages site with environment
checks and offline validation. Use the shell or Python version:

```bash
./scripts/edge_human_knowledge_pages_sprint.sh
python scripts/edge_human_knowledge_pages_sprint.py
```

Ensure **PythonÂ 3.11+**, **NodeÂ 20+** and `mkdocs` are installed. The
script mirrors the [Docs workflow](.github/workflows/docs.yml) used for automatic
deployment.

## Quickstart

```bash
./quickstart.sh
# or using Docker
docker compose up --build
# or one-click image
./run_quickstart.sh
```

Run `npm run fetch-assets` before `npm install` or executing `./setup.sh` to download the Insight demo assets. The helper retrieves the GPTâ€‘2 model from the official mirror, then tries the OpenAI fallback and finally IPFS. See [insight_browser_v1/README.md](alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/README.md) for a detailed guide. You can alternatively run `python scripts/download_wasm_gpt2.py` or `python scripts/download_openai_gpt2.py 124M` to fetch the model directly.

`fetch_assets.py` honors the `IPFS_GATEWAY` environment variable when downloading assets from IPFS. If the default gateway is unreachable, set it before running the helper:

```bash
IPFS_GATEWAY=https://ipfs.io/ipfs npm run fetch-assets
IPFS_GATEWAY=https://cloudflare-ipfs.com/ipfs npm run fetch-assets
```

Requires **Python 3.11 or 3.12** and **Docker Compose â‰¥2.5**.

Alternatively, run the pre-built image directly:
```bash
docker run --pull=always -p 8000:8000 ghcr.io/montrealai/alpha-factory:latest
```

Set `OPENAI_API_KEY` and other required secrets in your environment or `.env`
before launching the container. The orchestrator prints the
[project disclaimer](docs/DISCLAIMER_SNIPPET.md) when it starts.

**Supported OS:** UbuntuÂ 22.04+, DebianÂ 12+, macOSÂ 12+ and WindowsÂ 11 via
**WSLÂ 2** (recommended for Windows users). Native Windows paths frequently break
volume mounts. Clone this repository inside the WSL file system to avoid these
issues.

```powershell
wsl --install
wsl --set-default-version 2
wsl --update
# enable "Use the WSL 2 based engine" in Docker Desktop
```
Clone the repository inside your WSL home directory to avoid path translation errors.

See [docs/INTRO_BASICS.md](docs/INTRO_BASICS.md) for the bare essentials or
[docs/QUICKSTART_BASICS.md](docs/QUICKSTART_BASICS.md) for a minimal walkthrough.

Watch the run here: [Quickstart video](docs/assets/quickstart_insight.cast) Â·
[Asciinema link](https://asciinema.org/a/I0uXbfl9SLa6SjocAb8Ik8Mni)

See the [documentation](https://montrealai.github.io/AGI-Alpha-Agent-v0/) for detailed steps and an overview of the project.
For a concise high-level picture of how the main pieces fit together, see [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md).


# **META-AGENTIC**Â Î±â€‘AGI ğŸ‘ï¸âœ¨
## **v0.1.0â€‘alpha**
**Official and *pioneering* definition â€“ Meta-Agentic (adj.)**: Describes an agent whose **primary role** is to
**create, select, evaluate, or reâ€‘configure other agents** and the rules governing their interactions, thereby
exercising **secondâ€‘order agency** over a population of firstâ€‘order agents. *The term was **pioneered by
[VincentÂ Boucher](https://www.linkedin.com/in/montrealai/), President of MONTREAL.AI**.*

```mermaid
flowchart TD
    Insight["ğŸ–ï¸ Î±â€‘AGI Insight ğŸ‘ï¸âœ¨"]
    Seeds["ğŸŒ±ğŸ’« Î±-AGI Nova-Seeds ğŸ”"]
    Mark["Î±-AGI MARK ğŸ”®ğŸŒŒâœ¨"]
    Sovereign["ğŸ–ï¸ Î±â€‘AGI Sovereign ğŸ‘‘âœ¨"]
    Biz["ğŸŒ¸ Î±â€‘AGI Business ğŸ‘ï¸âœ¨"]
    Market["ğŸª Marketplace ğŸ‘ï¸âœ¨"]
    Jobs["ğŸ“œ Î±â€‘AGI Jobs ğŸ‘ï¸âœ¨"]
    Agents["ğŸ‘¾ğŸ‘¾ğŸ‘¾ğŸŒŒğŸ‘¾ğŸ‘¾ğŸ‘¾ Î±â€‘AGI Agents ğŸ‘ï¸âœ¨"]
    Reservoir["ğŸ’ Î±â€‘AGI Value Reservoir"]
    Architect["ğŸ–ï¸ Î±â€‘AGI Architect ğŸ”±âœ¨"]
    Council["ğŸ” Î±â€‘AGI Council ğŸ‘ï¸âœ¨"]
    Nodes["ğŸ–¥ï¸ Î±â€‘AGI Nodes ğŸ‘ï¸âœ¨"]

    Insight --> Seeds --> Mark --> Sovereign
    Sovereign --> Biz --> Market
    Market -->|spawn| Jobs --> Agents
    Agents -- success --> Reservoir
    Jobs -- Î”Î£USD --> Reservoir
    Reservoir -. reinvest .-> Seeds
    Reservoir -. fund .-> Market
    Agents <---> Nodes
    Architect <--> Sovereign
    Architect <--> Insight
    Council --> Sovereign
```

---
## Humanityâ€™s Structured Rise to Economic Supremacy via Strategic AGI Mastery

### ğŸ–ï¸ Î±â€‘AGI Insight ğŸ‘ï¸âœ¨ â€” Beyond Human Foresight
Where human foresight reaches its limits, Î±â€‘AGI Insight sees beyond. Humanity stands at the precipice of historyâ€™s most
profound economic transformation. Î±â€‘AGI Insight identifies with pinpoint accuracy those sectors poised for imminent
disruption by Artificial General Intelligence (AGI). With authoritative and rigorously validated projections estimating
economic opportunities surpassing **$15â€¯Quadrillion (15â€¯000â€¯trillionâ€¯USD)**, todayâ€™s strategic anticipation unlocks
extraordinary economic advantages tomorrow.

* **Precision Forecasting** â€” Identify and proactively engage critical sectors before AGI disruption.  
* **Firstâ€‘Mover Advantage** â€” Maximize returns through strategic foresight and superior positioning.
A static demo is available via [GitHub Pages](https://montrealai.github.io/AGI-Alpha-Agent-v0/alpha_agi_insight_v1/).
See [Quick Deployment](docs/HOSTING_INSTRUCTIONS.md#quick-deployment) for guidance on building the docs and publishing your own copy.

### ğŸ–ï¸ Î±â€‘AGI Sovereign ğŸ‘ï¸âœ¨ â€” Autonomous Economic Transformation
Metaâ€‘Agentic mastery at global scale. Î±â€‘AGI Sovereign represents a revolutionary class of autonomous, blockchainâ€‘based
enterprises deploying advanced Metaâ€‘Agentic frameworks. Through dynamically evolving swarms of intelligent agents, these
enterprises systematically identify and transform global inefficiencies into measurable economic value (â€œ$AGIALPHAâ€),
fundamentally reshaping market dynamics and strategically realigning global economic structures.

* **Î±â€‘AGI Marketplace ğŸ‘ï¸âœ¨** â€” Decentralized global platform matching strategic AGI tasks with optimal execution.  
  * **Î±â€‘AGI Jobs ğŸ‘ï¸âœ¨** â€” Autonomous missions precisely targeting identified inefficiencies.  
  * **Î±â€‘AGI Agents ğŸ‘ï¸âœ¨** â€” Adaptive, selfâ€‘optimizing intelligent agents executing Î±â€‘Jobs, yielding immediate economic
    returns.

Strategic Edge:

* Decentralized autonomy ensures superior agility and resilience.
* Strategically validated methodologies guarantee consistent economic leadership.

## Quick Start
**Local:** `./quickstart.sh` &nbsp;&nbsp;|&nbsp;&nbsp; **Docker:** `docker compose up --build`

An interactive Colab notebook demonstrates the same zeroâ€‘data Insight search loop. Open
[colab_alpha_agi_insight_v1.ipynb](alpha_factory_v1/demos/alpha_agi_insight_v1/colab_alpha_agi_insight_v1.ipynb) in
GoogleÂ Colab to try it online.

Clone the repository at the `v0.1.0-alpha` tag and run the helper script to start the Insight demo locally:

```bash
git clone --branch v0.1.0-alpha https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git
cd AGI-Alpha-Agent-v0
python -c "import alpha_factory_v1; print(alpha_factory_v1.__version__)"  # prints 0.1.0-alpha
python check_env.py --auto-install  # may run for several minutes
# NumPy and pandas are required for realistic results; omit or add
# `--allow-basic-fallback` to bypass this check.
# Abort with Ctrl+C and rerun with '--timeout 300' to fail fast
./quickstart.sh
Run `pre-commit run --all-files` after the dependencies finish installing.
```

Offline example using a local wheelhouse:

```bash
WHEELHOUSE=$(pwd)/wheels AUTO_INSTALL_MISSING=1 ./quickstart.sh
```

Or launch the full stack with Docker:

```bash
docker compose up --build
```

### Minimal Install

The default `requirements.txt` pulls in a lean set of packages for the
offline demos and tests:

```bash
pip install -r requirements.txt
```

### Full Feature Install

Install the heavier extras for finance, graph backâ€‘ends and large
language models:

```bash
pip install -r alpha_factory_v1/requirements.txt
# or set ALPHA_FACTORY_FULL=1 when running `check_env.py --auto-install`
```

Detailed stepâ€‘byâ€‘step instructions, including Colab usage,
are available in the [documentation](https://montrealai.github.io/AGI-Alpha-Agent-v0/).

For advanced options, see the [5â€‘Minute Quickâ€‘Start](#6-5-minute-quick-start)
and [Docker Quickstart](#docker-quickstart) sections below.

### Running the Insight Demo

For the browser-based version, see
[insight_browser_v1/README.md](alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/README.md).
It requires **Node.js â‰¥20**. Install the dependencies with
`npm ci` and build the static assets with `npm run build` before launching.
The repository includes a `.nvmrc` file so you can simply run `nvm use` to
select the correct Node version.

The Î±â€‘AGI Insight demo ships with an offlineâ€‘friendly command line interface.
After installation, launch the official demo via:

```bash
alpha-agi-insight-v1 --episodes 5
# Or run directly from the package
python -m alpha_factory_v1.demos.alpha_agi_insight_v1 --episodes 5
```

When API keys are configured the program automatically uses the OpenAI Agents
runtime. Otherwise it falls back to the local Metaâ€‘Agentic Tree Search.
The orchestrator also cleans up the OpenAI runtime on exit to release resources.

For production use, invoke the **official demo** which automatically
checks the environment, selects the best runtime and optionally starts the
Google ADK gateway:

```bash
alpha-agi-insight-v1 --episodes 5
```

This wrapper transparently falls back to the offline Metaâ€‘Agentic Tree
Search when API credentials are absent, ensuring the demo runs anywhere.

For a guaranteed offline run without external dependencies, use:

```bash
AGI_INSIGHT_OFFLINE=1 alpha-agi-insight-v1 --episodes 5
```

Setting ``AGI_INSIGHT_OFFLINE=1`` ensures the search loop never attempts network access.

When the host cannot reach the internet the environment checker prints a warning
and the demos continue in offline mode using any cached data. Optional downloads
are skipped automatically.

Several demos ship with small CSV snapshots for offline mode. These samples
mirror data from the [demo-assets](https://github.com/MontrealAI/demo-assets)
repository and cover roughly Marchâ€“AprilÂ 2024.

### Meta-Agentic Tree Search Demo

An offline-friendly reference implementation focused on recursive agent-to-agent rewrites lives in
[meta_agentic_tree_search_v0/README.md](alpha_factory_v1/demos/meta_agentic_tree_search_v0/README.md).
It demonstrates the bestâ€‘first search behind the other examples and runs without external APIs.

<a name="63-offline-mode"></a>
### Offline Mode

Follow these steps when working without internet access. See the
[documentation](https://montrealai.github.io/AGI-Alpha-Agent-v0/) for a summary
of required environment variables.

1. **Build a wheelhouse** on a machine with connectivity:
   ```bash
   ./scripts/build_offline_wheels.sh
   ```
   The script collects all required wheels under `wheels/`. Copy this
   directory to the offline host, for example using `scp` or a USB drive:
   ```bash
   scp -r wheels user@offline-host:/path/to/AGI-Alpha-Agent-v0/
   ```
   Then set the environment variable on the target machine:
   ```bash
   export WHEELHOUSE="/path/to/AGI-Alpha-Agent-v0/wheels"
   ```

2. **Install from the wheelhouse** and verify packages. The setup script
   automatically uses a `wheels/` directory in the repository root when
   `WHEELHOUSE` is unset:
   ```bash
   AUTO_INSTALL_MISSING=1 ./codex/setup.sh
   python check_env.py --auto-install --wheelhouse "$WHEELHOUSE"
   pip check
   ```
  When network access is unavailable, install packages directly from the
  wheelhouse:
```bash
pip install --no-index --find-links "$WHEELHOUSE" -r requirements.txt
# Install demo extras offline
pip install --no-index --find-links "$WHEELHOUSE" -r \
  alpha_factory_v1/demos/era_of_experience/requirements.lock
```
 `check_env.py` uses the wheels under `$WHEELHOUSE`. Set
`WHEELHOUSE="$WHEELHOUSE"` when running `pre-commit` or the tests so
dependencies install from the local cache. See
[Offline Setup](alpha_factory_v1/scripts/README.md#offline-setup) for more
details. A short reference lives in the
[documentation](https://montrealai.github.io/AGI-Alpha-Agent-v0/). If package installation hangs
for more than ten minutes,
`check_env.py` will time out and suggest using `--wheelhouse` for
offline installs.

Run the environment check again when the machine is completely
airâ€‘gapped:
```bash
python check_env.py --auto-install --wheelhouse "$WHEELHOUSE"
```
This mirrors the instructions in
[alpha_factory_v1/scripts/README.md](alpha_factory_v1/scripts/README.md#offline-setup).

See the [documentation](https://montrealai.github.io/AGI-Alpha-Agent-v0/)
for a concise summary of the wheelhouse setup.

3. **Download a `.gguf` weight** and set ``LLAMA_MODEL_PATH``:
   ```bash
   mkdir -p ~/.cache/llama
   curl -L -o ~/.cache/llama/TinyLlama-1.1B-Chat-v1.0.Q4_K_M.gguf \
     https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-GGUF/resolve/main/TinyLlama-1.1B-Chat-v1.0.Q4_K_M.gguf
   export LLAMA_MODEL_PATH=~/.cache/llama/TinyLlama-1.1B-Chat-v1.0.Q4_K_M.gguf
   ```
   Common weights and typical CPU throughput:

   | Model | Size | ~tokens/s |
   |-------|------|-----------|
   | TinyLlamaâ€‘1.1Bâ€‘Chat Q4_K_M | 380â€¯MB | ~20 |
   | Llamaâ€‘3â€‘8Bâ€‘Instruct Q4_K_M | 4â€¯GB | ~5 |
   | Mixtralâ€‘8Ã—7Bâ€‘Instruct Q4_0 | 7â€¯GB | ~3 |

   Install `llama-cpp-python` or `ctransformers` to enable offline inference.

4. **Fetch and build the browser assets** (requires **Node.js**) to run the Insight demo fully offline:
   ```bash
   cd alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1
   npm run fetch-assets
   npm ci
   npm run build
   ```
   Skipping this step or running without Node.js prevents the service worker
   from being generated, so offline functionality is limited.
5. **Bundle Pyodide for offline demos**
   ```bash
   make gallery-build
   ```
   This command generates the `site/` directory with the Pyodide runtime and demo assets so the browser examples work without a network connection. The service worker caches these files. Use a hard refresh (<kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>R</kbd>) or clear site data to pick up new releases.

6. **Skip browser downloads** when running the web demo tests offline:
   ```bash
   PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD=1 npm test
   ```

7. **Enable offline inference** by setting ``AGI_INSIGHT_OFFLINE=1`` in
   ``.env`` or the environment (ensure `llama-cpp-python` or `ctransformers`
   is installed).

8. **Disable broadcasting** to avoid network calls:
   ```bash
   export AGI_INSIGHT_BROADCAST=0
   ```

9. **Seed the lineage database** from existing DGM logs using ``--import-dgm``.
   ```bash
   python -m alpha_factory_v1.demos.alpha_agi_insight_v1.src.interface.cli \
     simulate --import-dgm path/to/dgm/logs
   ```

   Sample sector definitions live in

   ``alpha_factory_v1/demos/alpha_agi_insight_v1/docs/sectors.sample.json``.
   Pass this file with ``--sectors-file`` to forecast specific industries.

   The built-in **Sector-Shock-10** dataset ships with the package and is
   located using ``importlib.resources`` when running the demo. This allows
   `simulate` to score forecasts even when the repository layout is not
   available.

Example (using ``--sectors-file`` to customise the simulation):

```bash
AGI_INSIGHT_OFFLINE=1 AGI_INSIGHT_BROADCAST=0 \
python -m alpha_factory_v1.demos.alpha_agi_insight_v1.src.interface.cli simulate \
  --curve linear --k 8 --x0 0.0 --llama-model-path "$LLAMA_MODEL_PATH" \
  --offline --energy 2.0 --entropy 0.5 \
  --mut-rate 0.1 --xover-rate 0.5 \
  --sectors-file alpha_factory_v1/demos/alpha_agi_insight_v1/docs/sectors.sample.json
```

Produces output similar to:

```
OPENAI_API_KEY missing â€“ offline mode enabled
year | capability | affected
-----+------------+---------
1    | 0.88       |
2    | 0.98       |
3    | 1.00       |
4    | 1.00       |
5    | 1.00       |
```


### ğŸ–ï¸ Î±â€‘AGI Architect ğŸ‘ï¸âœ¨ â€” Foundational Operational Blueprint
Empowering Metaâ€‘Agentic visionaries with strategic infrastructure. At the core of Î±â€‘AGI Ascension is Î±â€‘AGI Architect â€”
the foundational operational framework for scalable global deployment. Rooted in the groundbreaking â€œMultiâ€‘Agent AI DAOâ€
model, Î±â€‘AGI Architect delivers immediate, scalable, and adaptive infrastructure ensuring continuous strategic
evolution.

* Robust feedback loops driving continuous refinement between Sovereign operations and Architect infrastructure.  
* Engineered for rapid global scalability and strategic responsiveness.

```mermaid
flowchart TD
    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  CORE LAYERS  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    A[ğŸš€ ğŸ–ï¸ Î±-AGI Ascension ğŸŒŒ]
    B[ğŸ–ï¸ Î±-AGI Insight ğŸ‘ï¸âœ¨]
    C[ğŸ–ï¸ Î±-AGI Sovereign ğŸ‘ï¸âœ¨]
    D[ğŸ–ï¸ Î±-AGI Marketplace ğŸ‘ï¸âœ¨]
    E[ğŸ–ï¸ Î±-AGI Jobs ğŸ‘ï¸âœ¨]
    F[ğŸ–ï¸ Î±-AGI Agents ğŸ‘ï¸âœ¨]
    G[ğŸ–ï¸ Î±-AGI Architect ğŸ‘ï¸âœ¨]
    V[ğŸ’ Infinite Value Reservoir]

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  PRIMARY FLOWS  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    A --> B
    B --> C
    C --> D
    D --> E
    D --> F
    C --> G
    G -.â†º Continuous optimisation .-> C

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  WEALTH FEEDBACK LOOPS  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    E -- Harvest Î”Î£USD --> V
    F -- Compound returns --> V
    V -- Reinvest capital --> D

    %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  STYLE  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    classDef asc     fill:#0f172a,color:#ffffff,font-weight:bold,stroke-width:0px
    classDef insight fill:#1e3a8a,color:#ffffff,stroke-width:0px
    classDef market  fill:#0e7490,color:#ffffff,stroke-width:0px
    classDef value   fill:#fde047,color:#000000,font-weight:bold,stroke-width:0px

    class A asc
    class B insight
    class C,G insight
    class D,E,F market
    class V value

    linkStyle default stroke-width:2px
```

---

---

## Deploy Now
Openâ€‘source framework for immediate strategic action: **[github.com/MontrealAI/AGI-Alpha-
Agent-v0](https://github.com/MontrealAI/AGI-Alpha-Agent-v0)**

---

## ğŸ”±âœ¨ Conclusion
**[ ğŸ–ï¸ Î±â€‘AGI Ascension ğŸŒŒ ]** launches humanity into an entirely new economic epoch. By systematically harnessing AGIâ€™s
transformative capabilities, it rewrites global economic structures, implicitly realigning international power dynamics
and propelling humanity toward unprecedented sovereign economic prosperity.

---
---
---

> **MissionÂ ğŸ¯**Â Â Identify ğŸ”Â â†’Â Learn ğŸ“šÂ â†’Â Think ğŸ§ Â â†’Â Design ğŸ¨Â â†’Â StrategiseÂ â™Ÿï¸Â â†’Â Execute âš¡ â€”
> compounding realâ€‘world **Î±** across *all* industries.

Global markets seep *USDâ€¯âœ§â€¯trillions/yr* in latent opportunity â€” â€œalphaâ€ in the broadest sense:  
<kbd>pricing dislocations â€¢ supplyâ€‘chain entropy â€¢ novel drug targets â€¢ policy loopholes â€¢ undiscovered materials</kbd>.

**Alphaâ€‘Factoryâ€¯v1** is an antifragile constellation of selfâ€‘improving Agentic Î±â€‘AGI Agents ğŸ‘ï¸âœ¨ orchestrated to **spot
live alpha across any industry and transmute it into compounding value**.

**Definition**: An **Î±â€‘AGI Business** ğŸ‘ï¸âœ¨ is an onâ€‘chain autonomous enterprise (<name>.a.agi.eth) that unleashes a swarm
of selfâ€‘improving agentic **Î±â€‘AGI agents** ğŸ‘ï¸âœ¨ (<name>.a.agent.agi.eth) to hunt down inefficiencies across any domain
and transmute them into **$AGIALPHA**.

Built atop **OpenAIÂ Agentsâ€¯SDK**, **GoogleÂ ADK**, **A2A protocol**, andÂ Anthropicâ€™s **ModelÂ ContextÂ Protocol**, the
stack runs cloudâ€‘native *or* airâ€‘gapped, hotâ€‘swapping between frontier LLMs and distilled local models.

### TL;DR Quick Start
Check out the `v0.1.0-alpha` tag for a reproducible environment.
```bash
git clone --branch v0.1.0-alpha https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git
cd AGI-Alpha-Agent-v0
python3 -m venv .venv
source .venv/bin/activate
# Install runtime dependencies
# Install runtime dependencies
pip install -r requirements.lock  # pinned versions for deterministic setup
# Optional ADK/MCP integration
pip install google-adk mcp
# Requires Python 3.11â€“3.12 (<3.13)
./quickstart.sh
Run `pre-commit run --all-files` after the dependencies finish installing.
# Open http://localhost:8000/docs in your browser
```
The adapters initialise automatically when these optional packages are present.

### Optional Packages

Install these extras to unlock additional features:

- `pip install gradio` â€“ enables the MuZero planning dashboard.
- `pip install openai-agents==0.0.17` â€“ activates the official Agents runtime used for commentary.
- `pip install google-adk` and set `ALPHA_FACTORY_ENABLE_ADK=true` â€“ starts the Google ADK gateway for
  crossâ€‘organisation agent exchange.
- Install domainâ€‘specific extras as needed (e.g. `httpx`, `feedparser`, `networkx`, `lightgbm`,
  `kafka-python`, `tldextract`). Each agent logs a warning when a library is missing and continues in
  degraded mode.

Offline installations can omit these lines from the relevant `requirements.txt`
files if the Agents SDK or ADK gateway are not needed.

To regenerate `requirements.lock` from `requirements.txt` with hashes, run:

```bash
pip-compile --generate-hashes --output-file requirements.lock requirements.txt
```

Once the API server is running you can launch a simulation:

```bash
curl -X POST http://localhost:8000/simulate \
  -H "Authorization: Bearer $API_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"horizon": 5, "pop_size": 6, "generations": 3, "mut_rate": 0.1, "xover_rate": 0.5, "curve": "linear", "energy": 1.0, "entropy": 1.0}'
```

## Further Reading
- Full documentation is available at [https://montrealai.github.io/AGI-Alpha-Agent-v0/](https://montrealai.github.io/AGI-Alpha-Agent-v0/) â€” click **Docs** in the navigation bar.

---
## Contributing
See [AGENTS.md](AGENTS.md) for the full contributor guide.

### Preâ€‘commit Hooks
After running `./codex/setup.sh`, install the hooks and run a full check:

```bash
pip install pre-commit
pre-commit install
pre-commit run --all-files   # verify hooks after setup
pre-commit run --files <paths>   # before each commit
```
Run `pre-commit run --all-files` once after the setup script to confirm
everything is formatted correctly. These commands mirror the steps in
[AGENTS.md](AGENTS.md) and keep commits consistent.
Before opening a pull request, run `pre-commit run --all-files` to ensure
all hooks succeed.
Run `python check_env.py --auto-install` before invoking these commands so
optional hook dependencies are installed. When working offline, pass
`--wheelhouse <dir>` or set `WHEELHOUSE` to install from a local cache. If
`pre-commit` isn't found, install it with `pip install pre-commit`.

When editing the web UI, preserve existing ARIA labels so the interface
remains accessible.

### Development Setup
Install the Python dependencies with the helper script:

```bash
scripts/setup_env.sh
```
The script checks for Python 3.11â€“3.12 and installs `requirements.txt` and
`requirements-dev.txt`.

When preparing an offline environment, build a wheelhouse on a machine with
internet access:

```bash
./scripts/build_offline_wheels.sh
```

Copy the resulting `wheels/` directory to the target host and set
`WHEELHOUSE=$(pwd)/wheels` before running `check_env.py` or the tests so
packages install from the local cache. The repository does not ship these
prebuilt wheels.

## ğŸ“œÂ TableÂ ofÂ Contents
0. [DesignÂ Philosophy](#0-design-philosophy)  
1. [SystemÂ TopologyÂ ğŸ—ºï¸](#1-system-topology)  
2. [Worldâ€‘ModelÂ &Â PlannerÂ ğŸŒŒ](#2-world-model--planner)  
3. [AgentÂ GalleryÂ ğŸ–¼ï¸Â (12Â agents)](#3-agent-gallery)  
4. [DemoÂ ShowcaseÂ ğŸ¬Â (14Â demos)](#4-demo-showcase)
5. [MemoryÂ &Â KnowledgeÂ FabricÂ ğŸ§ ](#5-memory--knowledge-fabric)
6. [5â€‘Minute Quickâ€‘StartÂ ğŸš€](#6-5-minute-quick-start)
6.1. [Running Tests ğŸ§ª](#61-running-tests)
6.2. [Marketplace Demo Example ğŸ›’](#62-marketplace-demo-example)
6.3. [Offline Mode](#63-offline-mode)
    - Set `LLAMA_MODEL_PATH` to the downloaded `.gguf` weight
    - `AGI_INSIGHT_BROADCAST=0` disables blockchain broadcasting
    - Example:
      ```bash
      AGI_INSIGHT_OFFLINE=1 AGI_INSIGHT_BROADCAST=0
        python -m alpha_factory_v1.demos.alpha_agi_insight_v1.src.interface.cli
        simulate --offline --energy 2.0 --entropy 0.5 \
        --mut-rate 0.1 --xover-rate 0.5 \
        --llama-model-path "$LLAMA_MODEL_PATH"
      ```
7. [DeploymentÂ RecipesÂ ğŸ³](#7-deployment-recipes)
7.1. [Deploying securely ğŸš€](#71-deploying-securely)
8. [Governanceâ€¯&â€¯ComplianceÂ âš–ï¸](#8-governance--compliance)  
9. [ObservabilityÂ ğŸ”­](#9-observability)
10. [SafetyÂ &Â SecurityÂ ğŸ›¡ï¸](#10-safety--security)
11. [ExtendingÂ theÂ MeshÂ ğŸ”Œ](#11-extending-the-mesh)
12. [TroubleshootingÂ ğŸ› ï¸](#12-troubleshooting)
13. [RoadmapÂ ğŸ›£ï¸](#13-roadmap)
14. [CreditsÂ ğŸŒŸ](#14-credits)
15. [LicenseÂ ğŸ“](#15-license)

---

<a name="0-design-philosophy"></a>
## 0Â Â·Â DesignÂ Philosophy

> â€œWe have shifted from *bigâ€‘data hoarding* to **bigâ€‘experience compounding**.â€ â€” *EraÂ ofÂ Experience*.

* **Experienceâ€‘First Loop** â€” Sense â†’ *Imagine* (MuZeroâ€‘style latent planning) â†’ Act â†’ Adapt.  
* **AIâ€‘GA Autogenesis** â€” The factory metaâ€‘evolves new agents and curricula inspired by Cluneâ€™s *AIâ€‘Generating
  Algorithms*.
* **GracefulÂ Degradation** â€” GPUâ€‘less?Â No cloud key?Â Agents fall back to distilled local models & heuristics.  
* **Zeroâ€‘Trust Core** â€” SPIFFE identities, signed artefacts, guardâ€‘rails, exhaustive audit logs.  
* **PolyglotÂ Value** â€” Everything is normalised to a common *alpha Î”âˆ‘USD* lens.

---

<a name="1-system-topology"></a>
## 1Â Â·Â SystemÂ TopologyÂ ğŸ—ºï¸
```mermaid
flowchart LR
  ORC([ğŸ› ï¸ Orchestrator])
  WM[(ğŸŒŒ Worldâ€‘Model)]
  MEM[(ğŸ”— Vectorâ€‘Graph Memory)]
  subgraph Agents
    FIN(ğŸ’°)
    BIO(ğŸ§¬)
    MFG(âš™ï¸)
    POL(ğŸ“œ)
    ENE(ğŸ”‹)
    SUP(ğŸ“¦)
    RET(ğŸ›ï¸)
    CYB(ğŸ›¡ï¸)
    CLM(ğŸŒ)
    DRG(ğŸ’Š)
    SCT(â›“ï¸)
    TAL(ğŸ§‘â€ğŸ’»)
  end
  ORC -- A2A --> Agents
  Agents -- experience --> WM
  WM -- embeddings --> MEM
  ORC -- Kafka --> DL[(ğŸ—„ï¸ DataÂ Lake)]
```

* **Orchestrator** autoâ€‘discovers agents (see `backend/agents/__init__.py`) and exposes a unified RESTÂ +Â gRPC facade.  
* **Worldâ€‘Model** uses MuZeroâ€‘style latent dynamics for counterfactual planning.  
* **Memory Fabric** = pgvector + Neo4j for dense & causal recall.

---

<a name="2-world-model--planner"></a>
## 2Â Â·Â Worldâ€‘ModelÂ &Â PlannerÂ ğŸŒŒ

| Component | Source Tech | Role |
|-----------|-------------|------|
| **LatentÂ Dynamics** | MuZero++ | Predict env transitions & value |
| **Selfâ€‘Play Curriculum** | POETâ€‘XL | Generates alphaâ€‘labyrinth tasks |
| **Metaâ€‘Gradient** | AIâ€‘GA | Evolves optimiser hyperâ€‘nets |
| **TaskÂ Selector** | Multiâ€‘ArmedÂ Bandit | Schedules agent â†”Â worldâ€‘model interactions |

---

<a name="3-agent-gallery"></a>
## 3Â Â·Â AgentÂ GalleryÂ ğŸ–¼ï¸

```mermaid
flowchart TD
    ORC["ğŸ› ï¸Â Orchestrator"]
    GEN{{"ğŸ§ªÂ Envâ€‘Generator"}}
    LRN["ğŸ§ Â MuZero++"]

    subgraph Agents
        FIN["ğŸ’°"]
        BIO["ğŸ§¬"]
        MFG["âš™ï¸"]
        POL["ğŸ“œ"]
        ENE["ğŸ”‹"]
        SUP["ğŸ“¦"]
        RET["ğŸ›ï¸"]
        MKT["ğŸ“ˆ"]
        CYB["ğŸ›¡ï¸"]
        CLM["ğŸŒ"]
        DRG["ğŸ’Š"]
        SMT["â›“ï¸"]
    end

    %% message flows
    GEN -- tasks --> LRN
    LRN -- policies --> Agents
    Agents -- skills --> LRN

    ORC -- A2A --> FIN
    ORC -- A2A --> BIO
    ORC -- A2A --> MFG
    ORC -- A2A --> POL
    ORC -- A2A --> ENE
    ORC -- A2A --> SUP
    ORC -- A2A --> RET
    ORC -- A2A --> MKT
    ORC -- A2A --> CYB
    ORC -- A2A --> CLM
    ORC -- A2A --> DRG
    ORC -- A2A --> SMT
    ORC -- A2A --> GEN
    ORC -- A2A --> LRN

    ORC -- Kafka --> DATALAKE["ğŸ—„ï¸Â DataÂ Lake"]
    FIN -.->|Prometheus| GRAFANA{{"ğŸ“Š"}}
```

| # | Agent | Path | PrimeÂ Directive | Status | KeyÂ EnvÂ Vars |
|---|-------|------|-----------------|--------|--------------|
| 1 | **Finance** ğŸ’° | `finance_agent.py` | Multiâ€‘factor alpha & RL execution | **Prod** | `BROKER_DSN` |
| 2 | **Biotech** ğŸ§¬ | `biotech_agent.py` | CRISPR & assay proposals | **Prod** | `OPENAI_API_KEY` |
| 3 | **Manufacturing** âš™ï¸ | `manufacturing_agent.py` | CPâ€‘SAT optimiser | **Prod** | `SCHED_HORIZON` |
| 4 | **Policy** ğŸ“œ | `policy_agent.py` | Statute QA & diffs | **Prod** | `STATUTE_CORPUS_DIR` |
| 5 | **Energy** ğŸ”‹ | `energy_agent.py` | Spotâ€‘vsâ€‘forward arbitrage | **Beta** | `ISO_TOKEN` |
| 6 | **Supplyâ€‘Chain** ğŸ“¦ | `supply_chain_agent.py` | Stochastic MILP routing | **Beta** | `SC_DB_DSN` |
| 7 | **RetailÂ Demand** ğŸ›ï¸ | `retail_demand_agent.py` | SKU forecast & pricing | **Beta** | `POS_DB_DSN` |
| 8 | **Cyberâ€‘Sec** ğŸ›¡ï¸ | `cyber_threat_agent.py` | Predict & patch CVEs | **Beta** | `VT_API_KEY` |
| 9 | **ClimateÂ Risk** ğŸŒ | `climate_risk_agent.py` | ESG stress tests | **Beta** | `NOAA_TOKEN` |
|10 | **Drugâ€‘Design** ğŸ’Š | `drug_design_agent.py` | Diffusion + docking | **Incub** | `CHEMBL_KEY` |
|11 | **Smartâ€‘Contract** â›“ï¸ | `smart_contract_agent.py` | Formal verification | **Incub** | `ETH_RPC_URL` |
|12 | **Talentâ€‘Match** ğŸ§‘â€ğŸ’» | `talent_match_agent.py` | Autoâ€‘bounty hiring | **Incub** | â€” |

```mermaid
%% Legend
%%  solid arrows  = primary valueâ€‘flow
%%  dashed arrows = secondary / supporting influence
%%  node emojis   = domain archetypes

graph TD
    %% Core pillars
    FIN["ğŸ’° Finance"]
    BIO["ğŸ§¬ Biotech"]
    MFG["âš™ï¸ Manufacturing"]
    POL["ğŸ“œ PolicyÂ /Â Regâ€‘Tech"]
    ENE["ğŸ”‹ Energy"]
    SUP["ğŸ“¦ Supplyâ€‘Chain"]
    RET["ğŸ›ï¸ RetailÂ /Â Demand"]
    CYB["ğŸ›¡ï¸ Cyberâ€‘Security"]
    CLM["ğŸŒ Climate"]
    DRG["ğŸ’Š DrugÂ Design"]
    SMT["â›“ï¸ SmartÂ Contracts"]
    TLT["ğŸ§‘â€ğŸ’¼ Talent"]

    %% Derived transversal competences
    QNT["ğŸ“Š QuantÂ R&D"]
    RES["ğŸ”¬ ResearchÂ Ops"]
    DSG["ğŸ¨ Design"]
    OPS["ğŸ”§ DevOps"]

    %% Primary valueâ€‘creation arcs
    FIN -->|PriceÂ discovery| QNT
    FIN -->|RiskÂ stressâ€‘test| CLM
    BIO --> DRG
    BIO --> RES
    MFG --> SUP
    ENE --> CLM
    RET --> FIN
    POL --> CYB
    SMT --> FIN

    %% Crossâ€‘pollination (secondary, dashed)
    FIN -.-> POL
    SUP -.-> CLM
    CYB -.-> OPS
    DRG -.-> POL
    QNT -.-> RES
    RET -.-> DSG

    %% Visual grouping
    subgraph Core
        FIN
        BIO
        MFG
        POL
        ENE
        SUP
        RET
        CYB
        CLM
        DRG
        SMT
        TLT
    end
    classDef core fill:#0d9488,color:#ffffff,stroke-width:0px;
```

Each agent exports a signed *proofâ€‘ofâ€‘alpha* message to the Kafka bus, enabling crossâ€‘breeding of opportunities.

```mermaid
sequenceDiagram
    participant User
    participant ORC as Orchestrator
    participant FIN as ğŸ’°
    participant GEN as ğŸ§ª
    User->>ORC: /alpha/run
    ORC->>GEN: new_world()
    GEN-->>ORC: env_json
    ORC->>FIN: act(env)
    FIN-->>ORC: proof(Î”G)
    ORC-->>User: artefact + KPI
```

---

<a name="4-demo-showcase"></a>
## 4Â Â·Â DemoÂ ShowcaseÂ ğŸ¬

| # | Folder | Emoji | LightningÂ Pitch | Alpha Contribution | StartÂ Locally |
|---|--------|-------|-----------------|--------------------|---------------|
|1|`aiga_meta_evolution`|ğŸ§¬|Agents *evolve* new agents; genetic tests autoâ€‘score fitness.|Expands strategy space, surfacing fringe alpha.|`cd alpha_factory_v1/demos/aiga_meta_evolution && ./run_aiga_demo.sh`|
|2|`alpha_agi_business_v1`|ğŸ¦|Autoâ€‘incorporates a digitalâ€‘first company endâ€‘toâ€‘end.|Shows AGI turning ideas â†’ registered business.|`./alpha_factory_v1/demos/alpha_agi_business_v1/run_business_v1_demo.sh [--pull] [--gpu]` (docs: `http://localhost:8000/docs`)|
|3|`alpha_agi_business_2_v1`|ğŸ—|Iterates business model with live market data RAG.|Continuous adaptation â†’ durable competitive alpha.|`./alpha_factory_v1/demos/alpha_agi_business_2_v1/run_business_2_demo.sh`|
|4|`alpha_agi_business_3_v1`|ğŸ“Š|Financial forecasting & fundraising agent swarm.|Optimises capital stack for ROI alpha.|`./alpha_factory_v1/demos/alpha_agi_business_3_v1/run_business_3_demo.sh`|
|5|`alpha_agi_marketplace_v1`|ğŸ›’|Peerâ€‘toâ€‘peer agent marketplace simulating price discovery.|Validates microâ€‘alpha extraction via agent barter.|`docker compose -f demos/docker-compose.marketplace.yml up`|
|6|`alpha_asi_world_model`|ğŸŒŒ|Scales MuZeroâ€‘style worldâ€‘model to an openâ€‘ended gridâ€‘world.|Stressâ€‘tests anticipatory planning for ASI scenarios.|`docker compose -f demos/docker-compose.asi_world.yml up`|
|7|`cross_industry_alpha_factory`|ğŸŒ|Full pipeline: ingest â†’ plan â†’ act across 4 verticals.|Proof that one orchestrator handles multiâ€‘domain alpha.|`./alpha_factory_v1/demos/cross_industry_alpha_factory/deploy_alpha_factory_cross_industry_demo.sh`|
|8|`era_of_experience`|ğŸ›|Lifelong RL stack blending real & synthetic experience streams.|Showcases sensor-motor tools, grounded rewards & non-human reasoning.|`cd alpha_factory_v1/demos/era_of_experience && ./run_experience_demo.sh`|
|9|`finance_alpha`|ğŸ’¹|Live momentumÂ + riskâ€‘parity bot on Binance testâ€‘net.|Generates real P&L; stressâ€‘tested against CVaR.|`./alpha_factory_v1/demos/finance_alpha/deploy_alpha_factory_demo.sh`|
|10|`macro_sentinel`|ğŸŒ|GPTâ€‘RAG news scanner autoâ€‘hedges with CTA futures.|Shields portfolios from macro shocks.|`docker compose -f demos/docker-compose.macro.yml up`|
|11|`muzero_planning`|â™Ÿ|MuZero in 60â€¯s; online worldâ€‘model with MCTS.|Distills planning research into a oneâ€‘command demo.|`./alpha_factory_v1/demos/muzero_planning/run_muzero_demo.sh`|
|12|`self_healing_repo`|ğŸ©¹|CI fails â†’ agent crafts patch â‡’ PRÂ green again.|Maintains pipeline uptime alpha.|`docker compose -f demos/docker-compose.selfheal.yml up`|
|13|`meta_agentic_tree_search_v0`|ğŸŒ³|Recursive agent rewrites via bestâ€‘first search.|Rapidly surfaces AGI-driven trading alpha.|`mats-bridge --episodes 3`|
|14|`alpha_agi_insight_v1`|ğŸ‘ï¸|Zeroâ€‘data search ranking AGIâ€‘disrupted sectors.|Forecasts sectors primed for AGI transformation.|`alpha-agi-insight-v1 --episodes 5`|

> **Colab?** Each folder ships an `*.ipynb` that mirrors the Docker flow with free GPUs.

The official Docker image bundles **PyTorch&nbsp;2.2.x** and **Ray&nbsp;2.10.0**. The
notebooks install PyTorch from the [PyTorch wheel index](https://download.pytorch.org/whl)
and pin Ray to the same version for compatibility.

* [SolvingÂ AGIÂ Governance](alpha_factory_v1/demos/solving_agi_governance/README.md) â€” Monteâ€‘Carlo governance simulation
  with optional OpenAIâ€‘Agents/ADK integration.
  [Colab](alpha_factory_v1/demos/solving_agi_governance/colab_solving_agi_governance.ipynb)
* [Selfâ€‘Healing Repo](alpha_factory_v1/demos/self_healing_repo/README.md) â€” agents automatically craft patches when CI
  fails.
  The underlying `MetaRefinementAgent` **only simulates** improvement by
  generating placeholder diffs. We hope to replace this with genuine
  optimisation based on real performance metricsâ€”contributions are
  warmly welcomed.
* **Note:** The `alpha_agi_business_3_v1` demo is intentionally left out of the published package. Clone this repository
  to run it from source.

| `USE_GPU` | PyTorch wheel URL |
|:--------:|-------------------------------------------------|
| `True`   | <https://download.pytorch.org/whl/cu118> |
| `False`  | <https://download.pytorch.org/whl/cpu> |

### 4.1Â Â·Â [Î±-ASI World-Model Demo ğŸ‘ï¸âœ¨](
https://github.com/MontrealAI/AGI-Alpha-Agent-v0/tree/main/alpha_factory_v1/demos/alpha_asi_world_model)

Paper: [Multi-Agent AGENTIC Î±-AGI World-Model Demo ğŸ¥‘](https://github.com/MontrealAI/AGI-Alpha-
Agent-v0/blob/main/alpha_factory_v1/demos/alpha_asi_world_model/Alpha_ASI_World_Model.pdf)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Alpha-Factory Bus (A2A) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   curriculum   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   telemetry   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚ StrategyAgentâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Orchestr. â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   UI / WS  â”‚          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚  (loop)   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Interface â”‚          â”‚
â”‚          â–²  â–²                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    commands   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚          â”‚  â”‚ new_env/reward                     â–²                                   â”‚
â”‚   plans  â”‚  â”‚ loss stats                        â”‚ halt                              â”‚
â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”   context       â”‚            â”‚                                   â”‚
â”‚   â”‚ ResearchAgentâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Learner (MuZero) â—„â”€ SafetyAgent (loss guard)      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚   â–²                                             â”‚
â”‚              code patches         â”‚   â”‚                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚   â”‚ gradients                                   â”‚
â”‚   â”‚ CodeGenAgent â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚                                             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚                                             â”‚
â”‚                                       â–¼                                             â”‚
â”‚                            POET Generator â†’ MiniWorlds (env pool)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2Â Â·Â [ğŸ›ï¸Â Largeâ€‘ScaleÂ Î±â€‘AGIâ€¯Businessâ€¯3Â Demo ğŸ‘ï¸âœ¨Â â€” **Omegaâ€‘Grade Edition**](
https://github.com/MontrealAI/AGI-Alpha-Agent-v0/tree/main/alpha_factory_v1/demos/alpha_agi_business_3_v1)

> **Alphaâ€‘FactoryÂ v1Â â†’Â Î©â€‘LatticeÂ v0**  
> _Transmuting cosmological freeâ€‘energy gradients into compounding cashâ€‘flows._

Multiâ€‘Scale Energyâ€‘Landscape Diagram:

```mermaid
flowchart TB
  subgraph Macro["Macroâ€‘Finance Î”Î²"]
    FIN[FinanceAgent]:::agent
    ENE[EnergyAgent]:::agent
  end
  subgraph Meso["Supplyâ€‘Chain Î”S"]
    MFG[ManufacturingAgent]:::agent
    LOG[LogisticsAgent]:::agent
  end
  subgraph Micro["Bio/Chem Î”H"]
    BIO[BiotechAgent]:::agent
    MAT[MaterialsAgent]:::agent
  end
  FIN & ENE -->|Î² feed| ORC
  MFG & LOG -->|entropy Î”S| ORC
  BIO & MAT -->|latent Î”H| ORC
  classDef agent fill:#cffafe,stroke:#0369a1;
```

Cells with \(Î”\mathcal F < 0\) glow ğŸ”µ on Grafana; Î©â€‘Agents race to harvest.

---

<a name="5-memory--knowledge-fabric"></a>
## 5Â Â·Â MemoryÂ &Â KnowledgeÂ FabricÂ ğŸ§ 

```
[Event] --embedding--> PGVector DB
                   \--edge--> Neo4j (CAUSES, SUPPORTS, RISK_OF)
```

* Agents query `mem.search("supply shock beta>0.2")`  
* Planner asks Neo4j: `MATCH (a)-[:CAUSES]->(b) WHERE b.delta_alpha > 5e6 RETURN path`
* SQLite vector store fallback requires `numpy`
* Realistic operation also relies on `pandas`

---

<a name="6-5-minute-quick-start"></a>
## 6Â Â·Â 5â€‘Minute Quickâ€‘StartÂ ğŸš€
This guide assumes the repository is cloned at `v0.1.0-alpha`. The walkthrough
requires the `numpy`, `yaml` and `pandas` packages which `check_env.py` installs
automatically when run with `--auto-install`.
```bash
git clone --branch v0.1.0-alpha https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git
cd AGI-Alpha-Agent-v0
./quickstart.sh --preflight   # optional environment check
python check_env.py --auto-install  # verify & auto-install deps (10 min timeout)
# Install runtime dependencies
pip install -r requirements.lock
# (If this fails with a network error, create a wheelhouse and rerun
#  with --wheelhouse <path> or place the wheels under ./wheels)
# Build a wheelhouse if the machine has no internet access:
#   ./scripts/build_offline_wheels.sh
./quickstart.sh               # creates venv, installs deps, launches
# Use `--wheelhouse /path/to/wheels` to install offline packages when
# the host has no internet access. The setup script automatically
# sets `WHEELHOUSE` to `./wheels` when that directory exists. When
# working offline, run `python check_env.py --auto-install --wheelhouse
# /path/to/wheels` to verify and install packages. The setup script
# exits with a message if neither network nor a wheelhouse are available.
# Example offline workflow:
#   export WHEELHOUSE=$(pwd)/wheels
#   python check_env.py --auto-install --wheelhouse "$WHEELHOUSE"
#   WHEELHOUSE=$WHEELHOUSE ./quickstart.sh
#   WHEELHOUSE=$WHEELHOUSE pytest -q
# Open http://localhost:8000/docs in your browser
# Alternatively, ``python alpha_factory_v1/quickstart.py`` provides the same
# workflow on Windows and other systems without Bash.

# Deploy instantly with Docker (prebuilt image)
docker run --pull=always -p 8000:8000 ghcr.io/montrealai/alpha-factory:latest

# The `alpha-factory` CLI also works when the package is installed:
# A short warning is printed before startup.
#   pip install -e .
#   alpha-factory --list-agents
#   alpha-asi-demo --demo   # launch the Î±â€‘ASI worldâ€‘model UI
#   alpha-agi-insight-v1 orchestrator   # run the Insight orchestrator
#
# Or install directly from GitHub for a quick test:
#   pip install git+https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git@v0.1.0-alpha
#   alpha-factory --list-agents

# Automated one-click setup (builds & starts Docker stack)
./alpha_factory_v1/scripts/one_click_install.sh --deploy

# Verify the Î©â€‘Lattice demo locally
python alpha_factory_v1/demos/alpha_agi_business_3_v1/alpha_agi_business_3_v1.py --loglevel info
# The entrypoint automatically verifies dependencies via `check_env.py`.
```

Adjust `alpha_factory_v1/demos/alpha_asi_world_model/config.yaml` to tune the world-model loop. Key options include
`env_batch` (parallel environments), `hidden` (latent state size) and `mcts_simulations` (MCTS rollouts per action).


### Insight Browser Demo

A browser-only Pareto explorer lives under
`alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1`.
Run `npm run build` in that directory to generate the `dist/` assets
(they are not stored in Git) then open `dist/index.html` to run the demo locally.
The quick-start guide is available from the
[documentation](https://montrealai.github.io/AGI-Alpha-Agent-v0/) and is copied
to `dist/insight_browser_quickstart.pdf` during the build so it is available
alongside the compiled assets.
Set `window.DEBUG = true` before loading the page to expose debugging helpers
such as `window.pop`.

For evolutionary experiments you can run the optional
[evolution worker](https://montrealai.github.io/AGI-Alpha-Agent-v0/) container
and POST a tarball of agent code to `/mutate`.

## Docker Quickstart
Start the full stack using Docker Compose:
```bash
docker compose up --build
```
Browse the dashboard at <http://localhost:8080>.

## One-Click Docker Quickstart
Run the minimal image directly:
```bash
./run_quickstart.sh
```
The script prints the project disclaimer, builds `docker/quickstart/Dockerfile`
and launches the container with your `.env` file mounted.

The same configuration can be installed via Helm:
```bash
helm upgrade --install alpha-demo ./infrastructure/helm-chart \
  --values ./infrastructure/helm-chart/values.yaml \
  --set env.RUN_MODE=web
```
This deploys the services to your local Kubernetes cluster.

Generate TLS certificates for the gRPC bus using the bundled helper:
```bash
./infrastructure/gen_bus_certs.sh > .env.bus
source .env.bus
```
The script prints `AGI_INSIGHT_BUS_CERT`, `AGI_INSIGHT_BUS_KEY` and
`AGI_INSIGHT_BUS_TOKEN` which you can append to your `.env` file.

### .env Setup & Security
Before running the orchestrator, copy `alpha_factory_v1/.env.sample` to `.env` and
replace all placeholder values with strong secrets. The sample sets
`NEO4J_PASSWORD=REPLACE_ME` as a placeholderâ€”generate a random password for
services like Neo4j and Postgres using `openssl rand -base64 18` or a similar
tool and **never deploy with the defaults**. The orchestrator will refuse to
start if `NEO4J_PASSWORD` remains `REPLACE_ME` or is missing.
Set `API_TOKEN` to a strong secret so that the REST API can authenticate
incoming requests. Clients must send `Authorization: Bearer <token>`.
The server aborts if `API_TOKEN` equals `REPLACE_ME_TOKEN`.
Use `API_RATE_LIMIT` to limit requests per minute per IP (default `60`).
If more than 5% of requests return HTTP `429` within a minute, the server calls
`utils.alerts.send_alert` to report excessive throttling.
Avoid storing private keys directly in `.env`. Instead set
`AGI_INSIGHT_SOLANA_WALLET_FILE` to a file containing your hex-encoded wallet
key and keep that file readable only by the orchestrator.
To enable secure gRPC transport set `AGI_INSIGHT_BUS_CERT`,
`AGI_INSIGHT_BUS_KEY` and `AGI_INSIGHT_BUS_TOKEN`. If these values are
omitted and `AGI_INSIGHT_ALLOW_INSECURE=1`, the bus starts without TLS.
See the [documentation](https://montrealai.github.io/AGI-Alpha-Agent-v0/)
for instructions and example volume mounts.

`.env.sample` notes that paths on Windows may require quotes (e.g., `C:\\path\\to\\file`).

#### Supported Environment Variables

| Variable | Default | Purpose |
|----------|---------|---------|
| `OPENAI_API_KEY` | _(empty)_ | API key for hosted models. Offline mode is used when empty. |
| `OPENAI_TIMEOUT_SEC` | `30` | Timeout for OpenAI API requests in seconds. |
| `NO_LLM` | `0` | Set to `1` to skip the LLM planner even when `OPENAI_API_KEY` is provided. |
| `ALPHA_ASI_LLM_MODEL` | `gpt-4o-mini` | Planner model name used by the world model demo. |
| `ALPHA_ASI_SEED` | `42` | Deterministic RNG seed for the demo (can also be set via `general.seed` in `config.yaml`). |
| `ALPHA_ASI_MAX_STEPS` | `100000` | Learner steps before auto-stop. |
| `ALPHA_ASI_BUFFER_LIMIT` | `50000` | Replay-buffer length. |
| `ALPHA_ASI_TRAIN_BATCH` | `128` | SGD mini-batch size. |
| `ALPHA_ASI_MAX_GRID` | `64` | Safety clamp on generated mazes. |
| `ALPHA_ASI_HOST` | `0.0.0.0` | FastAPI bind address for the demo. |
| `ALPHA_ASI_PORT` | `7860` | FastAPI port for the demo. |
| `NEO4J_PASSWORD` | `REPLACE_ME` | Database password required by the orchestrator. |
| `RUN_MODE` | `api` | Launch mode for Compose or Helm (`api`, `cli`, `web`). |
| `PORT` | `8000` | REST API port. |
| `AGI_INSIGHT_OFFLINE` | `0` | Set to `1` to force local inference models. |
| `AGI_INSIGHT_BUS_PORT` | `6006` | gRPC bus port used by the demo. |
| `AGI_INSIGHT_LEDGER_PATH` | `./ledger/audit.db` | Path to the local audit ledger. |
| `AGI_INSIGHT_SECRET_BACKEND` | _(empty)_ | Set to `vault`, `aws` or `gcp` to load secrets from an external manager. |
| `VAULT_ADDR`/`VAULT_TOKEN` | _(empty)_ | Connection details for HashiCorp Vault when using the `vault` backend. |
| `AWS_REGION`/`OPENAI_API_KEY_SECRET_ID` | _(empty)_ | AWS Secrets Manager region and secret ID when using the `aws` backend. |
| `GCP_PROJECT_ID`/`OPENAI_API_KEY_SECRET_ID` | _(empty)_ | GCP project and secret name when using the `gcp` backend. |
| `AGI_INSIGHT_BUS_CERT` | _(empty)_ | Path to the gRPC bus certificate. |
| `AGI_INSIGHT_BUS_KEY` | _(empty)_ | Private key matching `AGI_INSIGHT_BUS_CERT`. |
| `AGI_INSIGHT_BUS_TOKEN` | _(empty)_ | Shared secret for bus authentication. |
| `AGI_INSIGHT_ALLOW_INSECURE` | `0` | Set to `1` to run the bus without TLS when no certificate is provided. |
| `API_TOKEN` | `REPLACE_ME_TOKEN` | Bearer token required by the REST API. Startup fails if unchanged. |
| `API_CORS_ORIGINS` | `*` | Comma-separated list of allowed CORS origins. |
| `SANDBOX_CPU_SEC` | `2` | CPU time limit for sandboxed code. |
| `SANDBOX_MEM_MB` | `256` | Memory cap for sandboxed code in MB. |
| `MAX_RESULTS` | `100` | Maximum stored simulation results. |
| `MAX_SIM_TASKS` | `4` | Maximum concurrent simulation tasks. |
| `IPFS_GATEWAY` | `https://ipfs.io/ipfs` | Base URL for IPFS downloads used by `npm run fetch-assets`. Override with `IPFS_GATEWAY=<url> npm run fetch-assets`. |
| `OPENAI_GPT2_BASE_URL` | `https://openaipublic.blob.core.windows.net/gpt-2/models` | Base URL for the GPTâ€‘2 checkpoints. |
| `OPENAI_GPT2_URL` | `https://openaipublic.blob.core.windows.net/gpt-2/models/124M/wasm-gpt2.tar` | Full URL for the wasmâ€‘gpt2 archive. |
| `OTEL_ENDPOINT` | _(empty)_ | OTLP endpoint for anonymous telemetry. |
| `ALPHA_FACTORY_ENABLE_ADK` | `false` | Set to `true` to start the Google ADK gateway. |
| `ALPHA_FACTORY_ADK_PORT` | `9000` | Port for the ADK gateway when enabled. |
| `ALPHA_FACTORY_ADK_TOKEN` | _(empty)_ | Optional auth token for the ADK gateway. |

#### IPFS Gateway

`scripts/fetch_assets.py` uses the `IPFS_GATEWAY` variable to construct URLs when downloading
files from IPFS. The default is `https://ipfs.io/ipfs`, but any reachable mirror will work.
Set `IPFS_GATEWAY` before running the helper to switch gateways.

The values above mirror `.env.sample`. When running the stack with Docker
Compose, adjust the environment section of
`infrastructure/docker-compose.yml` to override any variableâ€”such as the gRPC
bus port or ledger path. Sandbox limits are described in the
[documentation](https://montrealai.github.io/AGI-Alpha-Agent-v0/).
When the `firejail` binary is present, CodeGen snippets run inside `firejail --net=none --private` for stronger
isolation.
If asset downloads fail during `npm run fetch-assets`, specify an alternate gateway:
`IPFS_GATEWAY=https://ipfs.io/ipfs npm run fetch-assets`
`IPFS_GATEWAY=https://cloudflare-ipfs.com/ipfs npm run fetch-assets`
Use whichever mirror is fastest in your region.

#### Troubleshooting Asset Downloads

If `scripts/fetch_assets.py` or `npm run fetch-assets` returns `401` or `404`,
download the checkpoint directly:

```bash
python scripts/download_gpt2_small.py models
# Or fetch manually from OpenAI's mirror
curl -O https://openaipublic.blob.core.windows.net/gpt-2/models/124M/encoder.json
curl -O https://openaipublic.blob.core.windows.net/gpt-2/models/124M/hparams.json
curl -O https://openaipublic.blob.core.windows.net/gpt-2/models/124M/vocab.bpe
curl -O https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.index
curl -O https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.data-00000-of-00001
curl -O https://openaipublic.blob.core.windows.net/gpt-2/models/124M/model.ckpt.meta
```

For a production-ready ADK setup see
[PRODUCTION_GUIDE.md](alpha_factory_v1/demos/alpha_agi_business_v1/PRODUCTION_GUIDE.md).

### Finance Demo Quickâ€‘Start

Launch the finance alpha demo directly from your terminal:

```bash
curl -L https://raw.githubusercontent.com/MontrealAI/AGI-Alpha-Agent-v0/main/alpha_factory_v1/demos/finance_alpha/deploy_alpha_factory_demo.sh | bash
```

The script pulls the signed demo container, runs a BTC/GLD strategy, prints open
positions and P&L, and exposes the traceâ€‘graph UI at
<http://localhost:${TRACE_WS_PORT}>.

Need a different pair or port? Use environment variables:
`STRATEGY=my_pair PORT_API=8001 TRACE_WS_PORT=9000 bash deploy_alpha_factory_demo.sh`

No GPU â†’ falls back to GGML Llamaâ€‘3â€‘8Bâ€‘Q4.
No `OPENAI_API_KEY` â†’ switches to local SBERT + heuristics.
`AF_LLM_CACHE_SIZE` caps in-memory LLM cache entries (default 1024).
`AF_PING_INTERVAL` sets the ping frequency in seconds (default 60, minimum 5).
`AF_DISABLE_PING_AGENT=true` disables the builtâ€‘in ping agent.

---

<a name="61-running-tests"></a>
### 6.1Â Â·Â Running TestsÂ ğŸ§ª

Unit tests can be executed with the bundled helper script:

```bash
python -m alpha_factory_v1.scripts.run_tests
```

The helper validates the target directory, prefers `pytest` when
available and otherwise falls back to `unittest`. Ensure all tests pass
before deploying changes.

Install the optional test dependencies with:

```bash
pip install -r requirements-dev.txt
pip install -r requirements-demo.txt  # adds numpy, torch and extras
```

Install the project in editable mode so tests resolve imports:
```bash
pip install -e .
python check_env.py --auto-install  # times out after 10 minutes
```
The `run_tests` helper automatically executes `python check_env.py --auto-install`
before running `pytest`. When offline, set `WHEELHOUSE` or pass
`--wheelhouse <dir>` so packages install from the local wheel cache. The
repository ships with a `wheels/` directory that can be used as this cache.
The full test suite relies on optional packages including `numpy`, `torch`,
`pandas`, `prometheus_client`, `gymnasium`, `playwright`, `httpx`, `uvicorn`,
`git` and `hypothesis`.

#### Wheelhouse Setup

Tests install packages from PyPI unless a local wheelhouse is provided. Build
one from `requirements.lock` and point `WHEELHOUSE` to it before verifying the
environment and running the suite:

```bash
mkdir -p wheels
pip wheel -r requirements.lock -w wheels
export WHEELHOUSE=$(pwd)/wheels
python check_env.py --auto-install --wheelhouse "$WHEELHOUSE"
WHEELHOUSE="$WHEELHOUSE" pytest -q
```

If network access is unavailable and the variable is unset these commands fail
instead of falling back to PyPI.

#### Offline or Restricted Environments

Run `./scripts/build_offline_wheels.sh` to populate a wheelhouse on a
machine with internet access, then set `WHEELHOUSE=<path>` before executing
the tests so dependencies install from this local cache.

#### Test Runtime

Running `pytest` may take several minutes on the first run while caches are
created. Execute the suite in verbose mode to see ongoing progress:

```bash
pytest -vv
```

After completion `pytest` prints a summary such as `### passed in 120.00s`.

The suite includes `tests/test_api_rate_limit.py` which spins up
`api_server.app` with `API_RATE_LIMIT=2` and verifies that exceeding the
limit returns HTTP `429`.

<a name="62-marketplace-demo-example"></a>
### 6.2 Â· Marketplace Demo Example ğŸ›’
A minimal snippet queues the sample job once the orchestrator is running:

```bash
alpha-factory --enabled finance,manufacturing &
python - <<'PY'
import subprocess, time
from alpha_factory_v1.demos import alpha_agi_marketplace_v1 as market
time.sleep(5)
subprocess.run(["bash", str(market.POST_JOB_SCRIPT), str(market.SAMPLE_JOB)], check=True)
marketplace_args = ["python", "-m", "alpha_factory_v1.demos.alpha_agi_marketplace_v1.marketplace", str(market.SAMPLE_JOB)]
subprocess.run(marketplace_args, check=True)
PY
```

---

### 6.2 Â· Cross-Industry Demo Quickâ€‘Start ğŸŒ
Clone the stable `v0.1.0-alpha` release:
```bash
git clone --branch v0.1.0-alpha https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git
cd AGI-Alpha-Agent-v0/alpha_factory_v1/demos/cross_industry_alpha_factory
# Set AUTO_COMMIT=1 to save generated assets back to the repo
./deploy_alpha_factory_cross_industry_demo.sh
```

---

### 6.3 Â· Signing Agent Wheels ğŸ”‘
Sign wheels dropped into `$AGENT_HOT_DIR` with the project ED25519 key.
You need **OpenSSL** to create and verify signatures. Install it with
`brew install openssl` on macOS or from the
[OpenSSL Windows binaries](https://slproweb.com/products/Win32OpenSSL.html).
Generate `<wheel>.whl.sig` via:

```bash
openssl dgst -sha512 -binary <wheel>.whl |
  openssl pkeyutl -sign -inkey agent_signing.key |
  base64 -w0 > <wheel>.whl.sig
```

Keep `<wheel>.whl.sig` next to the wheel in `$AGENT_HOT_DIR`.

Verify the signature (PowerShell example):

```powershell
Get-Content <wheel>.whl -Encoding Byte |
  openssl dgst -sha512 -binary |
  openssl pkeyutl -verify -pubin -inkey $env:AGENT_WHEEL_PUBKEY -sigfile <wheel>.whl.sig
```

Add the base64 signature to `_WHEEL_SIGS` in
`alpha_factory_v1/backend/agents/__init__.py`. Wheels failing verification are
ignored.

### 6.4 Â· Web Dashboard Quick-Start ğŸ“Š
Launch the local web interface:
```bash
uvicorn alpha_factory_v1.demos.alpha_agi_insight_v1.src.interface.api_server:app --reload
streamlit run alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/web_app.py
# React client
cd alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/web_client
npm ci          # use the lock file for reproducible installs
npm run dev       # http://localhost:5173
# build production assets
pnpm build
python -m http.server --directory dist 9000
```
Alternatively run inside Docker:
```bash
# build the web client first so `dist/` exists
make build_web
# regenerate protobuf modules and Go stubs
./tools/gen_proto_stubs.sh  # updates alpha_factory_v1/core/utils/a2a_pb2.py and tools/go_a2a_client/a2a.pb.go
make compose-up  # builds and waits for healthy services
```
Run `./tools/gen_proto_stubs.sh` whenever `alpha_factory_v1/core/utils/a2a.proto` changes to keep the
Python and Go stubs up to date.
Open <http://localhost:8080> in your browser. When `RUN_MODE=web`, the container
serves the static files from `alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/web_client/dist` using `python -m
http.server`. The FastAPI demo also mounts this folder at `/` when present so the
dashboard is reachable without additional tooling.

Once running, Docker Compose marks the services **healthy** when:

- `http://localhost:8000/healthz` returns status `200` for the orchestrator container.
- `http://localhost:8000/status` exposes agent heartbeats and restart counts.
  Use `alpha-agi-insight-v1 agents-status` to view the same data from the CLI.
- `http://localhost:8080/` returns statusÂ `200` for the web container.

The dashboard now plots a 3â€‘D scatter chart of effectiveness vs. risk vs.
complexity from the final population.

If Streamlit isn't installed or you're running on a headless server, use:
```bash
python -m alpha_factory_v1.demos.alpha_agi_insight_v1.src.interface.minimal_ui --text
```
to display the forecast results directly in the console.


---

<a name="7-deployment-recipes"></a>
## 7Â Â·Â DeploymentÂ RecipesÂ ğŸ³
The repository bundles a lightweight `edge_runner.py` helper for running
Alphaâ€‘Factory on airâ€‘gapped or resourceâ€‘constrained devices. The script
forwards to `alpha_factory_v1.edge_runner` and exposes additional flags
like `--cycle`, `--loglevel` and `--version`.
It prints the same warning as the main CLI before launching.

Build the demo containers locally:

```bash
cp .env.sample .env  # fill in NEO4J_PASSWORD, API_TOKEN and optional PINNER_TOKEN
chmod 600 alpha_factory_v1/.env
cd infrastructure
docker build -t alpha-demo .
docker compose up -d
# Dashboard available at <http://localhost:8080>
```

The Compose stack restricts the agents worker using Docker resource limits. The
`agents` service runs with `mem_limit: 8g`, `pids_limit: 512` and
`network_mode: none` to prevent outbound traffic.

The Helm chart under `infrastructure/helm-chart` mirrors this Compose
setup:

```bash
helm upgrade --install alpha-demo ./infrastructure/helm-chart \
  --values ./infrastructure/helm-chart/values.yaml \
  --set env.RUN_MODE=web
# Enable persistent storage for the audit ledger
#   --set persistence.enabled=true --set persistence.size=5Gi
# â†’ browse to <http://localhost:8080>
```

`values.example.yaml` demonstrates typical overrides such as API tokens, service ports and replica counts.

The Helm charts ship with placeholders like `NEO4J_PASSWORD` and
`adminPassword` set to `REPLACE_ME`. Replace these with strong secrets
in `values.yaml` or via `--set` before deploying.

Terraform scripts in `infrastructure/terraform` provide GCP and AWS
examples. Update the placeholder image and networking variables,
then initialise and apply:

```bash
cd infrastructure/terraform
terraform init
terraform apply
```

| Target | Command | Notes |
|--------|---------|-------|
| **Docker Compose** | `docker compose up -d` | Web UI on `localhost:8080` |
| **Helm (K8s)** | `helm install af helm/alpha-factory` | `--set env.RUN_MODE=web` |
| **AWSâ€¯Fargate** | `./infra/deploy_fargate.sh` | set `container_image` & `subnets` |
| **IoT Edge** | `python edge_runner.py --agents manufacturing,energy` | Jetson Nano |
<a name="71-deploying-securely"></a>
### ğŸš€ Deploying securely
See the [documentation](https://montrealai.github.io/AGI-Alpha-Agent-v0/) for TLS setup, API tokens and Vault usage. Mount secrets
via Docker or Kubernetes and never commit them.


---

<a name="8-governance--compliance"></a>
## 8Â Â·Â Governanceâ€¯&â€¯ComplianceÂ âš–ï¸

* **MCP envelopes** (SHAâ€‘256, ISOâ€‘8601, policy hash)  
* **Redâ€‘Team Suite** fuzzes prompts & actions  
* **Attestations** â€” W3C Verifiable Credentials at every Actuator call

---

<a name="9-observability"></a>
## 9Â Â·Â ObservabilityÂ ğŸ”­

| Signal | Sink | Example |
|--------|------|---------|
| Metrics | Prometheus | `alpha_pnl_realised_usd` |
| Traces | OpenTelemetry | `trace_id` |
| Dashboards | Grafana | `alpha-factory/trade-lifecycle.json` |

Prometheus scrapes metrics from the API server at `/metrics`.

By default traces and metrics print to ``stdout``. To export to a collector such
as **Jaeger**, set ``OTEL_EXPORTER_OTLP_ENDPOINT`` and start Jaeger locally:

```bash
docker run -p 16686:16686 -p 4317:4317 jaegertracing/all-in-one
```

Set ``OTEL_ENDPOINT`` to enable anonymous dashboard telemetry. Users are
prompted for consent before any metrics are sent.

### Telemetry Queue
Anonymous usage metrics are buffered in the browser under the
`telemetryQueue` key in `localStorage`. Each record includes:

- `ts` â€“ the timestamp when the entry was recorded.
- `session` â€“ a deterministic SHAâ€‘256 hash identifying the session.
- `generations` â€“ how many runs were executed.
- `shares` â€“ how many times results were shared.

When the browser is online the queue is flushed to ``OTEL_ENDPOINT`` using
`navigator.sendBeacon` with a `fetch` fallback. The queue holds at most 100
entries and is persisted across page loads until sent. No personal data or IP
addresses are stored.

Telemetry can be disabled from the Analytics panel by clicking **Disable
telemetry**. Clearing the `telemetryConsent` and `telemetryQueue` entries in
browser storage also stops all transmissions.

---

<a name="10-safety--security"></a>
## 10Â Â·Â Safety & SecurityÂ ğŸ›¡ï¸

The [policy runbook](https://montrealai.github.io/AGI-Alpha-Agent-v0/) outlines sandbox resource limits,
timeout behaviour, required human review and rollback steps.
Operational tips for the governance module reside in the
[documentation](https://montrealai.github.io/AGI-Alpha-Agent-v0/).

---

<a name="11-extending-the-mesh"></a>
## 11Â Â·Â Extending theÂ MeshÂ ğŸ”Œ
```python
from backend.agents.base import AgentBase

class MySuperAgent(AgentBase):
    NAME = "super"
    CAPABILITIES = ["telemetry_fusion"]
    COMPLIANCE_TAGS = ["gdpr_minimal"]

    async def run_cycle(self):
        ...

# setup.py entrypoint
[project.entry-points."alpha_factory.agents"]
super = my_pkg.super_agent:MySuperAgent
```
`pip install .` â†’ orchestrator hotâ€‘loads at next boot.

---

<a name="12-troubleshooting"></a>
## 12Â Â·Â TroubleshootingÂ ğŸ› ï¸

| Symptom | Cause | Fix |
|---------|-------|-----|
| `ImportError: faiss` | FAISS missing | `pip install faiss-cpu` |
| Agent quarantined | exceptions | Check logs, clear flag |
| Kafka refuse | broker down | unset `ALPHA_KAFKA_BROKER` |

---

<a name="13-roadmap"></a>
## 13Â Â·Â RoadmapÂ ğŸ›£ï¸

1. **RLâ€‘onâ€‘Execution** â€” slippageâ€‘aware order routing  
2. **Federated Mesh** â€” crossâ€‘org agent exchange via ADK federation  
3. **Worldâ€‘Model Audits** â€” interpretable probes of latents  
4. **Industry Packs** â€” Healthâ€‘Care, Govâ€‘Tech  
5. **Provable SafetyÂ â„™** â€” Coq proofs for Actuators  

---

<a name="14-credits"></a>
## 14Â Â·Â CreditsÂ ğŸŒŸ

[VincentÂ Boucher](https://www.linkedin.com/in/montrealai/)â€”pioneer in AI and President of
[MONTREAL.AI](https://www.montreal.ai/) sinceÂ 2003â€”dominated the
[OpenAIÂ Gym](https://web.archive.org/web/20170929214241/https://gym.openai.com/read-only.html) with **AI Agents**
inÂ 2016 and unveiled the seminal [**â€œMultiâ€‘Agent AIÂ DAOâ€**](https://www.quebecartificialintelligence.com/priorart)
inÂ 2017.

Our **AGIÂ ALPHAÂ AGENT**, fuelled by the strictlyâ€‘utility **$AGIALPHA** token, now taps that foundation to unleash the
ultimate Î±â€‘signal engine.

<a name="15-license"></a>
## 15Â Â·Â License

This project is distributed under the [ApacheÂ 2.0](LICENSE) license.
All community members are expected to follow our [Code of Conduct](CODE_OF_CONDUCT.md).
Please report security issues via the process outlined in our [Security Policy](SECURITY.md).

### Release Tweet

```
ğŸš€ New Alpha-Factory release! Offline dashboard, responsive UI and automated visual tests powered by Percy.
```

<a name="16-final-note"></a>
## 16 Â· Final Note

Please ensure all usage and contributions align with the project's
[ApacheÂ 2.0 license](LICENSE).
---

*Made withÂ â¤ï¸Â by the Alphaâ€‘FactoryÂ Agentic Core Team â€” forging the tools that forge tomorrow.*
