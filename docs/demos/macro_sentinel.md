[See docs/DISCLAIMER_SNIPPET.md](../DISCLAIMER_SNIPPET.md)

# üåê Macro‚ÄëSentinel¬†¬∑ Alpha‚ÄëFactory‚ÄØv1¬†üëÅÔ∏è‚ú®

![preview](../alpha_agi_insight_v1/favicon.svg){.demo-preview}

[See docs/DISCLAIMER_SNIPPET.md](../../../docs/DISCLAIMER_SNIPPET.md)
This repository is a conceptual research prototype. References to "AGI" and "superintelligence" describe aspirational goals and do not indicate the presence of a real general intelligence. Use at your own risk. Nothing herein constitutes financial advice. MontrealAI and the maintainers accept no liability for losses incurred from using this software.
Each demo package exposes its own `__version__` constant. The value marks the revision of that demo only and does not reflect the overall Alpha‚ÄëFactory release version.



# üåê Macro‚ÄëSentinel¬†¬∑ Alpha‚ÄëFactory‚ÄØv1¬†üëÅÔ∏è‚ú®  
*Cross‚Äëasset macro risk radar powered by multi‚Äëagent Œ±‚ÄëAGI*

[![Docker](https://img.shields.io/badge/Run‚Äëwith-Docker-blue?logo=docker)](#one‚Äëcommand‚Äëdocker)¬†
[![Colab](https://img.shields.io/badge/Try‚Äëon‚ÄëColab-yellow?logo=googlecolab)](#google‚Äëcolab)¬†
![License](https://img.shields.io/badge/License-Apache%202.0-blue)

> **TL;DR**¬†¬†¬†Spin up a self‚Äëhealing stack that ingests macro telemetry, runs a Monte‚ÄëCarlo risk engine, sizes an ES hedge, and explains its reasoning‚Äîall behind a Gradio dashboard.

This demonstration is a conceptual research prototype. Any references to AGI or superintelligence describe aspirational goals rather than current capabilities.

---

## ‚ú®¬†Key capabilities
| Capability | Detail |
|------------|--------|
| **Multi‚Äëagent orchestration** | OpenAI¬†Agents¬†SDK + A2A protocol |
| **LLM fail‚Äëover** | GPT‚Äë4o when `OPENAI_API_KEY` present, Mixtral‚Äë8x7B (Ollama) otherwise |
| **Live + offline feeds** | FRED yield curve, Fed RSS speeches, Etherscan on‚Äëchain flows |
| **Risk engine** | 10‚ÄØk¬†√ó¬†30‚Äëday 3‚Äëfactor Monte‚ÄëCarlo (<‚ÄØ20‚ÄØms¬†CPU) |
| **Seeded runs** | Use `MonteCarloSimulator(seed=42)` for reproducible results |
| **Action layer** | Draft JSON orders for Micro‚ÄëES futures (Alpaca stub) |
| **Observability** | TimescaleDB, Redis stream, Prometheus & Grafana dashboard |
| **A2A gateway** | Optional Google ADK server via `ALPHA_FACTORY_ENABLE_ADK=1` |

---

## üèóÔ∏è¬†Architecture

```mermaid
flowchart LR
    subgraph Agents
        A[LLM¬†Toolbox] -->|A2A| B[Orchestrator<br/>Agent]
    end
    B --> C(Monte‚ÄëCarlo¬†Simulator)
    B --> D[Gradio¬†UI]
    B --> E[TimescaleDB]
    B --> F[Redis¬†Bus]

    subgraph Sources
        G[CSV¬†Snapshots / FRED / Fed RSS / Etherscan]
    end
    G --> B
```

---

## üöÄ Quickstart

### One‚Äëcommand (Docker)

```bash
git clone https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git
cd AGI-Alpha-Agent-v0/alpha_factory_v1/demos/macro_sentinel
python ../../check_env.py --demo macro_sentinel    # verify optional dependencies
./run_macro_demo.sh           # add --live for real‚Äëtime collectors
                              # (--live exports LIVE_FEED=1)
```

Export `OPENAI_API_KEY` in your shell (or define it in `config.env`) before
launching. If the variable is absent, the script runs in offline mode. With the
previous issue resolved, the launcher now reads `config.env` automatically when
present.

Offline mode requires an [Ollama](https://ollama.com) server with the
`mixtral:instruct` model available at `http://localhost:11434`. The Docker
stack provisions this container automatically via the `offline` profile using
`ollama/ollama:0.1.32`, but when running bare‚Äëmetal or inside Colab you must
manually start `ollama serve` first. If the server runs elsewhere, set
`OLLAMA_BASE_URL=http://<host>:11434/v1` in your shell or `config.env`. To
upgrade or pin a different version, edit `docker-compose.macro.yml` and rebuild
with `docker compose build --pull`.

Offline sample data is fetched automatically the first time you run the
launcher‚Äîno manual downloads required. These CSV snapshots mirror
public data from the [demo‚Äëassets](https://github.com/MontrealAI/demo-assets)
repository and cover roughly March‚ÄìApril¬†2024 activity.

These CSVs are pinned at revision `90fe9b623b3a0ae5475cf4fa8693d43cb5ba9ac5` of
the demo-assets repo. Set `DEMO_ASSETS_REV=<sha>` to override when refreshing
the snapshots. Run `python refresh_offline_data.py --revision <sha>` to
synchronize them with a different commit from the external repository.

To reuse existing CSV snapshots or share them across projects,
set `OFFLINE_DATA_DIR=/path/to/csvs` in your shell or `config.env`.

*Dashboard:* http://localhost:7864
*Health:*    http://localhost:7864/healthz
*Grafana:*¬†http://localhost:3001¬†(admin/alpha)
*ADK gateway:* http://localhost:9000 (when `ALPHA_FACTORY_ENABLE_ADK=1`)

### ADK gateway

Expose a Google ADK endpoint by setting `ALPHA_FACTORY_ENABLE_ADK=1` before
launching the stack:

```bash
ALPHA_FACTORY_ENABLE_ADK=1 ./run_macro_demo.sh
```

Require an authentication header by also exporting `ALPHA_FACTORY_ADK_TOKEN`:

```bash
export ALPHA_FACTORY_ENABLE_ADK=1
export ALPHA_FACTORY_ADK_TOKEN=mysecret
./run_macro_demo.sh
```

Interact with the running gateway using `curl` or the `google-adk` CLI:

```bash
curl -X POST http://localhost:9000/v1/tasks \
     -H "x-alpha-factory-token: mysecret" \
     -H "Content-Type: application/json" \
     -d '{"agent": "risk_agent", "content": "hedge 100 ES"}'

google-adk create-task --host http://localhost:9000 \
                       --agent risk_agent \
                       --content "hedge 100 ES" \
                       --token mysecret
```

See [`../../backend/adk_bridge.py`](../../backend/adk_bridge.py) for advanced
configuration options such as custom bind addresses.

### Google¬†Colab

[Open the notebook ‚ñ∂](colab_macro_sentinel.ipynb)

### Bare‚Äëmetal (advanced)

```bash
pip install -r requirements.txt
macro-sentinel  # or `python agent_macro_entrypoint.py`
```
The entry point pulls minimal CSV snapshots if they are missing so you can run
fully offline.

### Preparing a wheelhouse

Build wheels on a machine with internet access so the demo can be installed
offline:

```bash
pip wheel -r requirements.txt -w /path/to/wheels
```

Pass `--wheelhouse /path/to/wheels` to `check_env.py` as shown below.

### Offline installation

```bash
pip wheel -r requirements.txt -w /media/wheels
WHEELHOUSE=/media/wheels AUTO_INSTALL_MISSING=1 \
  python ../../check_env.py --demo macro_sentinel --auto-install --wheelhouse /media/wheels
```

This mirrors the repository's offline setup instructions so the demo works
without internet access.

For a concise overview of the offline workflow see
[the repository guide](../../../docs/OFFLINE_INSTALL.md).

---

## ‚öôÔ∏è¬†Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `OPENAI_API_KEY` | *(blank)* | Use GPT‚Äë4o when provided; offline Mixtral otherwise |
| `MODEL_NAME` | `gpt-4o-mini` | Any OpenAI completion model |
| `TEMPERATURE` | `0.15` | LLM sampling temperature |
| `OLLAMA_BASE_URL` | `http://ollama:11434/v1` | Offline LLM endpoint |
| `FRED_API_KEY` | *(blank)* | Enables live yield‚Äëcurve collector |
| `ETHERSCAN_API_KEY` | *(blank)* | Enables on‚Äëchain stable‚Äëflow collector |
| `STABLE_TOKEN` | `0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606e48` | ERC‚Äë20 token used for stablecoin flow tracking |
| `TW_BEARER_TOKEN` | *(blank)* | Twitter/X API bearer token for Fed speech stream |
| `PG_PASSWORD` | `alpha` | TimescaleDB superuser password |
| `REDIS_PASSWORD` | *(blank)* | Optional password for the Redis cache |
| `LIVE_FEED` | `0` | 1 uses live FRED/Etherscan feeds |
| `POLL_INTERVAL_SEC` | `15` | Seconds between macro event polls (1 offline) |
| `OFFLINE_DATA_DIR` | `offline_samples/` | Path for CSV snapshots |
| `DEFAULT_PORTFOLIO_USD` | `2000000` | Portfolio USD notional for Monte‚ÄëCarlo hedge sizing |
| `ALPHA_FACTORY_ENABLE_ADK` | `0` | 1 exposes ADK gateway on port 9000 |
| `ALPHA_FACTORY_ADK_TOKEN` | *(blank)* | Require `x-alpha-factory-token` header when set |
| `PROMETHEUS_SCRAPE_INTERVAL` | `15s` | Metrics polling frequency |
| `GRAFANA_ADMIN_PASSWORD` | `alpha` | Grafana admin password |

Edit **`config.env`** or export variables before launch.

---

## üìä Grafana dashboards

| Dashboard | Path |
|-----------|------|
| Macro Events | `macro_stream.json` |
| Risk Metrics | `risk_metrics.json` |

Pre‚Äëprovisioned at <http://localhost:3001>.

### Accessing Grafana

Open your browser to `http://localhost:3001` and log in with user `admin` and
`GRAFANA_ADMIN_PASSWORD` (default `alpha`). The `Macro Events` and `Risk Metrics`
dashboards load automatically.

### Tuning Prometheus

Adjust metric collection frequency by setting `PROMETHEUS_SCRAPE_INTERVAL` in
`config.env` before launching, or edit `observability/prometheus.yml` for more
advanced settings.

---

## üõ†Ô∏è¬†Directory layout

```
macro_sentinel/
‚îú‚îÄ‚îÄ agent_macro_entrypoint.py   # Gradio + Agent wiring
‚îú‚îÄ‚îÄ data_feeds.py               # offline/live feed generator
‚îú‚îÄ‚îÄ simulation_core.py          # Monte‚ÄëCarlo risk engine
‚îú‚îÄ‚îÄ run_macro_demo.sh           # Docker launcher
‚îú‚îÄ‚îÄ docker-compose.macro.yml    # Service graph
‚îú‚îÄ‚îÄ colab_macro_sentinel.ipynb  # Cloud notebook
‚îî‚îÄ‚îÄ offline_samples/            # CSV snapshots (auto‚Äësynced)
```

---

## üîê¬†Security notes
* No secrets are baked into images.
* All containers drop root and listen on ¬†`0.0.0.0`¬†only when behind Docker bridge.
* Network egress is restricted to required endpoints (FRED, Etherscan, ollama).

---

## WARNING: Disclaimer

This demo is **for research and educational purposes only**. It
does not constitute financial advice and should not be relied upon
for real trading decisions. MontrealAI and the maintainers accept
no liability for losses incurred from using this software.

---

## ü©π Troubleshooting

| Symptom | Fix |
|---------|-----|
| `Health-check failed` | Increase `health_wait` tries or free port¬†7864 |
| GPU not used | Ensure `nvidia‚Äëdocker` runtime and drivers ‚â•¬†535 |
| Colab hangs at tunnel | Re‚Äërun; sometimes Gradio link takes >30‚ÄØs |

---

## üìú¬†License
Apache‚Äë2.0¬†¬©¬†2025¬†**MONTREAL.AI**

Happy alpha‚Äëhunting¬†üöÄ


[View README](../../alpha_factory_v1/demos/macro_sentinel/README.md)
