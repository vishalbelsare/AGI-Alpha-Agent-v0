[See docs/DISCLAIMER_SNIPPET.md](../DISCLAIMER_SNIPPET.md)

# üåê Macro‚ÄëSentinel¬†¬∑ Alpha‚ÄëFactory‚ÄØv1¬†üëÅÔ∏è‚ú®

![preview](../macro_sentinel/assets/preview.svg){.demo-preview}

[Launch Demo](../macro_sentinel/){.md-button}

Each demo package exposes its own `__version__` constant. The value marks the revision of that demo only and does not reflect the overall Alpha‚ÄëFactory release version.



# üåê Macro‚ÄëSentinel¬†¬∑ Alpha‚ÄëFactory‚ÄØv1¬†üëÅÔ∏è‚ú®  
*Cross‚Äëasset macro risk radar powered by multi‚Äëagent Œ±‚ÄëAGI*

[![Docker](https://img.shields.io/badge/Run‚Äëwith-Docker-blue?logo=docker)](#one‚Äëcommand‚Äëdocker)¬†
[![Colab](https://img.shields.io/badge/Try‚Äëon‚ÄëColab-yellow?logo=googlecolab)](#google‚Äëcolab)¬†
![License](https://img.shields.io/badge/License-Apache%202.0-blue)

> **TL;DR**¬†¬†¬†Spin up a self‚Äëhealing stack that ingests macro telemetry, runs a Monte‚ÄëCarlo risk engine, sizes an ES hedge, and explains its reasoning‚Äîall behind a Gradio dashboard.


---

## ‚ú®¬†Key capabilities
| Capability | Detail |
|------------|--------|
| **Multi‚Äëagent orchestration** | OpenAI¬†Agents¬†SDK + A2A protocol |
| **LLM fail‚Äëover** | GPT‚Äë4o when `OPENAI_API_KEY` present, Mixtral‚Äë8x7B (Ollama) otherwise |
| **Live + offline feeds** | FRED yield curve, Fed RSS speeches, Etherscan on‚Äëchain flows |
| **Risk engine** | 10‚ÄØk¬†√ó¬†30‚Äëday 3‚Äëfactor Monte‚ÄëCarlo (<‚ÄØ20‚ÄØms¬†CPU) |
| **Seeded runs** | Use `MonteCarloSimulator(seed=42)` for reproducible results |
| **Action layer** | Draft JSON orders for Micro‚ÄëES futures (Alpaca stub) |
| **Observability** | TimescaleDB, Redis stream, Prometheus & Grafana dashboard |
| **A2A gateway** | Optional Google ADK server via `ALPHA_FACTORY_ENABLE_ADK=1` |

---

## üèóÔ∏è¬†Architecture

```mermaid
flowchart LR
    subgraph Agents
        A[LLM¬†Toolbox] -->|A2A| B[Orchestrator<br/>Agent]
    end
    B --> C(Monte‚ÄëCarlo¬†Simulator)
    B --> D[Gradio¬†UI]
    B --> E[TimescaleDB]
    B --> F[Redis¬†Bus]

    subgraph Sources
        G[CSV¬†Snapshots / FRED / Fed RSS / Etherscan]
    end
    G --> B
```

---

## üöÄ Quickstart

### One‚Äëcommand (Docker)

```bash
git clone https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git
cd AGI-Alpha-Agent-v0/alpha_factory_v1/demos/macro_sentinel
python ../../check_env.py --demo macro_sentinel    # verify optional dependencies
./run_macro_demo.sh           # add --live for real‚Äëtime collectors
                              # (--live exports LIVE_FEED=1)
```

Export `OPENAI_API_KEY` in your shell (or define it in `config.env`) before
launching. If the variable is absent, the script runs in offline mode. With the
previous issue resolved, the launcher now reads `config.env` automatically when
present.

Offline mode requires an [Ollama](https://ollama.com) server with the
`mixtral:instruct` model available at `http://localhost:11434`. The Docker
stack provisions this container automatically via the `offline` profile using
`ollama/ollama:0.1.32`, but when running bare‚Äëmetal or inside Colab you must
manually start `ollama serve` first. If the server runs elsewhere, set
`OLLAMA_BASE_URL=http://<host>:11434/v1` in your shell or `config.env`. To
upgrade or pin a different version, edit `docker-compose.macro.yml` and rebuild
with `docker compose build --pull`.

Offline sample data is fetched automatically the first time you run the
launcher‚Äîno manual downloads required. These CSV snapshots mirror
public data from the [demo‚Äëassets](https://github.com/MontrealAI/demo-assets)
repository and cover roughly March‚ÄìApril¬†2024 activity.

These CSVs are pinned at revision `90fe9b623b3a0ae5475cf4fa8693d43cb5ba9ac5` of
the demo-assets repo. Set `DEMO_ASSETS_REV=<sha>` to override when refreshing
the snapshots. Run `python refresh_offline_data.py --revision <sha>` to
synchronize them with a different commit from the external repository.

To reuse existing CSV snapshots or share them across projects,
set `OFFLINE_DATA_DIR=/path/to/csvs` in your shell or `config.env`.

*Dashboard:* http://localhost:7864
*Health:*    http://localhost:7864/healthz
*Grafana:*¬†http://localhost:3001¬†(admin/alpha)
*ADK gateway:* http://localhost:9000 (when `ALPHA_FACTORY_ENABLE_ADK=1`)

### ADK gateway

Expose a Google ADK endpoint by setting `ALPHA_FACTORY_ENABLE_ADK=1` before
launching the stack:

```bash
ALPHA_FACTORY_ENABLE_ADK=1 ./run_macro_demo.sh
```

Require an authentication header by also exporting `ALPHA_FACTORY_ADK_TOKEN`:

```bash
export ALPHA_FACTORY_ENABLE_ADK=1
export ALPHA_FACTORY_ADK_TOKEN=mysecret
./run_macro_demo.sh
```

Interact with the running gateway using `curl` or the `google-adk` CLI:

```bash
curl -X POST http://localhost:9000/v1/tasks \
     -H "x-alpha-factory-token: mysecret" \
     -H "Content-Type: application/json" \
     -d '{"agent": "risk_agent", "content": "hedge 100 ES"}'

google-adk create-task --host http://localhost:9000 \
                       --agent risk_agent \
                       --content "hedge 100 ES" \
                       --token mysecret
```

See [`../../backend/adk_bridge.py`](../../backend/adk_bridge.py) for advanced
configuration options such as custom bind addresses.

### Google¬†Colab

[Open the notebook ‚ñ∂](colab_macro_sentinel.ipynb)

### Bare‚Äëmetal (advanced)

```bash
pip install -r requirements.txt
macro-sentinel  # or `python agent_macro_entrypoint.py`
```
The entry point pulls minimal CSV snapshots if they are missing so you can run
fully offline.

### Preparing a wheelhouse

Build wheels on a machine with internet access so the demo can be installed
offline:

```bash
pip wheel -r requirements.txt -w /path/to/wheels
```

Pass `--wheelhouse /path/to/wheels` to `check_env.py` as shown below.

### Offline installation

```bash
pip wheel -r requirements.txt -w /media/wheels
WHEELHOUSE=/media/wheels AUTO_INSTALL_MISSING=1 \
  python ../../check_env.py --demo macro_sentinel --auto-install --wheelhouse /media/wheels
```

This mirrors the repository's offline setup instructions so the demo works
without internet access.

For a concise overview of the offline workflow see
[the repository guide](../../../docs/OFFLINE_INSTALL.md).

---

## ‚öôÔ∏è¬†Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `OPENAI_API_KEY` | *(blank)* | Use GPT‚Äë4o when provided; offline Mixtral otherwise |
| `MODEL_NAME` | `gpt-4o-mini` | Any OpenAI completion model |
| `TEMPERATURE` | `0.15` | LLM sampling temperature |
| `OLLAMA_BASE_URL` | `http://ollama:11434/v1` | Offline LLM endpoint |
| `FRED_API_KEY` | *(blank)* | Enables live yield‚Äëcurve collector |
| `ETHERSCAN_API_KEY` | *(blank)* | Enables on‚Äëchain stable‚Äëflow collector |
| `STABLE_TOKEN` | `0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606e48` | ERC‚Äë20 token used for stablecoin flow tracking |
| `TW_BEARER_TOKEN` | *(blank)* | Twitter/X API bearer token for Fed speech stream |
| `PG_PASSWORD` | `alpha` | TimescaleDB superuser password |
| `REDIS_PASSWORD` | *(blank)* | Optional password for the Redis cache |
| `LIVE_FEED` | `0` | 1 uses live FRED/Etherscan feeds |
| `POLL_INTERVAL_SEC` | `15` | Seconds between macro event polls (1 offline) |
| `OFFLINE_DATA_DIR` | `offline_samples/` | Path for CSV snapshots |
| `DEFAULT_PORTFOLIO_USD` | `2000000` | Portfolio USD notional for Monte‚ÄëCarlo hedge sizing |
| `ALPHA_FACTORY_ENABLE_ADK` | `0` | 1 exposes ADK gateway on port 9000 |
| `ALPHA_FACTORY_ADK_TOKEN` | *(blank)* | Require `x-alpha-factory-token` header when set |
| `PROMETHEUS_SCRAPE_INTERVAL` | `15s` | Metrics polling frequency |
| `GRAFANA_ADMIN_PASSWORD` | `alpha` | Grafana admin password |

Edit **`config.env`** or export variables before launch.

---

## üìä Grafana dashboards

| Dashboard | Path |
|-----------|------|
| Macro Events | `macro_stream.json` |
| Risk Metrics | `risk_metrics.json` |

Pre‚Äëprovisioned at <http://localhost:3001>.

### Accessing Grafana

Open your browser to `http://localhost:3001` and log in with user `admin` and
`GRAFANA_ADMIN_PASSWORD` (default `alpha`). The `Macro Events` and `Risk Metrics`
dashboards load automatically.

### Tuning Prometheus

Adjust metric collection frequency by setting `PROMETHEUS_SCRAPE_INTERVAL` in
`config.env` before launching, or edit `observability/prometheus.yml` for more
advanced settings.

---

## üõ†Ô∏è¬†Directory layout

```
macro_sentinel/
‚îú‚îÄ‚îÄ agent_macro_entrypoint.py   # Gradio + Agent wiring
‚îú‚îÄ‚îÄ data_feeds.py               # offline/live feed generator
‚îú‚îÄ‚îÄ simulation_core.py          # Monte‚ÄëCarlo risk engine
‚îú‚îÄ‚îÄ run_macro_demo.sh           # Docker launcher
‚îú‚îÄ‚îÄ docker-compose.macro.yml    # Service graph
‚îú‚îÄ‚îÄ colab_macro_sentinel.ipynb  # Cloud notebook
‚îî‚îÄ‚îÄ offline_samples/            # CSV snapshots (auto‚Äësynced)
```

---

## üîê¬†Security notes
* No secrets are baked into images.
* All containers drop root and listen on ¬†`0.0.0.0`¬†only when behind Docker bridge.
* Network egress is restricted to required endpoints (FRED, Etherscan, ollama).

---


---

## ü©π Troubleshooting

| Symptom | Fix |
|---------|-----|
| `Health-check failed` | Increase `health_wait` tries or free port¬†7864 |
| GPU not used | Ensure `nvidia‚Äëdocker` runtime and drivers ‚â•¬†535 |
| Colab hangs at tunnel | Re‚Äërun; sometimes Gradio link takes >30‚ÄØs |

---

## üìú¬†License
Apache‚Äë2.0¬†¬©¬†2025¬†**MONTREAL.AI**

Happy alpha‚Äëhunting¬†üöÄ

[View README](../../alpha_factory_v1/demos/macro_sentinel/README.md)
