{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "colab": {
   "name": "AI-GA_Meta-Evolution_Demo.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": { "name": "python" }
 },
 "cells": [
  { "cell_type": "markdown",
    "source": [
     "# ðŸ§¬ AI-GA Meta-Evolution Â· Colab v3.5\n",
     "\n",
     "**Launch the complete three-pillar demo** (Clune 2020) in ~2 min â€” straight from your browser.\n",
     "\n",
     "| feature | note |\n",
     "|---------|------|\n",
     "| Minimal deps | `torch`, `gymnasium`, `openai_agents`, `gradio`, `ray` (GPU optional) |\n",
     "| LLM mode | set `OPENAI_API_KEY` â†’ online; else Mixtral via Ollama cloud binary |\n",
     "| Dashboards | Gradio (7862) + FastAPI (8000 â†’ `/docs`) |\n",
     "| Tests | `pytest -q` â‰¥ 90 % branch cov < 0.5 s |\n",
     "| Observability | Prometheus scrape + inline Matplotlib plot |\n",
     "| Scale-out | Ray remote evaluation; K8s YAML snippet |\n",
     "| SOC-2 | no secrets on disk, signed-image example |\n"
    ]
  },

  { "cell_type": "code",
    "metadata": { "id": "00_gpu_flag" },
    "source": [
     "#@title â†³ Select runtime { run: \"auto\", display-mode: \"form\" }\n",
     "USE_GPU = False  #@param {type:\"boolean\"}\n",
     "import os; os.environ[\"USE_GPU\"] = str(USE_GPU)\n",
     "print(\"âš™ï¸  GPU\" if USE_GPU else \"âš™ï¸  CPU\", \"runtime selected\")"
    ]
  },

  { "cell_type": "code",
    "metadata": { "id": "01_setup" },
    "source": [
     "%%bash --no-stderr\n",
     "set -Eeuo pipefail\n",
     "REPO=AGI-Alpha-Agent-v0\n",
     "[[ -d $REPO ]] || git clone --depth 1 https://github.com/MontrealAI/$REPO.git -q\n",
     "cd $REPO/alpha_factory_v1/demos/aiga_meta_evolution\n",
     "\n",
     "# pick torch wheel (CPU vs CUDA)\n",
     "IDX=$(python - <<PY\n",
     "import os; print('cu118' if os.getenv('USE_GPU')=='True' else 'cpu')\n",
     "PY)\n",
     "python -m pip -q install --upgrade pip\n",
     "python -m pip -q install torch torchvision --extra-index-url https://download.pytorch.org/whl/$IDX\n",
     "python -m pip -q install gymnasium[classic_control] gradio==4.* openai_agents ray httpx prometheus-client pytest coverage\n",
     "echo 'âœ…  Dependencies installed'"
    ]
  },

  { "cell_type": "code",
    "metadata": { "id": "02_key" },
    "source": [
     "import os, getpass\n",
     "if not os.getenv(\"OPENAI_API_KEY\"):\n",
     "    key = getpass.getpass(\"Paste OPENAI_API_KEY (or press Enter for offline mode): \")\n",
     "    if key:\n",
     "        %env OPENAI_API_KEY=$key\n",
     "        print(\"ðŸ”‘  Key set â€” online mode.\")\n",
     "    else:\n",
     "        print(\"ðŸ›°ï¸  Offline mode (Mixtral via Ollama fallback).\")"
    ]
  },

  { "cell_type": "code",
    "metadata": { "id": "03_tests" },
    "source": [
     "%%bash\n",
     "cd AGI-Alpha-Agent-v0/alpha_factory_v1/demos/aiga_meta_evolution\n",
     "pytest -q --disable-warnings --cov=. --cov-branch --cov-report=term-missing:skip-covered || echo 'âš ï¸  Tests < 90 % coverage â€” investigate'"
    ]
  },

  { "cell_type": "code",
    "metadata": { "id": "04_launch" },
    "source": [
     "import subprocess, threading, re, time, pathlib, sys, os\n",
     "ROOT = pathlib.Path('AGI-Alpha-Agent-v0/alpha_factory_v1/demos/aiga_meta_evolution').resolve()\n",
     "os.chdir(ROOT)\n",
     "proc = subprocess.Popen([sys.executable, 'agent_aiga_entrypoint.py'],\n",
     "                        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
     "                        text=True)\n",
     "dash_url = None\n",
     "def _tail():\n",
     "    global dash_url\n",
     "    for ln in proc.stdout:\n",
     "        print(ln, end='')\n",
     "        if dash_url is None and 'Running on' in ln and 'https' in ln:\n",
     "            dash_url = re.search(r'https?://[\\w./-]+', ln)[0]\n",
     "            print(f\"\\nðŸ”—  Dashboard â†’ {dash_url}\\n\")\n",
     "threading.Thread(target=_tail, daemon=True).start()\n",
     "for _ in range(90):\n",
     "    if dash_url: break\n",
     "    time.sleep(1)\n",
     "if not dash_url: print('â³  Still starting â€¦ check logs above.')"
    ]
  },

  { "cell_type": "markdown", "source": "## â˜Žï¸  FastAPI helper" },

  { "cell_type": "code",
    "metadata": { "id": "05_api" },
    "source": [
     "import httpx, json, time\n",
     "API='http://localhost:8000'\n",
     "print('Health:', httpx.get(API+'/health').json())\n",
     "httpx.post(API+'/evolve/10')\n",
     "print('â©  10 generations scheduled.')"
    ]
  },

  { "cell_type": "markdown", "source": "## ðŸ“ˆ  Prometheus scrape" },

  { "cell_type": "code",
    "metadata": { "id": "06_metrics" },
    "source": [
     "import httpx, re\n",
     "raw=httpx.get('http://localhost:8000/metrics').text\n",
     "gen=int(re.search(r'aiga_generations_total (\\d+)', raw).group(1))\n",
     "fit=float(re.search(r'aiga_best_fitness (\\d+\\.?\\d*)', raw).group(1))\n",
     "print(f'Gen {gen}, best fitness {fit:.2f}')"
    ]
  },

  { "cell_type": "markdown", "source": "## ðŸ“Š  Plot history" },

  { "cell_type": "code",
    "metadata": { "id": "07_plot" },
    "source": [
     "import glob, json, pandas as pd, matplotlib.pyplot as plt, pathlib\n",
     "ckpts=sorted(glob.glob('checkpoints/evolver_gen*.json'))\n",
     "if ckpts:\n",
     "    hist=json.loads(pathlib.Path(ckpts[-1]).read_text())[\"history\"]\n",
     "    pd.DataFrame(hist, columns=['gen','avg']).plot(x='gen',y='avg',grid=True,figsize=(6,3));\n",
     "else:\n",
     "    print('No checkpoints yet.')"
    ]
  },

  { "cell_type": "markdown",
    "source": [
      "---\n",
      "## ðŸ—  Kubernetes snippet\n",
      "```yaml\n",
      "apiVersion: apps/v1\n",
      "kind: Deployment\n",
      "metadata: { name: aiga-demo }\n",
      "spec:\n",
      "  replicas: 1\n",
      "  selector: { matchLabels: { app: aiga-demo } }\n",
      "  template:\n",
      "    metadata: { labels: { app: aiga-demo } }\n",
      "    spec:\n",
      "      containers:\n",
      "      - name: orchestrator\n",
      "        image: ghcr.io/montrealai/alpha-aiga:latest@sha256:<signed>\n",
      "        envFrom: [{ secretRef: { name: aiga-secrets } }]\n",
      "        ports:\n",
      "        - { containerPort: 8000 }\n",
      "        - { containerPort: 7862 }\n",
      "```"
    ]
  },

  { "cell_type": "markdown",
    "source": "### ðŸŽ¯  Next steps â€” adjust `meta_evolver.py`, extend the curriculum, or hook the REST API into your own autonomous pipelines." }
 ]
}
