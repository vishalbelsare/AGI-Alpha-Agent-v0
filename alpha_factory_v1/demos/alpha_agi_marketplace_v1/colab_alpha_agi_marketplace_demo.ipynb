{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83d\uded2 Alpha\u2011AGI Marketplace \u00b7 Colab Notebook\n", "\n", "Run the Alpha\u2011Factory marketplace micro-demo.\n", "\n", "* \ud83d\udd27 Start the orchestrator\n", "* \ud83d\udce8 Queue a sample job and inspect memory\n", "* \ud83d\udd34 Works offline via Mixtral unless you provide an `OPENAI_API_KEY`\n", "\n", "Paste your OpenAI key below or leave blank to run offline."]}, {"cell_type": "code", "metadata": {"id": "env"}, "source": ["OPENAI_API_KEY = \"\"  # optional"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "setup"}, "source": ["%%bash\n", "set -euo pipefail\n", "REPO=AGI-Alpha-Agent-v0\n", "if [ ! -d \"$REPO/.git\" ]; then\n", "  echo '\ud83d\udce5 Cloning repo ...'\n", "  git clone --depth 1 https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git $REPO\n", "fi\n", "cd $REPO\n", "\n", "echo '\ud83d\udd27 Installing dependencies ...'\n", "pip install -q -r alpha_factory_v1/requirements-colab.txt\n", "pip install -q uvicorn fastapi pyngrok ctransformers==0.2.27\n", "\n", "mkdir -p alpha_factory_v1/{keys,policies}\n", "ssh-keygen -t ed25519 -N '' -q -f alpha_factory_v1/keys/agent_key <<<y || true\n", "PUB=$(cat alpha_factory_v1/keys/agent_key.pub)\n", "\n", "cat > alpha_factory_v1/.env <<EOF\n", "OPENAI_API_KEY=${OPENAI_API_KEY}\n", "OPENAI_API_BASE=${OPENAI_API_BASE:-https://api.openai.com/v1}\n", "PROMPT_SIGN_PUBKEY=${PUB}\n", "EOF\n", "\n", "if [ -z \"${OPENAI_API_KEY}\" ]; then\n", "  pip install -q sentencepiece\n", "  python - <<'PY'\n", "from ctransformers import AutoModelForCausalLM\n", "AutoModelForCausalLM.from_pretrained(\n", "  'TheBloke/Mixtral-8x7B-Instruct-GGML',\n", "  model_file='mixtral-8x7b-instruct.ggmlv3.q4_K_M.bin',\n", "  local_files_only=False)\n", "PY\n", "fi"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\ude80 Launch orchestrator (background)"]}, {"cell_type": "code", "metadata": {"id": "launch"}, "source": ["%%bash --bg\n", "cd AGI-Alpha-Agent-v0/alpha_factory_v1\n", "uvicorn backend.orchestrator:app --host 0.0.0.0 --port 8000 &>/dev/null &"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udd17 Expose API with pyngrok"]}, {"cell_type": "code", "metadata": {"id": "ngrok"}, "source": ["from pyngrok import ngrok, conf\n", "conf.get_default().region = 'us'\n", "api = ngrok.connect(8000, 'http')\n", "print('API \u2192', api.public_url)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u2705 Check orchestrator status"]}, {"cell_type": "code", "metadata": {"id": "check"}, "source": ["from alpha_factory_v1.demos.alpha_agi_marketplace_v1 import MarketplaceClient\n", "client = MarketplaceClient()\n", "print('health \u2192', client.health())\n", "print('agents \u2192', client.agents())"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udccb Queue sample job and view memory"]}, {"cell_type": "code", "metadata": {"id": "queue"}, "source": ["from alpha_factory_v1.demos.alpha_agi_marketplace_v1 import MarketplaceClient, SAMPLE_JOB\n", "import time, json\n", "client = MarketplaceClient()\n", "for _ in range(20):\n", "    try:\n", "        if client.health() == 'ok':\n", "            break\n", "    except Exception:\n", "        time.sleep(1)\n", "\n", "job = json.load(open(SAMPLE_JOB))\n", "client.queue_job(job)\n", "time.sleep(2)\n", "print('recent memory \u2192', client.recent_memory(job['agent']))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "### \ud83c\udf89 All set!\n", "Use the API URL above to monitor progress or trigger your own jobs."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 5}
