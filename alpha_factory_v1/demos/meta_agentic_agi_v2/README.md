
# Metaâ€‘AgenticÂ Î±â€‘AGIÂ ğŸ‘ï¸âœ¨Â Demo v2 â€“ **Productionâ€‘GradeÂ v0.1.0**

Identical to **v1** plus a statistical-physics wrapper that logs and minimises **Gibbs / variational free-energy** for each candidate agent during the evolutionary search.

*Metric toggle*: `configs/default.yml â†’ physics_metric: free_energy`  
Implementation: `core/physics/gibbs.py` (â‰ˆ25 LoC) & 4-line hook in `scorer.py`.

> **Official definition â€“ Meta-Agentic (adj.)**  
> *Describes an agent whose **primary role** is to **create, select, evaluate, or reâ€‘configure other agents** and the rules governing their interactions, thereby exercising **secondâ€‘order agency** over a population of firstâ€‘order agents.*

> *The term was **pioneered by Vincent Boucher, President of MONTREAL.AI**.*

```mermaid
%% ğ—šğ—¿ğ—®ğ—»ğ—± ğ—¦ğ˜†ğ—»ğ—®ğ—½ğ˜€ğ—² ğ—šğ—¿ğ—®ğ—½ğ—µ â€“ Meta-Agentic Î±-AGI (v2 with variational free-energy)
graph LR
  %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Class styles
  classDef meta      fill:#6425ff,stroke:#eee,color:#fff
  classDef layer     fill:#1e1e2e,stroke:#ddd,color:#fff
  classDef agent     fill:#0f9d58,stroke:#fff,color:#fff
  classDef tool      fill:#fbbc05,stroke:#000,color:#000
  classDef physics   fill:#ff6d00,stroke:#000,color:#fff

  %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  High-level layers
  A0["ğŸ§  Meta-Programmer"]:::meta
  A1["ğŸ“ˆ Evolution Archive"]:::layer
  A2["âš–ï¸ Multi-Objective Scorer"]:::layer
  AÏ†["â™¾ï¸ Free-Energy Monitor"]:::physics
  A3["ğŸ§© Agent Population"]:::layer

  %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  First-order agents
  subgraph " "
    direction TB
    D1["ğŸ” Researcher"]:::agent
    D2["ğŸ‘· Builder"]:::agent
    D3["ğŸ§ª Evaluator"]:::agent
    D4["âš™ï¸ Auto-Tuner"]:::agent
    D5["ğŸ›¡ Guardian"]:::agent
  end

  %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Foundation-model providers / tools
  subgraph " "
    direction TB
    T1["GPT-4o"]:::tool
    T2["Claude-3"]:::tool
    T3["Llama-3 âˆ"]:::tool
  end

  %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Core data/value loop
  subgraph " "
    direction LR
    V1["ğŸŒ Industry Data Streams"]
    V2["ğŸ’ Extracted Alpha"]
    V3["ğŸš€ Deployed Solutions"]
  end

  %% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Arrows
  A0 -->|generate| A3
  A3 -->|select| A2
  A2 -->|rank| A1
  A1 -- feedback --> A0

  %% Free-energy feedback
  A3 -.state logits.-> AÏ†
  AÏ† -->|F metric| A2
  AÏ† -- entropy gradient --> A0

  %% Providers
  D1 -.uses.-> T1
  D2 -.uses.-> T3
  D3 -.uses.-> T2
  D4 -.uses.-> T3
  D5 -.uses.-> T1

  %% Value extraction
  A3 -->|iterate| V1
  V1 -->|signals| D1
  D2 --> V2
  V2 --> D3
  D4 --> V3
  D5 -.audit.-> V3
```

> **Elevating Alphaâ€‘FactoryÂ v1 into a selfâ€‘improving, crossâ€‘industry â€œAlphaÂ Factoryâ€ that systematically  
> Outâ€‘Learn Â· Outâ€‘Think Â· Outâ€‘Design Â· Outâ€‘Strategize Â· Outâ€‘Execute â€” without coupling to a single vendor or model.**  
> Inspired by and extending the *Metaâ€‘AgentÂ Search* paradigm from Hu *etâ€¯al.*Â (ICLRâ€¯2025).

---

## ğŸ“ŒÂ PurposeÂ &Â Positioning
This demo operationalises the **Automated Designâ€¯ofâ€¯Agenticâ€¯Systems (ADAS)** paradigm and layers:

* **True multiâ€‘objective search** (accuracy, cost, latency, risk, carbon)
* **Openâ€‘weights or APIâ€‘based FM backâ€‘ends** (OpenAI, Anthropic, MistralÂ .gguf â€¦)
* **Automated provenance & lineage visualisation**
* **Antifragile, regulatorâ€‘ready safeguards**

into the existing **Alphaâ€‘FactoryÂ v1** (multiâ€‘agent AGENTICÂ Î±â€‘AGI) pipeline.

---

## 1Â Quickâ€‘startÂ ğŸ
```bash
# 1ï¸âƒ£Â Clone & enter demo
git clone https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git
cd AGI-Alpha-Agent-v0/alpha_factory_v1/demos/meta_agentic_agi_v2

# 2ï¸âƒ£Â Environment (CPUâ€‘only default)
micromamba create -n metaagi python=3.11 -y
micromamba activate metaagi
pip install -r requirements.txt        # â‰¤â€¯40â€¯MiB wheels

# 3ï¸âƒ£Â Run â€“ zeroâ€‘API mode (pulls a gguf via Ollama)
python meta_agentic_agi_demo_v2.py --provider mistral:7b-instruct.gguf

# Â Â â€¦or point to any provider
OPENAI_API_KEY=skâ€‘â€¦ python meta_agentic_agi_demo_v2.py --provider openai:gpt-4o

# 4ï¸âƒ£Â Launch the lineage UI
streamlit run ui/lineage_app.py
```
*No GPU?* llamaâ€‘cppâ€‘python autoâ€‘selects 4â€‘bit quantisation <â€¯6â€¯GBÂ RAM.

### ğŸ“Â Colab notebook

[![OpenÂ InÂ Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MontrealAI/AGI-Alpha-Agent-v0/blob/main/alpha_factory_v1/demos/meta_agentic_agi_v2/colab_meta_agentic_agi_v2.ipynb)

Spin up the demo endâ€‘toâ€‘end without installing anything. Works offline using openâ€‘weights or with your API keys. The notebook now previews the latest lineage entries after the search loop so you can inspect results directly in Colab.

---

## 2Â FolderÂ StructureÂ ğŸ“
```
meta_agentic_agi_v2/
â”œâ”€â”€ core/                # providerâ€‘agnostic primitives
â”‚   â”œâ”€â”€ fm.py            # unified FM wrapper
â”‚   â”œâ”€â”€ prompts.py       # reusable prompt fragments
â”‚   â””â”€â”€ tools.py         # exec sandbox, RAG, vector store
â”œâ”€â”€ meta_agentic_search/ # â¬… evolutionary loop
â”‚   â”œâ”€â”€ archive.py       # steppingâ€‘stone JSONL log
â”‚   â”œâ”€â”€ search.py        # NSGAâ€‘II + Reflexion
â”‚   â””â”€â”€ scorer.py        # multiâ€‘objective metrics
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ agent_base.py    # runtime interface
â”‚   â””â”€â”€ seeds.py         # bootstrap population
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ lineage_app.py   # Streamlit dashboard
â”‚   â””â”€â”€ assets/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default.yml      # editable inâ€‘UI
â””â”€â”€ meta_agentic_agi_demo_v2.py
```

---

## 3Â Highâ€‘LevelÂ ArchitectureÂ ğŸ”
```mermaid
graph TD
  subgraph "MetaÂ AgentÂ SearchÂ Loop"
    MGPT["MetaÂ LLMÂ Programmer"]
    Candidate["CandidateÂ Agent<br/>PythonÂ fn"]
    Evaluator["SandboxedÂ Evaluator"]
    Archive["Archive<br/>(ParetoÂ +Â Novelty)"]
    MGPT -->|generates| Candidate
    Candidate --> Evaluator
    Evaluator -->|scores| Archive
    Archive -->|contextÂ &Â feedback| MGPT
  end
  UI["StreamlitÂ LineageÂ UI"] <-->|stream
lineage| Archive
```

```mermaid
flowchart LR
  AFV1["Alphaâ€‘FactoryÂ v1Â Core"]
  MAA["Metaâ€‘AgenticÂ Layer"]
  Providers["FMÂ Providers<br/>(OpenAIÂ /Â AnthropicÂ /Â llamaâ€‘cpp)"]
  Dataset["DomainÂ Datasets"]
  UI2["LineageÂ UI"]
  AFV1 --> MAA
  MAA --> Providers
  MAA --> Dataset
  Archive -.-> UI2
```

---

## 4Â ProviderÂ AbstractionÂ â¡ï¸Â openâ€‘weightsÂ ğŸ‹ï¸â€â™€ï¸
`configs/default.yml` (excerpt):
```yaml
provider: mistral:7b-instruct.gguf   # any ollama / llama.cpp id
context_length: 8192
rate_limit_tps: 4
retry_backoff: 2
```

Change **provider** to:

| Value                       | Notes                      |
|-----------------------------|----------------------------|
| `openai:gpt-4o`             | needs `OPENAI_API_KEY`     |
| `anthropic:claude-3-sonnet` | needs `ANTHROPIC_API_KEY`  |
| `mistral:7b-instruct.gguf`  | default local model        |

Wrapper normalises chat/completions, streams via **MCP**, and windowâ€‘slides tokens.

---

## 5Â Multiâ€‘ObjectiveÂ SearchÂ ğŸ¯
*Objective vector*Â =Â **[accuracy, cost, latency, hallucinationâ€‘risk, carbon]**

* NSGAâ€‘II elitist selection  
* Behaviour descriptor = SHAâ€‘256 of candidate AST  
* Optional humanâ€‘inâ€‘theâ€‘loop thumbs up/down (UI)

---

## 6Â SecurityÂ &Â AntifragilityÂ ğŸ›¡
* FirejailÂ `--seccomp` + 512â€¯MiB memâ€‘cgroup sandbox  
* Static analysis (`bandit`) + dynamic taint tracking  
* Live watchdog kills rogue processesÂ >â€¯30â€¯s CPU  
* Chaosâ€‘tests inject tool failures; reward graceful degradation

---

## 7Â ExtendingÂ ğŸ› 
1. **New dataset** â€“ drop `my.pkl` into `data/`, flag `--dataset my`.  
2. **New metric** â€“ subclass `scorer.BaseMetric`, list in `configs/default.yml`.  
3. **New tool** â€“ add `core/tools/foo.py` exposing `__call__(self, query)`.

---

## 8Â RoadmapÂ ğŸ—º
* â˜ Hierarchical metaâ€‘meta search  
* â˜ GPU batch infer (Flashâ€‘inferÂ v3)  
* â˜ Offline RL fineâ€‘tune search policy with lineage replay

---

## 9Â ReferencesÂ ğŸ“š
* S.â€¯HuÂ *etâ€¯al.* â€œAutomated Design of Agentic Systemsâ€Â ICLRâ€¯2025  
* OpenAI â€œA Practical Guide to BuildingÂ Agentsâ€Â (2024)  
* Google ADK docsÂ (2025)

---

Â©Â 2025Â MONTREAL.AI â€” Apacheâ€‘2.0
