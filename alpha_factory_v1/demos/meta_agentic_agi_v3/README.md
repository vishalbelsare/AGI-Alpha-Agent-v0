# Metaâ€‘AgenticÂ Î±â€‘AGIÂ ğŸ‘ï¸âœ¨Â DemoÂ v3Â â€” **AZRâ€‘PoweredÂ Productionâ€‘GradeÂ v0.2.0**

Identical to **v1** plus **two synergistic upgrades**  
1. *Statisticalâ€‘physics wrapper* â€” logs & minimises **Gibbs / variational freeâ€‘energy** for every candidate agent.  
2. *AbsoluteÂ Zero Reasoner (AZR) selfâ€‘curriculum* â€” a **reinforced selfâ€‘play engine** that perpetually invents and solves its own tasks, unlocking *openâ€‘ended* crossâ€‘domain reasoning.

> **Official definitionÂ â€” Metaâ€‘Agentic (adj.)**  
> *Describes an agent whose **primary role** is to **create, select, evaluate, or reâ€‘configure other agents** and the rules governing their interactions, thereby exercising **secondâ€‘order agency** over a population of firstâ€‘order agents.*  
> *The term was **pioneered by VincentÂ Boucher, PresidentÂ ofÂ MONTREAL.AI**.*

---

## ğŸš€Â Why AZR Matters
`AbsoluteÂ Zero Reasoner` (ZhaoÂ *etâ€¯al.*Â 2025) discards the last human bottleneck: **task curation**.  
It **proposes**, **validates**, **solves**, and **learns from** its own codeâ€‘reasoning problems â€” then feeds the distilled knowledge back into the evolutionary loop.  
*Result:* steeper learning curves, bolder exploration, and broad generalisation across math, code, and strategic planning â€” all while remaining vendorâ€‘agnostic.

---

mermaid
%% ğ—šğ—¿ğ—®ğ—»ğ—±Â ğ—¦ğ˜†ğ—»ğ—®ğ—½ğ˜€ğ—²Â ğ—šğ—¿ğ—®ğ—½ğ—µ â€“ Metaâ€‘AgenticÂ Î±â€‘AGIÂ (v3Â AZRâ€‘powered)
graph LR
  classDef meta       fill:#6425ff,stroke:#eee,color:#fff
  classDef layer      fill:#1e1e2e,stroke:#ddd,color:#fff
  classDef agent      fill:#0f9d58,stroke:#fff,color:#fff
  classDef tool       fill:#fbbc05,stroke:#000,color:#000
  classDef physics    fill:#ff6d00,stroke:#000,color:#fff
  classDef curriculum fill:#d81b60,stroke:#eee,color:#fff

  A0["ğŸ§  Metaâ€‘Programmer"]:::meta
  A1["ğŸ“ˆ Evolution Archive"]:::layer
  A2["âš–ï¸ Multiâ€‘ObjectiveÂ Scorer"]:::layer
  AÏ†["â™¾ï¸ Freeâ€‘EnergyÂ Monitor"]:::physics
  AZ["ğŸ§® AZRÂ Selfâ€‘CurriculumÂ Engine"]:::curriculum
  A3["ğŸ§© AgentÂ Population"]:::layer

  subgraph " "
    direction TB
    D1["ğŸ” Researcher"]:::agent
    D2["ğŸ‘· Builder"]:::agent
    D3["ğŸ§ª Evaluator"]:::agent
    D4["âš™ï¸ Autoâ€‘Tuner"]:::agent
    D5["ğŸ›¡ Guardian"]:::agent
  end

  subgraph " "
    direction TB
    T1["GPTâ€‘4o"]:::tool
    T2["Claudeâ€‘3"]:::tool
    T3["Llamaâ€‘3Â âˆ"]:::tool
  end

  subgraph " "
    direction LR
    V1["ğŸŒ IndustryÂ DataÂ Streams"]
    V2["ğŸ’ ExtractedÂ Alpha"]
    V3["ğŸš€ DeployedÂ Solutions"]
  end

  %% controlâ€‘flow
  A0 -->|spawn| A3
  A0 -->|bootstrap tasks| AZ
  AZ -->|inventÂ curricula| A3
  A3 -->|solver traces| AZ
  A3 -->|select| A2
  A2 -->|rank| A1
  A1 -- feedback --> A0

  %% freeâ€‘energy link
  A3 -.state logits.-> AÏ†
  AÏ† -->|Fâ€‘metric| A2
  AÏ† -- entropy grad --> A0
  AZ -- expectedâ€‘learningâ€‘gain --> AÏ†

  %% providers
  D1 -.uses.-> T1
  D2 -.uses.-> T3
  D3 -.uses.-> T2
  D4 -.uses.-> T3
  D5 -.uses.-> T1

  %% value loop
  A3 -->|iterate| V1
  V1 -->|signals| D1
  D2 --> V2
  V2 --> D3
  D4 --> V3
  D5 -.audit.-> V3

---

## ğŸ“ŒÂ PurposeÂ &Â Positioning
This demo operationalises **Automatedâ€¯Designâ€¯ofâ€¯Agenticâ€¯SystemsÂ (ADAS)** and adds:

* **AZRâ€‘driven openâ€‘ended learning** â€” tasks invented onâ€‘theâ€‘fly, tuned for maximal learning gain.
* **True multiâ€‘objective optimisation** â€” accuracy, cost, latency, risk, carbon **& freeâ€‘energy**.
* **Openâ€‘weights *or* API FMs** â€” swap GPTâ€‘4o, Claudeâ€‘3, Llamaâ€‘3, MistralÂ .gguf at will.
* **Provable lineage & provenance** â€” every agent / artefact traceable via the Lineage UI.
* **Battleâ€‘tested safeguards** â€” sandboxing, taintâ€‘tracking, chaosâ€‘testing.

Together, they lift **Alphaâ€‘FactoryÂ v1** into a *selfâ€‘improving*, crossâ€‘industry **Alpha Factory** that systematically  
> **Outâ€‘Learn Â· Outâ€‘Think Â· Outâ€‘Design Â· Outâ€‘Strategize Â· Outâ€‘Execute**  

â€” with zero dependence on any single model or vendor.

---

## 1Â Quickâ€‘startÂ ğŸ

```bash
# 1ï¸âƒ£Â Clone & enter
git clone https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git
cd AGI-Alpha-Agent-v0/alpha_factory_v1/demos/meta_agentic_agi_v3

# 2ï¸âƒ£Â Environment (CPUâ€‘only default)
micromamba create -n metaagi python=3.11 -y
micromamba activate metaagi
pip install -r requirements.txt   # â‰¤â€¯40â€¯MiB wheels

# 3ï¸âƒ£Â Run â€“ zeroâ€‘API mode (pulls a gguf via Ollama)
python meta_agentic_agi_demo.py --provider mistral:7b-instruct.gguf

# Â Â â€¦or point to any provider
OPENAI_API_KEY=skâ€‘â€¦ python meta_agentic_agi_demo.py --provider openai:gpt-4o

# 4ï¸âƒ£Â Launch the lineage UI
streamlit run ui/lineage_app.py
```

*Tip:* `llamaâ€‘cppâ€‘python` autoâ€‘quantises to 4â€‘bit; <â€¯6â€¯GBÂ RAM is enough.

---

## 2Â FolderÂ StructureÂ ğŸ“
```
meta_agentic_agi/
â”œâ”€â”€ core/                # providerâ€‘agnostic primitives
â”‚   â”œâ”€â”€ fm.py            # unified FM wrapper
â”‚   â”œâ”€â”€ prompts.py       # reusable prompt fragments
â”‚   â””â”€â”€ tools.py         # exec sandbox, RAG, vector store
â”œâ”€â”€ meta_agentic_search/ # â¬… evolutionary loop
â”‚   â”œâ”€â”€ archive.py       # steppingâ€‘stone JSONL log
â”‚   â”œâ”€â”€ search.py        # NSGAâ€‘II + Reflexion
â”‚   â””â”€â”€ scorer.py        # multiâ€‘objective metrics (+ freeâ€‘energy)
â”œâ”€â”€ azr/                 # â¬… Absolute Zero Reasoner
â”‚   â”œâ”€â”€ proposer.py      # task invention
â”‚   â”œâ”€â”€ solver.py        # task execution
â”‚   â”œâ”€â”€ buffers.py       # triplet storage
â”‚   â””â”€â”€ rewards.py       # learnability & accuracy
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ agent_base.py    # runtime interface
â”‚   â””â”€â”€ seeds.py         # bootstrap population
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ lineage_app.py   # Streamlit dashboard
â”‚   â””â”€â”€ assets/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default.yml      # editable inâ€‘UI
â””â”€â”€ meta_agentic_agi_demo.py
```

---

## 3Â ProviderÂ AbstractionÂ â¡ï¸Â openâ€‘weightsÂ ğŸ‹ï¸â€â™€ï¸
`configs/default.yml` excerpt:
```yaml
provider: mistral:7b-instruct.gguf   # any ollama / llama.cpp id
context_length: 8192
rate_limit_tps: 4
retry_backoff: 2
```

Change **provider** to:

| Value                       | Notes                    |
|-----------------------------|--------------------------|
| openai:gpt-4o               | needs `OPENAI_API_KEY`   |
| anthropic:claude-3-sonnet   | needs `ANTHROPIC_API_KEY`|
| mistral:7b-instruct.gguf    | default local model      |

Wrapper normalises chat/completions, streams via **MCP**, and windowâ€‘slides tokens.

---

## 4Â AZRÂ Selfâ€‘CurriculumÂ ğŸ’
*Task space:* deterministic Python triplets **(programÂ p, inputÂ i, outputÂ o)**  
*Modes:* **abduction**Â (`infer i`), **deduction**Â (`infer o`), **induction**Â (`synthesise p`)  

AZR jointly trains **proposer** & **solver** roles with **Taskâ€‘RelativeÂ REINFORCE++**.  
Learnability reward peaks when tasks are â€œjustâ€‘hardâ€‘enoughâ€, driving an *automatic syllabus* that adapts as agents improve.

---

## 5Â Multiâ€‘ObjectiveÂ SearchÂ ğŸ¯
Objective vector â†’ **[accuracy, cost, latency, hallucinationâ€‘risk, carbon, freeâ€‘energy]**

* NSGAâ€‘II elitist selection  
* Behaviour descriptorÂ =Â SHAâ€‘256 of candidate AST  
* Optional humanâ€‘inâ€‘theâ€‘loop thumbsÂ â†‘/â†“  

---

## 6Â SecurityÂ &Â AntifragilityÂ ğŸ›¡
* FirejailÂ `--seccomp` + 512â€¯MiB memâ€‘cgroup sandbox  
* Static analysis (`bandit`) + dynamic taint tracking  
* Live watchdog kills rogue processesâ€¯>â€¯30â€¯s CPU  
* Chaosâ€‘tests inject tool failures; reward graceful degradation  
* Curriculum pruning autoâ€‘drops unsafe proposals.

---

## 7Â ExtendingÂ ğŸ› 
1. **New dataset**Â â€” drop `my.pkl` into `data/`, run `--dataset my`.  
2. **New metric**Â â€” subclass `scorer.BaseMetric`, list in `configs/default.yml`.  
3. **New AZR reward**Â â€” edit `azr/rewards.py`, plug into `buffers.py`.

---

## 8Â RoadmapÂ ğŸ—º
* â˜ Hierarchical metaâ€‘meta search  
* â˜ GPU batch infer (Flashâ€‘inferÂ v3)  
* â˜ Offline RL fineâ€‘tune search policy with lineage replay  
* â˜ Multimodal AZR (image â†” code â†” math)  

---

## 9Â ReferencesÂ ğŸ“š
* A.â€¯ZhaoÂ *etâ€¯al.* â€œAbsoluteÂ Zero: Reinforced Selfâ€‘play Reasoning with Zero Dataâ€Â arXivÂ 2025  
* S.â€¯HuÂ *etâ€¯al.* â€œAutomatedâ€¯Designâ€¯ofâ€¯Agenticâ€¯Systemsâ€Â ICLRâ€¯2025  
* OpenAI â€œA Practical Guide to BuildingÂ Agentsâ€Â (2024)  
* Google ADK docsÂ (2025)

---

Â©Â 2025Â MONTREAL.AI â€” Apacheâ€‘2.0
