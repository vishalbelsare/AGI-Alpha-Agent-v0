{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "This notebook is a conceptual research prototype. References to ‚ÄòAGI‚Äô or ‚Äòsuperintelligence‚Äô describe aspirational goals and do not indicate the presence of real general intelligence. Use at your own risk.\n\n# üëÅÔ∏è‚Äçüó®Ô∏è Alpha-Factory v1 ‚Äì Cross-Industry AGENTIC Œ±-AGI  \n## _(Google Colab, self-contained)_\n\n**What you get in < 10 minutes**\n\n* ü™Ñ Five domain agents (finance, biotech, climate, mfg, policy) orchestrated by `backend/orchestrator.py`\n* üèã Continual PPO trainer self-improves agents\n* üîê Guard-rails (MCP), ed25519 prompt signing, policy deny-list\n* üìä Prometheus **9090** & Grafana **3000** exposed through public *ngrok* URLs\n* ‚ö° 30-second k6 load-test to prove antifragility\n* üì¥ Works offline (Mixtral-8√ó7B GGML) or online (OpenAI key)\n\n> **Paste an `OPENAI_API_KEY` below for better quality,** or leave blank to run fully offline.\nThe script will also generate a random `API_TOKEN` in `.env` for authenticated requests."
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "env"
      },
      "source": [
        "OPENAI_API_KEY = \"\"  # ‚Üê üîë  put your key here or leave empty"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional offline mode\n",
        "\n",
        "Download a `.gguf` weight and set `LLAMA_MODEL_PATH` before running the setup cell. `llama-cpp-python` or `ctransformers` must be installed for local inference:\n",
        "\n",
        "```bash\n",
        "pip install openai-agents llama-cpp-python ctransformers\n",
        "```\n",
        "\n",
        "Example weights and rough CPU throughput:\n",
        "\n",
        "| Model | Size | ~tokens/s |\n",
        "|-------|------|-----------|\n",
        "| TinyLlama-1.1B-Chat Q4_K_M | 380 MB | ~20 |\n",
        "| Llama-3-8B-Instruct Q4_K_M | 4 GB | ~5 |\n",
        "| Mixtral-8x7B-Instruct Q4_0 | 7 GB | ~3 |\n",
        "\n",
        "When `LLAMA_MODEL_PATH` is defined the orchestrator loads the weight instead of calling OpenAI.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01-setup"
      },
      "source": [
        "%%bash",
        "if [ ! -d AGI-Alpha-Agent-v0 ]; then",
        "  git clone --depth 1 https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git",
        "fi",
        "cd AGI-Alpha-Agent-v0",
        "pip install -q -r alpha_factory_v1/requirements-colab.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Offline wheelhouse install\n",
        "Mount a Google Drive folder (or local path) containing pre-built wheels and install packages with `pip --no-index --find-links <wheelhouse>`. The definitive package list is in `alpha_factory_v1/requirements-colab.lock`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "wheelhouse = '/content/drive/MyDrive/wheelhouse'  # or any local path\n",
        "!pip install --no-index --find-links $wheelhouse -r AGI-Alpha-Agent-v0/alpha_factory_v1/requirements-colab.lock\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Patch orchestrator: add `/update_model` hot-reload endpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02-patch"
      },
      "source": [
        "%%bash\n",
        "apply_patch() {\n",
        "python - <<'PY'\n",
        "import importlib, textwrap, pathlib, inspect\n",
        "src = pathlib.Path('AGI-Alpha-Agent-v0/alpha_factory_v1/backend/orchestrator.py')\n",
        "code = src.read_text()\n",
        "if 'update_model' in code:\n",
        "    print('‚úÖ update_model already present'); raise SystemExit\n",
        "insertion = textwrap.dedent('''\\n@router.post(\"/agent/{agent_id}/update_model\")\\nasync def update_model(agent_id: str, file: bytes = File(...)):\\n    if agent_id not in AGENT_REGISTRY:\\n        raise HTTPException(status_code=404, detail=\"agent not found\")\\n    import tempfile, zipfile, io\\n    with tempfile.TemporaryDirectory() as td:\\n        zf = zipfile.ZipFile(io.BytesIO(file)); zf.extractall(td)\\n        AGENT_REGISTRY[agent_id].load_weights(td)\\n    return {\"status\":\"ok\"}\\n''')\n",
        "marker = '# === ROUTES ==='\n",
        "idx = code.index(marker) + len(marker)\n",
        "new_code = code[:idx] + insertion + code[idx:]\n",
        "src.write_text(new_code)\n",
        "print('üöÄ patched orchestrator with hot-reload endpoint')\n",
        "PY\n",
        "}\n",
        "apply_patch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Launch orchestrator, agents, Ray & mock adapters (background)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03-launch"
      },
      "source": [
        "%%bash --bg\n",
        "cd AGI-Alpha-Agent-v0/alpha_factory_v1\n",
        "ray start --head --dashboard-host 0.0.0.0 --port 6379 --dashboard-port 8265 &>/dev/null &\n",
        "uvicorn backend.orchestrator:app --host 0.0.0.0 --port 8000 &>/dev/null &\n",
        "\n",
        "# tiny PubMed & Carbon adapters\n",
        "python - <<'PY' &>/dev/null &\n",
        "from fastapi import FastAPI; import uvicorn, random\n",
        "app=FastAPI(); @app.get('/')\n",
        "def root(): return {\"msg\":\"ok\"}\n",
        "uvicorn.run(app,host='0.0.0.0',port=8005)\n",
        "PY\n",
        "python - <<'PY' &>/dev/null &\n",
        "from fastapi import FastAPI; import uvicorn\n",
        "app=FastAPI(); @app.get('/co2')\n",
        "def co2(): return {\"ppm\":420.42}\n",
        "uvicorn.run(app,host='0.0.0.0',port=8010)\n",
        "PY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîó Expose Grafana & Prometheus with `pyngrok`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04-ngrok"
      },
      "source": [
        "from pyngrok import ngrok, conf\n",
        "conf.get_default().region = 'us'\n",
        "import os\n",
        "port = int(os.getenv('DASH_PORT', 9000))\n",
        "grafana = ngrok.connect(port, 'http'); prom = ngrok.connect(9090, 'http')\n",
        "print('Grafana  ‚Üí', grafana.public_url)\n",
        "print('Prometheus ‚Üí', prom.public_url)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèãÔ∏è Quick k6 load-test (20 VUs √ó 30 s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05-k6"
      },
      "source": [
        "%%bash\nset -euo pipefail\n",
        "cat > k6.js <<'JS'\n",
        "import http from 'k6/http'; import {sleep} from 'k6';\n",
        "export let options = {vus:20,duration:'30s'};\n",
        "const A=['finance_agent','biotech_agent','climate_agent','manufacturing_agent','policy_agent'];\n",
        "export default function(){\n",
        "  const a=A[Math.floor(Math.random()*A.length)];\n",
        "  http.post(`http://127.0.0.1:8000/agent/${a}/skill_test`,JSON.stringify({ping:Math.random()}),{headers:{'Content-Type':'application/json'}});\n",
        "  sleep(0.05);\n",
        "}\n",
        "JS\n",
        "k6 run k6.js"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ôªÔ∏è Continuous PPO trainer (runs async)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06-trainer"
      },
      "source": [
        "%%bash --bg\n",
        "python AGI-Alpha-Agent-v0/alpha_factory_v1/continual/ppo_trainer.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Smoke-probe orchestrator + sample agent call"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07-health"
      },
      "source": [
        "import requests, time, pprint, json, os\n",
        "for _ in range(20):\n",
        "  try:\n",
        "    if requests.get('http://127.0.0.1:8000/healthz').status_code==200:\n",
        "      print('orchestrator healthy'); break\n",
        "  except: pass; time.sleep(2)\n",
        "resp=requests.post('http://127.0.0.1:8000/agent/finance_agent/skill_test',json={'ping':123}).json()\n",
        "pprint.pp(resp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### üéâ All set!\n",
        "\n",
        "* Use the **Grafana** link above (`admin / admin`) to explore dashboards (import JSON if blank)\n",
        "* Rewards tune automatically; edit `rubric.json` in `continual/` and rerun the trainer cell\n",
        "* Adapt this notebook to plug in your own domain adapters or extra agents\n",
        "* When finished, run `docker compose down -v` (or `./teardown_alpha_factory_cross_industry_demo.sh`) to clean up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Troubleshooting",
        "",
        "The demo typically completes setup in under 10 minutes. A code cell prints the detected GPU via `nvidia-smi -L` and falls back to the CPU when no GPU is present.",
        "Long waits often indicate missing GPU acceleration or network stalls."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
