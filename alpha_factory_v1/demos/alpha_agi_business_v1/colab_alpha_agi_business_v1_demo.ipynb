{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Alpha-AGI Business v1 ðŸ‘€âœ¨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the introductory **Alpha-Factory** business demo. Works offline\\nor upgrades automatically when `OPENAI_API_KEY` is set.\\n",
        "\\nThis notebook verifies requirements using `check_env.py --auto-install` and reads configuration from `config.env` (auto-created from the sample)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0 Â· Runtime check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi -L || echo 'GPU not detected - running on CPU'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1 Â· Clone repo & install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash",
        "set -e",
        "if [ ! -d AGI-Alpha-Agent-v0 ]; then",
        "  git clone --depth 1 https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git",
        "fi",
        "cp alpha_factory_v1/demos/alpha_agi_business_v1/config.env.sample alpha_factory_v1/demos/alpha_agi_business_v1/config.env 2>/dev/null || true",
        "cd AGI-Alpha-Agent-v0",
        "pip -q install openai_agents fastapi uvicorn gradio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('AGI-Alpha-Agent-v0')\n",
        "import check_env\n",
        "try:\n",
        "    check_env.main(['--auto-install'])\n",
        "except Exception as e:\n",
        "    print('Error: Environment check or dependency installation failed.')\n",
        "    print(f'Details: {e}')\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2 Â· (Optional) Configure your OpenAI API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, getpass\nos.environ['OPENAI_API_KEY'] = getpass.getpass('Enter OpenAI API key (leave blank for offline): ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (Optional) Live market price feed",
        "Set `YFINANCE_SYMBOL` to fetch a current closing price using `yfinance`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\nos.environ['YFINANCE_SYMBOL'] = os.getenv('YFINANCE_SYMBOL', 'SPY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3 Â· Launch orchestrator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess, threading, sys, time, requests\n",
        "from IPython.display import display, IFrame\n",
        "\n",
        "root = 'AGI-Alpha-Agent-v0/alpha_factory_v1/demos/alpha_agi_business_v1'\n",
        "proc = subprocess.Popen([sys.executable, 'start_alpha_business.py', '--no-browser'],\n",
        "                        cwd=root, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
        "\n",
        "def _tail():\n",
        "    for line in proc.stdout:\n",
        "        print(line, end='')\n",
        "\n",
        "threading.Thread(target=_tail, daemon=True).start()\n",
        "\n",
        "for _ in range(40):\n",
        "    try:\n",
        "        if requests.get('http://localhost:8000/healthz').status_code == 200:\n",
        "            break\n",
        "    except Exception:\n",
        "        time.sleep(0.2)\n",
        "\n",
        "display(IFrame(src='http://localhost:8000/docs', width='100%', height=600))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4 Â· Programmatic API call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\nprint('Available agents:', requests.get('http://localhost:8000/agents').json())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4b Â· Trigger Execution Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\nrequests.post('http://localhost:8000/agent/alpha_execution/trigger')\nprint('execution triggered')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5 Â· OpenAI Agents bridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash",
        "ALPHA_FACTORY_ENABLE_ADK=true python openai_agents_bridge.py --wait-secs 15 >/tmp/bridge.log 2>&1 &",
        "sleep 2",
        "tail -n 5 /tmp/bridge.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5b Â· Interactive Gradio dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\npython gradio_dashboard.py >/tmp/gradio.log 2>&1 &\nsleep 2\ntail -n 5 /tmp/gradio.log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import IFrame\nIFrame(src='http://localhost:7860', width='100%', height=480)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5bb Â· ADK gateway (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import IFrame",
        "IFrame(src=\"http://localhost:9000/docs\", width=\"100%\", height=320)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5c Â· Query recent alpha via OpenAI Agents bridge\n",
        "import requests\n",
        "resp = requests.post('http://localhost:5001/v1/agents/business_helper/invoke', json={'action':'recent_alpha'})\n",
        "if resp.status_code == 200:\n",
        "    try:\n",
        "        print('recent alpha:', resp.json())\n",
        "    except ValueError as e:\n",
        "        print('Error decoding JSON response:', e)\n",
        "else:\n",
        "    print(f'Error: Received status code {resp.status_code} with response: {resp.text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5cc Â· Trigger risk assessment via OpenAI Agents bridge\n",
        "import requests\n",
        "resp = requests.post('http://localhost:5001/v1/agents/business_helper/invoke', json={'action':'risk'})\n",
        "print('risk response:', resp.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5d Â· Submit a custom job via the bridge\n",
        "job = {'agent': 'alpha_execution', 'symbol': 'AAPL', 'qty': 1}\n",
        "resp = requests.post('http://localhost:5001/v1/agents/business_helper/invoke', json={'action':'submit_job', 'job': job})\n",
        "print('job submission:', resp.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5e Â· Search memory via the bridge\n",
        "import requests\n",
        "resp = requests.post('http://localhost:5001/v1/agents/business_helper/invoke', json={'action':'search_memory', 'query':'supply chain', 'limit': 3})\n",
        "print('memory search:', resp.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6 Â· Graceful shutdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "proc.terminate(); print('âœ… Orchestrator stopped')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
