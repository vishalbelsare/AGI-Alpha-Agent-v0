{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "This notebook is a conceptual research prototype. References to \u2018AGI\u2019 or \u2018superintelligence\u2019 describe aspirational goals and do not indicate the presence of real general intelligence. Use at your own risk."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha-AGI Business v1 \ud83d\udc40\u2728"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the introductory **Alpha-Factory** business demo. Works offline",
    "or upgrades automatically when `OPENAI_API_KEY` is set.",
    "",
    "This notebook verifies requirements using `check_env.py --auto-install` and reads configuration from `config.env` (auto-created from the sample).",
    "",
    "If you're on a restricted machine, build a wheelhouse with:",
    "```bash",
    "pip wheel -r requirements.txt -w /media/wheels",
    "pip wheel -r requirements-dev.txt -w /media/wheels",
    "```",
    "Then pass the path when running `check_env.py`:",
    "```bash",
    "python check_env.py --auto-install --wheelhouse /media/wheels",
    "```",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "When network access is unavailable, set `WHEELHOUSE` to your wheel cache and install dependencies from there:\n```bash\nWHEELHOUSE=/media/wheels pip install --no-index --find-links \"$WHEELHOUSE\" -r requirements.txt\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 \u00b7 Runtime check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi -L || echo 'GPU not detected - running on CPU'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 \u00b7 Clone repo & install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash",
    "set -e",
    "if [ ! -d AGI-Alpha-Agent-v0 ]; then",
    "  git clone --depth 1 https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git",
    "fi",
    "cp alpha_factory_v1/demos/alpha_agi_business_v1/config.env.sample alpha_factory_v1/demos/alpha_agi_business_v1/config.env 2>/dev/null || true",
    "cd AGI-Alpha-Agent-v0",
    "pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('AGI-Alpha-Agent-v0')\n",
    "import check_env\n",
    "try:\n",
    "    check_env.main(['--auto-install'])\n",
    "except Exception as e:\n",
    "    print('Error: Environment check or dependency installation failed.')\n",
    "    print(f'Details: {e}')\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 \u00b7 (Optional) Configure your OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\nos.environ['OPENAI_API_KEY'] = getpass.getpass('Enter OpenAI API key (leave blank for offline): ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Live market price feed",
    "Set `YFINANCE_SYMBOL` to fetch a current closing price using `yfinance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\nos.environ['YFINANCE_SYMBOL'] = os.getenv('YFINANCE_SYMBOL', 'SPY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 \u00b7 Launch orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, threading, sys, time, requests\n",
    "from IPython.display import display, IFrame\n",
    "\n",
    "root = 'AGI-Alpha-Agent-v0/alpha_factory_v1/demos/alpha_agi_business_v1'\n",
    "proc = subprocess.Popen([sys.executable, 'start_alpha_business.py', '--no-browser'],\n",
    "                        cwd=root, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
    "\n",
    "def _tail():\n",
    "    for line in proc.stdout:\n",
    "        print(line, end='')\n",
    "\n",
    "threading.Thread(target=_tail, daemon=True).start()\n",
    "\n",
    "for _ in range(40):\n",
    "    try:\n",
    "        if requests.get('http://localhost:8000/healthz').status_code == 200:\n",
    "            break\n",
    "    except Exception:\n",
    "        time.sleep(0.2)\n",
    "\n",
    "display(IFrame(src='http://localhost:8000/docs', width='100%', height=600))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 \u00b7 Programmatic API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\nprint('Available agents:', requests.get('http://localhost:8000/agents').json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b \u00b7 Trigger Execution Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\nrequests.post('http://localhost:8000/agent/alpha_execution/trigger')\nprint('execution triggered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 \u00b7 OpenAI Agents bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash",
    "ALPHA_FACTORY_ENABLE_ADK=true python openai_agents_bridge.py --wait-secs 15 >/tmp/bridge.log 2>&1 &",
    "sleep 2",
    "tail -n 5 /tmp/bridge.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5b \u00b7 Interactive Gradio dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\npython gradio_dashboard.py >/tmp/gradio.log 2>&1 &\nsleep 2\ntail -n 5 /tmp/gradio.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\nIFrame(src='http://localhost:7860', width='100%', height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5bb \u00b7 ADK gateway (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame",
    "IFrame(src=\"http://localhost:9000/docs\", width=\"100%\", height=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5c \u00b7 Query recent alpha via OpenAI Agents bridge\n",
    "import requests\n",
    "resp = requests.post('http://localhost:5001/v1/agents/business_helper/invoke', json={'action':'recent_alpha'})\n",
    "if resp.status_code == 200:\n",
    "    try:\n",
    "        print('recent alpha:', resp.json())\n",
    "    except ValueError as e:\n",
    "        print('Error decoding JSON response:', e)\n",
    "else:\n",
    "    print(f'Error: Received status code {resp.status_code} with response: {resp.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5cc \u00b7 Trigger risk assessment via OpenAI Agents bridge\n",
    "import requests\n",
    "resp = requests.post('http://localhost:5001/v1/agents/business_helper/invoke', json={'action':'risk'})\n",
    "print('risk response:', resp.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5d \u00b7 Submit a custom job via the bridge\n",
    "job = {'agent': 'alpha_execution', 'symbol': 'AAPL', 'qty': 1}\n",
    "resp = requests.post('http://localhost:5001/v1/agents/business_helper/invoke', json={'action':'submit_job', 'job': job})\n",
    "print('job submission:', resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5e \u00b7 Search memory via the bridge\n",
    "import requests\n",
    "resp = requests.post('http://localhost:5001/v1/agents/business_helper/invoke', json={'action':'search_memory', 'query':'supply chain', 'limit': 3})\n",
    "print('memory search:', resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5f \u00b7 Fetch orchestrator logs via the bridge\n",
    "import requests\n",
    "resp = requests.post('http://localhost:5001/v1/agents/business_helper/invoke', json={'action':'fetch_logs'})\n",
    "print('logs:', resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 \u00b7 Graceful shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc.terminate(); print('\u2705 Orchestrator stopped')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
