# Metaâ€‘AgenticÂ Î±â€‘AGIÂ ğŸ‘ï¸âœ¨Â Demo â€“ **Productionâ€‘Grade v0.1.0**

---

## ğŸ“ŒÂ Purpose & Positioning

This demo extends **Alphaâ€‘FactoryÂ v1** into a *selfâ€‘improving*, crossâ€‘industry â€œAlpha Factoryâ€ able to **Outâ€‘Learn Â· Outâ€‘Think Â· Outâ€‘Design Â· Outâ€‘Strategize Â· Outâ€‘Execute** â€” *without hardâ€‘wiring a single vendor or model*.

It operationalises the **Automated Designâ€¯ofâ€¯Agenticâ€¯Systems** paradigm from HuÂ *etâ€¯al.*Â ICLRâ€‘25 and layers true **multiâ€‘objective search**, openâ€‘weights support, automated lineage documentation, and antifragile safeguards on top of the existing Î±â€‘Factory.

> **Goal:** Provide a **completely deployable, auditedâ€‘byâ€‘design reference stack** that a nonâ€‘technical stakeholder can run on a laptop *or* scale up in Kubernetes, then immediately surface alphaâ€‘grade opportunities in any vertical.

---

## 1Â Quickâ€‘start ğŸ

```bash
# â¶Â Clone Alphaâ€‘Factory v1 and enter demo folder
$ git clone https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git
$ cd AGI-Alpha-Agent-v0/alpha_factory_v1/demos/meta_agentic_agi

# â·Â Create & activate env
$ micromamba create -n metaagi python=3.11 -y
$ micromamba activate metaagi
$ pip install -r requirements.txt          # â†“ pureâ€‘Python, CPUâ€‘only default

# â¸Â Run in ğŸ—²Â zeroâ€‘API mode (openâ€‘weights) â€“ pulls a gguf model via Ollama
$ python meta_agentic_agi_demo.py --provider mistral:7b-instruct.gguf

# Â â€¦or plug any provider (OpenAI, Anthropic, LMâ€‘Studioâ€‘local)
$ OPENAI_API_KEY=skâ€‘â€¦ python meta_agentic_agi_demo.py --provider openai:gpt-4o

# â¹Â Launch visual lineage UI
$ streamlit run ui/lineage_app.py           # http://localhost:8501
```

No GPU? No problem â€” default settings use dynamic lowâ€‘RAM quantisation and the search loop throttles to respect laptop thermals.

---

## 2Â Folder structure ğŸ“

```
meta_agentic_agi/
â”œâ”€â”€ core/                  # providerâ€‘agnostic primitives
â”‚   â”œâ”€â”€ fm.py              # OpenAI, Anthropic, openâ€‘weights backends
â”‚   â”œâ”€â”€ tools.py           # search, execution, RAG, eval
â”‚   â””â”€â”€ prompts.py         # seed buildingâ€‘blocks (COT, Reflexionâ€¦)
â”œâ”€â”€ meta_search/
â”‚   â”œâ”€â”€ archive.py         # JSONL steppingâ€‘stone log
â”‚   â”œâ”€â”€ search.py          # â¬… evolutionary loop (multiâ€‘objective)
â”‚   â””â”€â”€ scorer.py          # cost / latency / accuracy / risk metrics
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ agent_base.py      # forward(task:Â Info) â†’ Info | str
â”‚   â””â”€â”€ seeds.py           # handâ€‘picked minimal bootstrap set
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ lineage_app.py     # Streamlit dashboard â€“ graph lineage & metrics
â”‚   â””â”€â”€ assets/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default.yml        # editable inâ€‘UI â€“ objectives & weights
â”œâ”€â”€ requirements.txt       # â‰¤ 40Â MiB wheels; pureâ€‘py numpyâ€‘lite
â””â”€â”€ meta_agentic_agi_demo.py
```

---

## 3Â ArchitectureÂ ğŸ”

1. **Agent specÂ = Python function** â€“ *Turingâ€‘complete searchâ€‘space*.
2. **MetaÂ Agent (gptâ€‘4o, ClaudeÂ 3â€‘Sonnet, or local LlamaÂ 3â€‘70B)\_**
   â†³Â builds candidate agents **inâ€‘code**, guided by archive & multiâ€‘objective score.
3. **Evaluator** spawns sandboxed subprocesses â†’ returns metrics (accuracy ğŸ“ˆ, latency â±, cost ğŸ’°, risk ğŸ›¡).
4. **Archive** (Qualityâ€“Diversity map) retains Paretoâ€‘front & behavioural novelty hashes.
5. **UI** streams lineage graph (D3.js) + sparkâ€‘lines; click any node to expand full source & run.

<p align="center"><img src="https://raw.githubusercontent.com/MontrealAI/AGI-Alpha-Agent-v0/main/docs/img/meta_search_flow.svg" width="640"></p>

---

## 4Â Replacing vendors â¡ï¸ openâ€‘weightsÂ ğŸ‹ï¸â€â™€ï¸

```yaml
# configs/default.yml (excerpt)
provider: mistral:7b-instruct.gguf   # any ollama / llama.cpp id
context_length: 8192
rate_limit_tps: 4
retry_backoff: 2
```

Set `provider:` to:

* `openai:gpt-4o`  â€“Â envÂ `OPENAI_API_KEY`
* `anthropic:claude-3-sonnet` â€“Â envÂ `ANTHROPIC_API_KEY`
* `mistral:7b-instruct.gguf` (default) â€“ autoâ€‘pull via **llamaâ€‘cppâ€‘python**
  The wrapper normalises chat/completions and automatically chunks >Â context tokens via **MCP** streams.

---

## 5Â True multiâ€‘objective search ğŸ¯

> **Objective vector**Â =Â `[accuracy, cost, latency, hallucinationâ€‘risk, carbon]`

* **NSGAâ€‘II** selection (fast elitist) implemented inÂ `meta_search/search.py`.
* Behaviour descriptorÂ = SHAâ€‘256 of AST of candidate agent â€” encourages divergent program shapes (Â§2, HuÂ *etal.*).
* Optional *humanâ€‘inâ€‘theâ€‘loop* override â€” thumbs up/down in UI feeds reward shaping.

---

## 6Â Security & antifragilityÂ ğŸ›¡

* All generated code executed in a **pettingâ€‘zoo**: firejailÂ + `--seccomp` + 512â€¯MiB memcg.
* Mandatory static analysis via `bandit` and dynamic taint tracking before promotion to archive.
* Live monitors shoot rogue processes >Â 30â€¯s CPU.

---

## 7Â ExtendingÂ ğŸ› 

1. **Add domain dataset** â†’ dropÂ `my_dataset.pkl` into `data/` and reference in CLI.
2. **Custom metric** â†’ implement `scorer.MyMetric` and list under `configs/default.yml/objectives`.
3. **Plug tool** (browser, SQL, vectorâ€‘RAG) â†’ write `core/tools/my_tool.py` (must expose `__call__(self, query)`), then import in seeds.

---

## 8Â RoadmapÂ ğŸ—º

* \[ ]Â Hierarchical Metaâ€‘Meta search (selfâ€‘improving metaâ€‘agent).
* \[ ]Â Native CUDA kernel for batch eval of tens of lightweight models (Flashâ€‘infer).
* \[ ]Â Offline RL fineâ€‘tuning of search policy using lineage replay.

---

## 9Â ReferencesÂ ğŸ“š

* HuÂ *etâ€¯al.* â€œAutomated Design of Agentic Systemsâ€Â ICLRâ€¯2025Â îˆ€citeîˆ‚turn5file0îˆ
* OpenAIÂ â€œPractical Guide to Building Agentsâ€Â (2024)
* GoogleÂ ADK docsÂ (2025)

---

Â©Â 2025Â MontrealÂ AIÂ Â Â LicensedÂ Apacheâ€‘2.0
