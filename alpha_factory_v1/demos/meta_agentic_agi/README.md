# Meta-Agentic Î±-AGI ğŸ‘ï¸âœ¨ Demo â€” **Production-Grade v0.1.0**

> **Meta-Agentic (adj.)**  
> An agent whose *primary* role is to **create, select, evaluate, or re-configure other agents** and the rules that bind them, exercising *second-order agency* over a population of first-order agents.  
> *Coined by Vincent Boucher (MONTREAL.AI).*

> **Mission** â€“ Elevate **Alpha-Factory v1** into a self-improving, cross-industry *Alpha Factory* that systematically  
> **Out-Learn Â· Out-Think Â· Out-Design Â· Out-Strategize Â· Out-Execute** â€” while remaining provider-agnostic, regulator-ready, and antifragile.

---

## ğŸ“Œ Why this demo exists
This repository fuses three recent breakthroughs:

1. **Automated Design of Agentic Systems (ADAS)** â€“ meta-agents that *program* better agents via evolutionary search.  
2. **Foundation-model unification layer** â€“ seamless swap-in of **OpenAI**, **Anthropic**, or *any* local `gguf` weight (Mistral, Llama 3, etc.).  
3. **Full lineage provenance** â€“ every candidate agent, its code, metrics, and Pareto rank rendered live in a **Streamlit dashboard**.

The result is a turnkey sandbox for experimenting with **Meta-Agentic Î±-AGI** that can run entirely offline *or* scaled up with cloud APIs.

---

## 1 Quick-start ğŸ
\`\`\`bash
# 1ï¸âƒ£ Clone & enter
git clone https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git
cd AGI-Alpha-Agent-v0/alpha_factory_v1/demos/meta_agentic_agi

# 2ï¸âƒ£ Minimal environment (CPU-only by default)
micromamba create -n metaagi python=3.11 -y
micromamba activate metaagi
pip install -r requirements.txt          # â‰¤ 40 MiB wheels

# 3ï¸âƒ£ Run â€“ zero-API mode (pulls a 7-B gguf via Ollama)
python meta_agentic_agi_demo.py --provider mistral:7b-instruct.gguf

#   â€¦or point to any provider
OPENAI_API_KEY=sk-...   python meta_agentic_agi_demo.py --provider openai:gpt-4o
ANTHROPIC_API_KEY=tokâ€¦  python meta_agentic_agi_demo.py --provider anthropic:claude-3-sonnet

# 4ï¸âƒ£ Launch the real-time lineage UI
streamlit run ui/lineage_app.py
\`\`\`

*Tip â€“ no GPU?* \`llama-cpp-python\` autoselects 4-bit quantisation â†’ runs in < 6 GiB RAM.

---

## 2 Folder Structure ğŸ“
\`\`\`
meta_agentic_agi/
â”œâ”€â”€ core/                # provider-agnostic primitives
â”‚   â”œâ”€â”€ fm.py            # unified FM wrapper (OpenAI / Anthropic / gguf)
â”‚   â”œâ”€â”€ prompts.py       # reusable prompt fragments
â”‚   â””â”€â”€ tools.py         # exec sandbox, RAG, vector store, chaos-monkey
â”œâ”€â”€ meta_agentic_search/ # evolutionary loop
â”‚   â”œâ”€â”€ archive.py       # lineage store & analytics
â”‚   â”œâ”€â”€ scorer.py        # multi-objective metrics plug-ins
â”‚   â””â”€â”€ search.py        # NSGA-II + Reflexion + self-repair
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ agent_base.py    # runtime interface
â”‚   â””â”€â”€ seeds.py         # bootstrap population (vanilla LLM, RAG, plannerâ€¦)
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ lineage_app.py   # Streamlit dashboard
â”‚   â””â”€â”€ assets/          # SVGs, CSS
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default.yml      # editable live in UI
â””â”€â”€ meta_agentic_agi_demo.py  # orchestration entry-point
\`\`\`

---

## 3 Architecture ğŸ”

### 3.1 Meta-Agent Search Loop
\`\`\`mermaid
graph TD
  MLLM["ğŸ§  Meta-LLM<br/>"Programmer""]
  Cand["ğŸ“ Candidate Agent<br/>Python fn"]
  Eval["ğŸ”’ Sandboxed Evaluator"]
  Arch["ğŸ“š Archive<br/>Pareto + Novelty"]
  UI["ğŸ“ˆ Streamlit UI"]

  MLLM -->|generates| Cand
  Cand  --> Eval
  Eval  -->|scores| Arch
  Arch  -->|prompt context| MLLM
  Arch  -->|websocket| UI
\`\`\`

### 3.2 Integration with Alpha-Factory v1
\`\`\`mermaid
flowchart LR
  AFV1("Alpha-Factory v1 Core")
  MLayer("Meta-Agentic Layer<br/>(this demo)")
  Providers("FM Providers<br/>OpenAI / Anthropic / gguf")
  Data("Domain Datasets & RAG stores")
  AFV1 --> MLayer
  MLayer --> Providers
  MLayer --> Data
\`\`\`

---

## 4 Configuring Providers ğŸ‹ï¸

`configs/default.yml` (excerpt):

\`\`\`yaml
provider: mistral:7b-instruct.gguf   # any ollama / llama.cpp id
context_length: 8192
rate_limit_tps: 4
retry_backoff: 2
\`\`\`

| Value                          | Notes                              |
|--------------------------------|------------------------------------|
| \`openai:gpt-4o\`                | needs \`OPENAI_API_KEY\`             |
| \`anthropic:claude-3-sonnet\`    | needs \`ANTHROPIC_API_KEY\`          |
| \`mistral:7b-instruct.gguf\`     | default local model (no API key)   |
| \`llama3:70b-instruct.Q4_K_M.gguf\` | drop into \`~/.ollama\` and reference |

The unified wrapper normalises chat/completions, streams via **Model Context Protocol**, and slides windows automatically.

---

## 5 Multi-Objective Search ğŸ¯

**Objective Vector**  
\`[âˆ’accuracy, latency, cost, hallucination-risk, carbon]\`   *(lower is better)*

* *NSGA-II* elitist ranking + crowding distance  
* Novelty score = Shannon entropy of AST + Jaccard vs. archive  
* Live *thumbs-up / down* in UI feeds a human-in-the-loop reward slice

---

## 6 Security & Antifragility ğŸ›¡

| Layer                   | Mechanism                                               |
|-------------------------|---------------------------------------------------------|
| **Sandbox**             | \`firejail --seccomp\` + 512 MiB cgroup + net-ns isolation |
| **Static analysis**     | \`bandit\` + AST-level policy linter                      |
| **Dynamic guards**      | taint tracking, syscall whitelist                       |
| **Chaos testing**       | random API failure / latency injection                  |
| **Watchdog**            | kills rogue proc > 30 s CPU or > 256 MB tmp             |
| **Audit trail**         | every prompt/response hashed & timestamped to lineage   |

---

## 7 Extending ğŸ› 

| Goal                       | How-to                                                                 |
|----------------------------|------------------------------------------------------------------------|
| **Add dataset**            | Drop \`my.pkl\` into \`data/\`, run \`--dataset my\`                         |
| **Inject new metric**      | Subclass \`scorer.BaseMetric\`, list in \`configs/default.yml\`            |
| **Create new agent seed**  | Add a function into \`agents/seeds.py\` returning \`python\` code string   |
| **Add external tool**      | Implement in \`core/tools/\`, register via entry-point                   |

---

## 8 Roadmap ğŸ—º

* â˜ Hierarchical *meta-meta* evolutionary layer  
* â˜ Batch GPU inference via Flash-Infer v3 kernels  
* â˜ Offline RL fine-tuning of the search policy from lineage replay  
* â˜ Live â€œagent marketplaceâ€ plug-in protocol (A2A-compatible)

---

## 9 Key Metrics ğŸ“Š

| KPI                              | Why it matters                       |
|----------------------------------|--------------------------------------|
| *Design cycle time*              | Shorter loops â‡’ faster compounding   |
| *Cross-domain adaptability Î”*    | Measures generality across verticals |
| *Surplus $/GPU-hour*             | Direct economic efficiency signal    |
| *Pareto front size*              | Diversity of top solutions           |

---

## 10 References ğŸ“š

* Hu S. *et al.* **â€œAutomated Design of Agentic Systemsâ€** (ICLR 2025)  
* OpenAI **â€œA Practical Guide to Building Agentsâ€** (2024)  
* Google **ADK Documentation** (2025)  
* Silver D. & Sutton R. **â€œWelcome to the Era of Experienceâ€** (MIT Press preprint, 2025)  
* Schrittwieser J. *et al.* **â€œMastering Atari, Go, Chess and Shogi by Planning with a Learned Modelâ€** (2019)

---

Â© 2025 **MONTREAL.AI** â€” Apache-2.0  
*Built with â¤ï¸ for open, provider-agnostic innovation.*
