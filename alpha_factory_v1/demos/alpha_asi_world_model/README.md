<!--
README  â–‘Î±-ASI World-Model Demo â–‘  Alpha-Factory v1 ğŸ‘ï¸âœ¨
Last updated 2025-04-25   Maintainer â†’ Montreal.AI Core AGI Team
-->

<p align="center">
  <img src="https://raw.githubusercontent.com/MontrealAI/brand/main/alpha_factory_banner.svg" width="80%">
</p>

<h1 align="center">Î±-ASI World-Model Demo ğŸ‘ï¸âœ¨</h1>
<p align="center">
  <em>The open-ended curriculum engine + MuZero learner that powers the
  <strong>Alpha-Factory v1</strong> multi-agent runtime.</em><br>
  <strong>Out-Learn Â· Out-Think Â· Out-Design Â· Out-Strategise Â· Out-Execute</strong>
</p>

---

## 0  Table of Contents  <!-- omit in toc -->
1. [Why this demo matters](#1-why-this-demo-matters)
2. [Quick-start ğŸ¥‘](#2-quick-start-)
3. [High-level architecture ğŸ—ºï¸](#3-high-level-architecture-ï¸)
4. [Meet the agents ğŸ¤– (â‰¥ 5)](#4-meet-the-agents-ï¸-â‰¥-5)
5. [Runtime controls ğŸ®](#5-runtime-controls-)
6. [Deployment recipes ğŸš€](#6-deployment-recipes-)
7. [Safety, antifragility & governance ğŸ›¡ï¸](#7-safety-antifragility--governance-)
8. [Extending the demo ğŸ§©](#8-extending-the-demo-)
9. [Troubleshooting ğŸ”§](#9-troubleshooting-)
10. [License & citation](#10-license--citation)

---

## 1  Why this demo matters

> **Mission**â€ƒProve that a constellation of **agentic micro-services** can
> _independently grow their own synthetic worlds_ (open-ended _POET_ curriculum),
> _learn a general world-model_ (MuZero-style), automate strategy research,
> detect live **alpha** opportunities across industries, and march toward the
> **Î±-ASI** referenced by Greg Brockman (â€œbreak capitalismâ€ âš¡).

Success criteria âœ“  

| Pillar | Concrete demonstration |
| ------ | ---------------------- |
| **Open-Endedness** | Automatic generation & evaluation of ever harder MiniWorld mazes |
| **World-Models** | MuZero learner predicts reward/value & policy without ground-truth rules |
| **Multi-Agent** | â‰¥ 5 independent Alpha-Factory agents coordinate via A2A bus |
| **Cross-Industry Alpha** | StrategyAgent spots profitable â€œalphaâ€ events (simulated market feed) |
| **Antifragility** | SafetyAgent can freeze learner on NaN/spike; system self-recovers |
| **Local-First** | No internet or API keys required; LLM helpers activate only if keys provided |

---

## 2  Quick-start ğŸ¥‘

```bash
# â–‘ Local Python (CPU or GPU)
pip install -r requirements.txt        # torch, fastapi, uvicornâ€¦

python -m alpha_asi_world_model_demo --demo
open http://localhost:7860             # dashboard & Swagger

# â–‘ One-liner Docker
python -m alpha_asi_world_model_demo --emit-docker
docker build -t alpha_asi_world_model .
docker run -p 7860:7860 alpha_asi_world_model

# â–‘ Helm (K8s)
python -m alpha_asi_world_model_demo --emit-helm
helm install alpha-asi ./helm_chart

# â–‘ Notebook
python -m alpha_asi_world_model_demo --emit-notebook
jupyter lab alpha_asi_world_model_demo.ipynb
```

> **Tip ğŸ’¡** Set `ALPHA_ASI_SEED=<int>` to reproduce identical curriculum runs.

---

## 3  High-level architecture ğŸ—ºï¸

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Alpha-Factory Bus (A2A) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   curriculum   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   telemetry   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚ StrategyAgentâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Orchestr. â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   UI / WS  â”‚          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚  (loop)   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Interface â”‚          â”‚
â”‚          â–²  â–²                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    commands   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚          â”‚  â”‚ new_env/reward                     â–²                                   â”‚
â”‚   plans  â”‚  â”‚ loss stats                        â”‚ halt                              â”‚
â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”   context       â”‚            â”‚                                   â”‚
â”‚   â”‚ ResearchAgentâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Learner (MuZero) â—„â”€ SafetyAgent (loss guard)      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚   â–²                                             â”‚
â”‚              code patches         â”‚   â”‚                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚   â”‚ gradients                                   â”‚
â”‚   â”‚ CodeGenAgent â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚                                             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚                                             â”‚
â”‚                                       â–¼                                             â”‚
â”‚                            POET Generator â†’ MiniWorlds (env pool)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

* **All messages** flow through a single in-proc **A2A** topic bus (swap for
  Redis/NATS at scale).  
* **MCP** is used by ResearchAgent to attach rich â€œcontext blocksâ€ to
  learner queries when an LLM key is supplied.  
* Components comply with **OpenAI Agents SDK** & **Google ADK** lifecycle
  (`init/step/shutdown`), so they can be re-packaged as micro-services at will.

---

## 4  Meet the agents ğŸ¤– (â‰¥ 5)

| TopicÂ ğŸ›° | Skill | How it contributes to **End-to-End Alpha** |
|--------------|-------|-------------------------------------------|
| **planning_agent** | Long-horizon curriculum sketching (optionally via GPT-4o) | Keeps learner near its â€œzone of proximal developmentâ€ â†’ faster capability gain |
| **research_agent** | Literature & data mining (papers, patents, SEC filingsâ€¦) | Injects distilled insights; helps learner transfer skills across domains |
| **strategy_agent** | Real-time alpha detection (mock market feed ğŸ“ˆ) | Signals lucrative industry opportunities; triggers env mutations that mimic them |
| **codegen_agent** | Auto-ML / network surgery | Evolves MuZero hyper-params & architecture â†’ antifragile optimisation |
| **market_agent** | Streams synthetic or live financial ticks | Provides cross-domain stressor; validates Alpha-capture loops |
| **safety_agent** | Alignment guardrails | Halts on NaN/catastrophe; enforces resource quotas & ethical policies |

*(If a concrete implementation is absent the stub logs every call, guaranteeing
bus liveness even on a clean clone.)*

---

## 5  Runtime controls ğŸ®

| REST | Use case |
|------|----------|
| `GET /agents` | List active agent topics |
| `POST /command {"cmd":"new_env"}` | Force-spawn a fresh world |
| `POST /command {"cmd":"stop"}` | Graceful halt â¸ |

**WebSocket (`/ws`)** streams JSON telemetry every `ui_tick` steps:  
`{"t":1234,"r":-0.01,"loss":0.872}` â†’ plug into Grafana or a custom React chart.

---

## 6  Deployment recipes ğŸš€

| Target | Guide |
|--------|-------|
| ğŸ³ **Docker** | Auto-generated `Dockerfile` (<100 MB slim). GPU builds: swap base for `nvidia/cuda:runtime-12.4`. |
| â˜¸ï¸ **Kubernetes** | Run `--emit-helm`; edit values (`replicaCount`, `resources.limits`). Works on GKE, AKS, EKS, k3d. |
| ğŸ **Pure Python** | No Docker needed; just `pip install -r requirements.txt`. |
| ğŸ”’ **Air-gapped** | Offline wheels; set env `NO_LLM=1` or omit API keys. |
| ğŸ”‘ **Cloud LLM mode** | Export `OPENAI_API_KEY` â†’ PlanningAgent & ResearchAgent auto-upgrade to LLM assistants. |

---

## 7  Safety, antifragility & governance ğŸ›¡ï¸

* **Reward-hacking firewall** â€” StrategyAgent & SafetyAgent cross-check any
  sudden reward spike; suspicious events quarantine the environment seed for
  forensic replay.  
* **Loss guard** â€” Threshold `loss > 1e3` or `NaN` triggers global `stop`.  
* **Compute budget** â€” Learner train loop obeys `torch.set_grad_enabled(False)`
  for evaluation, cuts GPU utilisation to â‰¤ 80Â %.  
* **Policy logging** â€” Every 10â€¯k steps, MuZero weights hashed (SHAâ€‘256) +
  signed for traceability.  
* **Audit-ready** â€” All IPC messages dumped to `./logs/audit_<ts>.ndjson`
  (regulator-friendly).

---

## 8  Extending the demo ğŸ§©

> **One-file hackability** yet **enterprise scalability**.

1. **New env type** â†’ subclass `MiniWorld` (`step/reset/obs`), register in
   `POETGenerator.propose`.  
2. **Swap learner** â†’ Implement `.act/.remember/.train` in a new class;
   StrategyAgent can trigger hot-swap via `{"cmd":"swap_learner"}`.  
3. **External micro-service** â†’ Re-use `BaseAgent`; deploy as HTTP worker that
   bridges to A2A via WebSockets.

---

## 9  Troubleshooting ğŸ”§

| Problem | Cause / Fix |
|---------|-------------|
| _â€œUI stallsâ€_ | Browser blocked WS â†’ check console; ensure port 7860 reachable. |
| _CUDA OOM_ | `export TORCH_FORCE_CPU=1` or downsize net via CodeGenAgent. |
| _Docker build slow_ | Add build-arg `TORCH_WHL=<local-wheel>` (offline). |
| _K8s CrashLoop_ | `kubectl logs`; missing GPU driver or env var. |

Need help? Open an issue â†’ **@MontrealAI/alpha-factory-core**.

---

## 10  License & citation

```
MIT Â© 2025 Montreal.AI
```

Please cite **Alpha-Factory v1 ğŸ‘ï¸âœ¨ â€” Multi-Agent AGENTIC Î±-AGI**:

> Montreal.AI (2025). *Fully-Agentic Î±-AGI: Foundation World Models for Î±-ASI.*  
> GitHub https://github.com/MontrealAI/AGI-Alpha-Agent-v0

<p align="center">
  <img src="https://raw.githubusercontent.com/MontrealAI/brand/main/alpha_factory_footer.svg" width="60%">
</p>
