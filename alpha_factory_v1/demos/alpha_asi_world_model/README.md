<!--
README  â–‘Î±-ASI World-Model Demo â–‘  Alpha-Factory v1 ğŸ‘ï¸âœ¨
Last updated 2025-04-25   Maintainer â†’ Montreal.AI Core AGI Team
-->

<h1 align="center">Î±-ASI World-Model Demo ğŸ‘ï¸âœ¨</h1>
<p align="center">
  <em>The open-ended curriculum engine + MuZero learner that powers the
  <strong>Alpha-Factory v1</strong> multi-agent runtime.</em><br>
  <strong>Out-Learn Â· Out-Think Â· Out-Design Â· Out-Strategise Â· Out-Execute</strong>
</p>

---

> **Disclaimer**
> This demo is a conceptual research prototype and does **not** represent real
> AGI capabilities. See the project's [ApacheÂ 2.0 license](../../../LICENSE) and
> [security policy](../../../SECURITY.md) for details.

## 0  Table of Contents  <!-- omit in toc -->
1. [Why this demo matters](#1-why-this-demo-matters)
2. [Quick-start ğŸ¥‘](#2-quick-start-)
   - [Offline setup](#offline-setup)
3. [High-level architecture ğŸ—ºï¸](#3-high-level-architecture-ï¸)
4. [Meet the agents ğŸ¤– (â‰¥ 5)](#4-meet-the-agents-ï¸-â‰¥-5)
5. [Runtime controls ğŸ®](#5-runtime-controls-)
6. [Deployment recipes ğŸš€](#6-deployment-recipes-)
7. [Safety, antifragility & governance ğŸ›¡ï¸](#7-safety-antifragility--governance-)
8. [Extending the demo ğŸ§©](#8-extending-the-demo-)
9. [Troubleshooting ğŸ”§](#9-troubleshooting-)
10. [Production checklist âœ…](#10-production-checklist-)
11. [License & citation](#11-license--citation)

---

## 1  Why this demo matters

> **Mission**â€ƒProve that a constellation of **agentic micro-services** can
> _independently grow their own synthetic worlds_ (open-ended _POET_ curriculum),
> _learn a general world-model_ (MuZero-style), automate strategy research,
> detect live **alpha** opportunities across industries, and march toward the
> **Î±-ASI** referenced by Vincent Boucher, President of MONTREAL.AI and QUEBEC.AI âš¡).

Success criteria âœ“  

| Pillar | Concrete demonstration |
| ------ | ---------------------- |
| **Open-Endedness** | Automatic generation & evaluation of ever harder MiniWorld mazes |
| **World-Models** | MuZero learner predicts reward/value & policy without ground-truth rules |
| **Multi-Agent** | â‰¥ 5 independent Alpha-Factory agents coordinate via A2A bus |
| **Cross-Industry Alpha** | StrategyAgent spots profitable â€œalphaâ€ events (simulated market feed) |
| **Antifragility** | SafetyAgent can freeze learner on NaN/spike; system self-recovers |
| **Local-First** | No internet or API keys required; LLM helpers activate only if keys provided |

---

## 2  Quick-start ğŸ¥‘

```bash
# â–‘ Local Python (CPU or GPU)
pip install -r requirements.txt        # torch, fastapi, uvicornâ€¦

# All interactive helpers (`run_ui`, `run_headless`) require these packages.

# new CLI (after `pip install -e .` at repo root)
alpha-asi-demo --demo        # same as `python -m alpha_asi_world_model_demo --demo`
alpha-asi-demo --demo --no-llm   # force-disable the optional LLM planner
open http://localhost:7860             # dashboard & Swagger

# â–‘ One-liner Docker
python -m alpha_asi_world_model_demo --emit-docker
docker build -t alpha_asi_world_model .
docker run -p 7860:7860 alpha_asi_world_model

# â–‘ Helm (K8s)
python -m alpha_asi_world_model_demo --emit-helm
helm install alpha-asi ./helm_chart

# â–‘ Notebook
python -m alpha_asi_world_model_demo --emit-notebook
jupyter lab alpha_asi_world_model_demo.ipynb
# â–‘ Colab
Open `alpha_asi_world_model_colab.ipynb` in Google Colab for an end-to-end guided setup.
Nonâ€‘technical users can run it step by step:
1. Visit the notebook on GitHub and click **Open in Colab**.
2. Wait for the environment to start then choose **Runtime â†’ Run all** (or run each cell manually).
3. The notebook installs requirements and launches the demo. When no API key is provided it automatically sets `NO_LLM=1`.
4. Interact with the dashboard in the new browser tab and run the final **Shut down** cell when done.
# â–‘ Shell helper
./deploy_alpha_asi_world_model_demo.sh
# â–‘ OpenAI Agents bridge
python openai_agents_bridge.py
# â–‘ Google ADK gateway
ALPHA_FACTORY_ENABLE_ADK=true python openai_agents_bridge.py
```

> **Tip ğŸ’¡** Set `ALPHA_ASI_SEED=<int>` or `general.seed` in `config.yaml` to reproduce identical curriculum runs.
> **Tip ğŸ’¡** Set `ALPHA_ASI_SILENT=1` to hide the startup banner.

### Offline setup
When working without internet access, first build a local wheelhouse:

```bash
mkdir -p /media/wheels
pip wheel -r requirements.txt -w /media/wheels
pip wheel -r ../../../requirements-dev.txt -w /media/wheels
```

Install and verify using the wheelhouse from the repository root:

```bash
WHEELHOUSE=/media/wheels AUTO_INSTALL_MISSING=1 ./codex/setup.sh
WHEELHOUSE=/media/wheels AUTO_INSTALL_MISSING=1 \
  python check_env.py --auto-install --wheelhouse /media/wheels
```

Set `NO_LLM=1` to disable the planning agent when no API key is available. The
`deploy_alpha_asi_world_model_demo.sh` helper exports this variable
automatically.
Define `ALPHA_ASI_LLM_MODEL=gpt-4o-mini` to change the planner's model.

### Device selection
`config.yaml` exposes a `device` field controlling which accelerator PyTorch
uses. Accepted values are `cpu`, `cuda` and `auto`. With `auto` (the default),
the demo runs on GPU when `torch.cuda.is_available()` returns `True` and falls
back to CPU otherwise.

---

## 3  High-level architecture ğŸ—ºï¸

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Alpha-Factory Bus (A2A) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   curriculum   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   telemetry   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚ StrategyAgentâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Orchestr. â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   UI / WS  â”‚          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚  (loop)   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Interface â”‚          â”‚
â”‚          â–²  â–²                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    commands   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚          â”‚  â”‚ new_env/reward                     â–²                                   â”‚
â”‚   plans  â”‚  â”‚ loss stats                        â”‚ halt                              â”‚
â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”   context       â”‚            â”‚                                   â”‚
â”‚   â”‚ ResearchAgentâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Learner (MuZero) â—„â”€ SafetyAgent (loss guard)      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚   â–²                                             â”‚
â”‚              code patches         â”‚   â”‚                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚   â”‚ gradients                                   â”‚
â”‚   â”‚ CodeGenAgent â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚                                             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚                                             â”‚
â”‚                                       â–¼                                             â”‚
â”‚                            POET Generator â†’ MiniWorlds (env pool)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

* **All messages** flow through a single in-proc **A2A** topic bus (swap for
  Redis/NATS at scale).  
* **MCP** is used by ResearchAgent to attach rich â€œcontext blocksâ€ to
  learner queries when an LLM key is supplied.  
* Components comply with **OpenAI Agents SDK** & **Google ADK** lifecycle
  (`init/step/shutdown`), so they can be re-packaged as micro-services at will.

---

## 4  Meet the agents ğŸ¤– (â‰¥ 5)

| TopicÂ ğŸ›° | Skill | How it contributes to **End-to-End Alpha** |
|--------------|-------|-------------------------------------------|
| **planning_agent** | Long-horizon curriculum sketching (optionally via GPT-4o) | Keeps learner near its â€œzone of proximal developmentâ€ â†’ faster capability gain |
| **research_agent** | Literature & data mining (papers, patents, SEC filingsâ€¦) | Injects distilled insights; helps learner transfer skills across domains |
| **strategy_agent** | Real-time alpha detection (mock market feed ğŸ“ˆ) | Signals lucrative industry opportunities; triggers env mutations that mimic them |
| **codegen_agent** | Auto-ML / network surgery | Evolves MuZero hyper-params & architecture â†’ antifragile optimisation |
| **market_agent** | Streams synthetic or live financial ticks | Provides cross-domain stressor; validates Alpha-capture loops |
| **safety_agent** | Alignment guardrails | Halts on NaN/catastrophe; enforces resource quotas & ethical policies |

*(If a concrete implementation is absent the stub logs every call, guaranteeing
bus liveness even on a clean clone.)*

---

## 5  Runtime controls ğŸ®

| REST | Use case |
|------|----------|
| `GET /agents` | List active agent topics |
| `POST /command {"cmd":"new_env"}` | Force-spawn a fresh world |
| `POST /command {"cmd":"stop"}` | Graceful halt â¸ |

**WebSocket (`/ws`)** streams JSON telemetry every `ui_tick` steps:  
`{"t":1234,"r":-0.01,"loss":0.872}` â†’ plug into Grafana or a custom React chart.

---

## 6  Deployment recipes ğŸš€

| Target | Guide |
|--------|-------|
| ğŸ³ **Docker** | Auto-generated `Dockerfile` (<100 MB slim). GPU builds: swap base for `nvidia/cuda:runtime-12.4`. |
| â˜¸ï¸ **Kubernetes** | Run `--emit-helm`; edit values (`replicaCount`, `resources.limits`). Works on GKE, AKS, EKS, k3d. |
| ğŸ **Pure Python** | No Docker needed; just `pip install -r requirements.txt`. |
| ğŸ”’ **Air-gapped** | Offline wheels; set `NO_LLM=1` to disable the planner or omit API keys. |
| ğŸ”‘ **Cloud LLM mode** | Export `OPENAI_API_KEY` â†’ PlanningAgent & ResearchAgent auto-upgrade to LLM assistants. |

---

## 7  Safety, antifragility & governance ğŸ›¡ï¸

* **Reward-hacking firewall** â€” StrategyAgent & SafetyAgent cross-check any
  sudden reward spike; suspicious events quarantine the environment seed for
  forensic replay.  
* **Loss guard** â€” Threshold `loss > 1e3` or `NaN` triggers global `stop`.  
* **Compute budget** â€” Learner train loop obeys `torch.set_grad_enabled(False)`
  for evaluation, cuts GPU utilisation to â‰¤ 80Â %.  
* **Policy logging** â€” Every 10â€¯k steps, MuZero weights hashed (SHAâ€‘256) +
  signed for traceability.  
* **Audit-ready** â€” All IPC messages dumped to `./logs/audit_<ts>.ndjson`
  (regulator-friendly).

---

## 8  Extending the demo ğŸ§©

> **One-file hackability** yet **enterprise scalability**.

1. **New env type** â†’ subclass `MiniWorld` (`step/reset/obs`), register in
   `POETGenerator.propose`.  
2. **Swap learner** â†’ Implement `.act/.remember/.train` in a new class;
   StrategyAgent can trigger hot-swap via `{"cmd":"swap_learner"}`.  
3. **External micro-service** â†’ Re-use `BaseAgent`; deploy as HTTP worker that
   bridges to A2A via WebSockets.

---

## 9  Troubleshooting ğŸ”§

| Problem | Cause / Fix |
|---------|-------------|
| _â€œUI stallsâ€_ | Browser blocked WS â†’ check console; ensure port 7860 reachable. |
| _CUDA OOM_ | `export TORCH_FORCE_CPU=1` or downsize net via CodeGenAgent. |
| _Docker build slow_ | Add build-arg `TORCH_WHL=<local-wheel>` (offline). |
| _K8s CrashLoop_ | `kubectl logs`; missing GPU driver or env var. |
| _Hide banner_ | Set `ALPHA_ASI_SILENT=1` before launching. |

Need help? Open an issue â†’ **@MontrealAI/alpha-factory-core**.

## 10  Production checklist âœ…

- Ensure `python3 --version` returns 3.11â€“3.12.
- Install dependencies: `pip install -r requirements.txt`.
- Launch via `./deploy_alpha_asi_world_model_demo.sh` and visit `http://localhost:7860`.
- The script sets `NO_LLM=1` automatically when `OPENAI_API_KEY` is unset.
- Provide an `OPENAI_API_KEY` to unlock planner features.
- Set `NO_LLM=1` to skip the LLM planner even when a key is provided.

---

## 11  License & citation

```
Apacheâ€‘2.0 Â© 2025 MONTREAL.AI
```

Please cite **Alpha-Factory v1 ğŸ‘ï¸âœ¨ â€” Multi-Agent AGENTIC Î±-AGI**:

> MONTREAL.AI (2025). *Fully-Agentic Î±-AGI: Foundation World Models for Î±-ASI.*  
> GitHub https://github.com/MontrealAI/AGI-Alpha-Agent-v0
