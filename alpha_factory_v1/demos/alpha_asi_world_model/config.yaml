# ğŸ›ï¸ Alpha-ASI World-Model Demo â€“ Configuration
# =============================================
# Tweak anything, then run:  `python -m alpha_asi_world_model_demo --demo`
# Lines beginning with â€œ#â€ are comments / tooltips for non-technical users.
# =============================================
# Disclaimer: this demo is a conceptual research prototype. References to
# â€œAGIâ€ or â€œsuperintelligenceâ€ describe aspirational goals and do not
# indicate real general intelligence. Use at your own risk.

general:
  seed: 42        # ğŸ” Set to any int for reproduce-able runs
  device: auto    # cpu | cuda | auto  (auto picks GPU when available)

training:
  buffer_limit: 50000   # ğŸ§  Replay-buffer size
  env_batch: 2         # ğŸŒ Parallel environments
  train_batch: 128
  lr: 0.001
  max_steps: 100000     # â±ï¸ Orchestrator loop iterations
  hidden: 256          # ğŸ¤– Latent state size
  mcts_simulations: 16 # ğŸ•µï¸ MCTS rollouts per action
  ui_tick: 100          # ğŸ“ˆ How often to broadcast stats (in steps)

env:
  min_size: 5           # ğŸŒ Smallest grid size
  max_size: 10          # ğŸŒ Largest grid size
  obstacle_density: 0.15  # ğŸš§ % of cells turned into obstacles
  mc_min: 0.2           # ğŸ” Reject envs solved < mc_min return
  mc_max: 0.8           # ğŸ” Reject envs scoring > mc_max return
  mc_episodes: 3        # ğŸ² Episodes to estimate average return

agents:                 # ğŸ¤– Agent modules to auto-load
  required:
    - planning_agent.PlanningAgent
    - research_agent.ResearchAgent
    - strategy_agent.StrategyAgent
    - market_agent.MarketAnalysisAgent
    - codegen_agent.CodeGenAgent
  optional:
    - safety_agent.SafetyAgent
    - memory_agent.MemoryAgent
    - llm_planner.LLMPlanner   # auto-enabled only if OPENAI_API_KEY is set

integrations:
  openai_enabled: true  # ğŸ”Œ Set false for fully-offline demo
  adk_enabled: false
  a2a_enabled: true

ui:
  host: 0.0.0.0
  port: 7860
  cors_origins: ["*"]   # ğŸ” Lock this down in production
