<!--
  MuZeroÂ PlanningÂ Demo
  Alphaâ€‘FactoryÂ v1Â ğŸ‘ï¸âœ¨Â â€”Â Multiâ€‘AgentÂ **AGENTICÂ Î±â€‘AGI**
  Outâ€‘learnÂ Â·Â Outâ€‘thinkÂ Â·Â Outâ€‘strategiseÂ Â·Â Outâ€‘execute
  Â©Â 2025Â MONTREAL.AIÂ Â Â Apacheâ€‘2.0Â License
-->

# ğŸŒŸ **Mastery Without a Ruleâ€‘Book** â€” watch MuZero think in realÂ time

> â€œAn agent neednâ€™t be told the rules of Go, Chess or cartâ€‘balancing gravity;  
> it can conjure the laws for itself and still prevail.â€  
> â€”Â *SchrittwieserÂ etÂ al., â€œMasteringÂ Atari, Go, Chess and Shogi by Planning with aÂ LearnedÂ Modelâ€*

This demo distils that 26â€‘page landmark and its 600â€‘line reference pseudocode into a **60â€‘second,
oneâ€‘command experience**.  
Youâ€™ll see a MuZeroâ€‘style agent improvise physics, deploy Monteâ€‘Carlo search,
andÂ **stabilise CartPole** â€” all inside your browser. No GPU, no PhD required.

> **Disclaimer**
> This demo is a conceptual research prototype. References to "AGI" and
> "superintelligence" describe aspirational goals and do not indicate the
> presence of a real general intelligence. Use at your own risk.

---

## ğŸš€Â QuickÂ Start

Clone the repository and run the helper script. It generates a
`config.env` with safe defaults â€“ edit it to add your `OPENAI_API_KEY` if
you want narrated moves.

Set `HOST_PORT` to expose a different dashboard port,
`MUZERO_ENV_ID` to try other Gymnasium tasks,
and `MUZERO_EPISODES` to adjust episode count.
The helper script warns if the chosen port is already occupied.

```bash
git clone https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git
cd AGI-Alpha-Agent-v0/alpha_factory_v1/demos/muzero_planning
./run_muzero_demo.sh
```

The script prints the local URL and, when possible, automatically opens it in
your default browser. Automatic browser opening is currently supported only
on Linux (using `xdg-open`) and macOS (using `open`).

Alternatively run natively:

```bash
pip install -r requirements.txt
python -m alpha_factory_v1.demos.muzero_planning
```
The tests for this demo rely on `torch`, which can take a while to install.
If it's absent, those tests are skipped. For a lightweight check run
```bash
pytest -m 'not e2e'
```

### Optional `openai-agents`

For narrated actions and tool calls, install `openai-agents` version
`>=0.0.16`:

```bash
pip install -U 'openai-agents>=0.0.16'
```

Leaving `OPENAI_API_KEY` empty keeps the demo offline and falls back to
**Ollama âœ• Mixtral** if available.

### Command-line options

You can override the environment, episode count and port directly from the CLI:

```bash
python -m alpha_factory_v1.demos.muzero_planning --env MountainCar-v0 \
       --episodes 5 --port 8888
```


1. **Docker Desktop** builds the container (~45Â s on first run).
2. **Open <http://localhost:${HOST_PORT:-7861}>** and press **â€œâ–¶Â RunÂ MuZeroâ€**.
3. Watch the live video feed, reward ticker and optional commentary.

> **Offline by default** â€“ leaving `OPENAI_API_KEY` empty runs the demo
> fully locally with **OllamaÂ âœ•Â Mixtral**.

This script also registers a small **MuZeroAgent** with the OpenAI Agents runtime.
When `ALPHA_FACTORY_ENABLE_ADK=true` and the optional `google-adk` package is
installed, the agent is automatically exposed via a GoogleÂ ADK gateway for
crossâ€‘process collaboration.

---

## âœ¨Â Why it matters

| MuZero Pillar | How the demo shows it |
|---------------|-----------------------|
| **Learn the model, not the rules** | Environment dynamics are *unknown*; MiniMu invents them by gradient descent |
| **Plan with MCTS** | 64â€‘node tree search per action, mirroring Fig.Â 1 of the paper |
| **Joint reward, value & policy** | Network outputs all three heads; rewards predicted *before* they are observed |
| **Scales to swarms** | A2A wires multiple MiniMu workers into Alphaâ€‘Factoryâ€™s agent mesh |

---

## ğŸ› ï¸Â Architecture at a glance

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  observation  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CartPoleÂ ğŸ¢ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚MiniMu Core â”‚â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ hidden
                       â–²            â”‚          â–¼
                 rewardâ”‚     Recurrent model  â”‚
                       â”‚            â–¼          â”‚ MCTS
                â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”  policy/value  â”‚
                â”‚  MCTS 64Ã—   â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

* **MiniMu** â€” â‰¤Â 300Â LoC, pureâ€‘PyTorch, CPUâ€‘friendly  
* **openaiâ€‘agentsâ€‘python** â€” optional LLM overlay for narrative toolâ€‘calling  
* **Gradio** â€” zeroâ€‘install UI & live video  
* **Docker Compose** â€” reproducible, airâ€‘gapped deployment  

---

## ğŸ“Â Colab (two clicks)

[![OpenÂ InÂ Colab][colab-badge]][colab-notebook]

[colab-badge]: https://colab.research.google.com/assets/colab-badge.svg
[colab-notebook]: https://colab.research.google.com/github/MontrealAI/AGI-Alpha-Agent-v0/blob/main/alpha_factory_v1/demos/muzero_planning/colab_muzero_planning.ipynb

Colab spins up the same dashboard via anÂ ngrok tunnel â€” handy when Docker isnâ€™t.
It installs the tiny MuZero package, runs a quick sanity test and opens a shareable link.
Two extra cells let you tweak the Gym environment, port number and gracefully stop the demo.

---

## ğŸ§©Â Eager to tinker?

* **Change the world model**: `demo/minimuzero.py`, class `MiniMuNet`.
* **Crank search depth**: `ROLL_OUTS` constant â€” 64Â âœÂ 128 shows clearer MCTS gains.
* **Swap environments**: any Gymnasium classicâ€‘control task runs outâ€‘ofâ€‘theâ€‘box.
* **Join the swarm**: launch multiple `docker compose --scale orchestrator=4` and
  watch emergent coordination via A2A.

---

## ğŸ›¡ï¸Â Security & ops

| Concern | Mitigation |
|---------|------------|
| Secrets | `config.env` volume only, never written to image |
| Network egress | Absent key â†’ offline LLM, no outbound calls |
| Container user | Runs as nonâ€‘root UIDÂ 1001 |
| Health probes | `/__live` returns **200Â OK** for k8s &Â Dockerâ€‘Swarm |

---

## ğŸ†˜Â 30â€‘second troubleshooting

| Symptom | Remedy |
|---------|--------|
| â€œDocker not foundâ€ | Install via <https://docs.docker.com/get-docker> |
| PortÂ 7861 busy | Edit the `ports:` mapping in `docker-compose.muzero.yml` |
| ARMÂ Mac slow build | Enable â€œRosetta for x86/amd64 emulationâ€ in Docker settings |
| Want GPU | Swap base image to `nvidia/cuda:12.4.0-runtimeâ€‘ubuntu22.04` & add `--gpus all` |

---

### Development notes

Run `pre-commit run --files alpha_factory_v1/demos/muzero_planning` before committing changes. This mirrors the workflow in [AGENTS.md](../../../AGENTS.md).

---

## ğŸ¤Â Credits

* **DeepMind** for the research masterpieceÂ (2020).  
* **Montreal.AI** for distilling it into an afternoon playground.  
* The openâ€‘source community powering every dependency.

> **Alphaâ€‘Factory** â€” forging intelligence that **outâ€‘learns, outâ€‘thinks, outâ€‘executes**.
