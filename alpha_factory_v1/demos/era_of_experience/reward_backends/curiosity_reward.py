
"""
curiosity_reward.py â€“ Alphaâ€‘FactoryÂ v1Â ðŸ‘ï¸âœ¨
------------------------------------------------
Reward backend that encourages agents to seek *novel* observations.

Formula
~~~~~~~
    reward = 1 / (1 + N_obs)

where **N_obs** is how many times the exact observation hash has been seen
*so far in this Python process*.  Firstâ€‘time events => **1.0**, second
occurrence => **0.5**, third => **0.33**, ...

Implementation details
----------------------
â€¢ Stateless API expected by *reward_backends* :
      reward(state, action, result) -> float

â€¢ Observation uniqueness:
    - We SHAâ€‘1 hash ``repr(result)`` truncated to 4â€¯KB to bound memory.
    - Hash digest stored in an LRU mapÂ (maxlenÂ =Â 50â€¯000) to avoid
      unbounded growth during very long runs.

â€¢ Threadâ€‘safety: a single ``threading.Lock`` protects the counter map.

â€¢ Zero thirdâ€‘party dependencies â€“ standard library only.

Â©Â 2025Â Montreal.AIÂ Â Â Apache-2.0 License
"""

from __future__ import annotations

import hashlib
import logging
import threading
from collections import OrderedDict
from typing import Any, Dict

__all__ = ["reward"]

_LOG = logging.getLogger(__name__)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_MAX_ENTRIES = 50_000           # LRU capacity for seen hashes
_HASH_TRUNCATE = 4096           # bytes of repr() to hash

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ internal state â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class _LRUCounter(OrderedDict):
    """Threadâ€‘safe LRU counter mapping hash â†’ count."""

    def __init__(self, max_len: int) -> None:
        super().__init__()
        self._max_len = max_len
        self._lock = threading.Lock()

    def increment(self, h: str) -> int:
        """Increment count for *h* and return the *previous* count."""
        with self._lock:
            prev = self.get(h, 0)
            self[h] = prev + 1
            self.move_to_end(h)

            if len(self) > self._max_len:
                # Pop the leastâ€‘recently used item
                popped_h, _ = self.popitem(last=False)
                _LOG.debug("[curiosity_reward] LRU evict %s", popped_h)
            return prev

_seen = _LRUCounter(_MAX_ENTRIES)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _hash_observation(obs: Any) -> str:
    """Return a stable SHAâ€‘1 hex digest for an arbitrary Python object."""
    data = repr(obs).encode("utf-8", errors="replace")[: _HASH_TRUNCATE]
    return hashlib.sha1(data).hexdigest()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ public API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def reward(state: Any, action: Any, result: Any) -> float:  # noqa: D401
    """Compute curiosity reward âˆˆ (0,â€¯1]."""
    h = _hash_observation(result)
    prev_count = _seen.increment(h)

    # Inverse frequency
    r = 1.0 / (1.0 + prev_count)
    _LOG.debug("[curiosity_reward] hash=%s prev=%d reward=%.4f", h, prev_count, r)
    return r
