{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[See docs/DISCLAIMER_SNIPPET.md](../../../docs/DISCLAIMER_SNIPPET.md)"
  },
  {
   "cell_type": "markdown",
   "id": "0cf8b073",
   "metadata": {},
   "source": [
    "# 🛠️ Self‑Healing Repo · Colab Notebook\n",
    "See an agent detect failing tests, generate a patch, and heal the codebase—right in Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d2e163",
   "metadata": {},
   "source": [
    "## 1 · Clone Alpha‑Factory & install lean deps (≈2 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d65bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!git clone --depth 1 https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git -q\n",
    "%cd AGI-Alpha-Agent-v0/alpha_factory_v1/demos/self_healing_repo\n",
    "!apt-get update -y > /dev/null && apt-get install -y patch > /dev/null\n",
    "!pip -q install pytest gradio openai_agents tensorflow==2.15 --extra-index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "GNU patch is required to apply diffs. The install step above ensures it is available."
  },
  {
   "cell_type": "markdown",
   "id": "ec99722d",
   "metadata": {},
   "source": [
    "## 2 · (Optional) Add your OpenAI API key for GPT‑4o reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e73217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = ''  # paste API key or leave blank for offline\n",
    "os.environ['USE_LOCAL_LLM'] = 'true'  # set false to use OpenAI if key present\n",
    "os.environ['OLLAMA_BASE_URL'] = 'http://localhost:11434/v1'\n",
    "os.environ['OPENAI_MODEL'] = 'gpt-4o-mini'\n",
    "os.environ['CLONE_DIR'] = '/tmp/demo_repo'  # optional clone location\n",
    "os.environ['WHEELHOUSE'] = '/content/wheels'  # path to wheel cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offline_wheelhouse",
   "metadata": {},
   "source": [
    "### 2b · Offline wheelhouse setup",
    "",
    "Upload a prebuilt wheelhouse to this runtime and set `WHEELHOUSE` so `check_env.py` installs from the cache. Combine with `USE_LOCAL_LLM` and `OLLAMA_BASE_URL` to run completely offline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_check_env",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../../../check_env.py --auto-install --wheelhouse $WHEELHOUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GRADIO_SHARE'] = '1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f21232b",
   "metadata": {},
   "source": [
    "## 3 · Launch dashboard (public link will appear below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13b7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python agent_selfheal_entrypoint.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4566d7",
   "metadata": {},
   "source": [
    "When the cell prints the Gradio public URL, click it to open the interactive UI.\n",
    "\n",
    "*Try pressing **Heal Repository** to watch the agent patch the bug and rerun tests.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
