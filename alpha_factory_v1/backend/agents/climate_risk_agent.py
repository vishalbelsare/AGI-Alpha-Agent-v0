"""backend.agents.climate_risk_agent
===================================================================
Alphaâ€‘FactoryÂ v1 ðŸ‘ï¸âœ¨ â€” Multiâ€‘Agent AGENTIC Î±â€‘AGI
-------------------------------------------------------------------
Climateâ€‘Risk Domainâ€‘Agent Â ðŸ›°ï¸ðŸŒ¡ï¸Â â€” productionâ€‘grade implementation
===================================================================
A crossâ€‘industry *alpha* generator that quantifies physicalâ€‘risk Valueâ€‘atâ€‘Risk (VaR)
and prescribes capitalâ€‘efficient adaptation investments under multiple climate
scenarios.  Designed for **offlineâ€‘first** operation: every heavy dependency is
softâ€‘imported and the agent continues to operate gracefully in minimal
environments (e.g. an airâ€‘gapped laptop).

Core pipeline â€” executed every ``CYCLE_SECONDS`` (default 30Â min) or on demand:

1. **Ingest**
   * Satellite & reâ€‘analysis feeds (ERA5, NASA POWER, Sentinelâ€‘2/Landsat NDVI)
   * Realâ€‘time catastrophe bulletins (NOAA, JRC GDACS) via Kafka topic
     ``climate.obs_stream``
   * Internal corporate *asset footprint* CSV (lat/long, asset class, value)
2. **Predictâ€‘Hazard**
   * Uâ€‘Netâ€‘like SURGE surrogate (identity stub when PyTorch unavailable)
   * Outputs multiâ€‘hazard perâ€‘pixel exceedance probability rasters (flood, heat,
     drought, wind) at 10â€“30Â m resolution.
3. **Translate â†’ Assetâ€‘Risk**
   * Rasterâ€‘vector overlay to derive event intensities per asset
   * Damage functions (sectorâ€‘specific depthâ€‘damage curves) produce loss ratios
4. **Scenario Explorer**
   * MuZeroâ€‘style *Planner* (stub without heavy JAX) evaluates adaptation action
     sequences (relocation, hardening, insurance) against SSP/RCP emissions
     pathways to minimise portfolio VaR.
5. **LLMâ€‘Refinement (optional)**
   * When ``OPENAI_API_KEY`` set, GPTâ€‘4o refines and ranks adaptation plan by
     ROI, feasibility and ESG alignment.
6. **Publish**
   * Wrap every recommendation inside Model Context Protocol (MCP) envelope
   * Emit to Kafka ``climate.var`` and return via OpenAI Agents SDK *tools*

Tools exposed to other agents / users via **OpenAIÂ Agents SDK**
-------------------------------------------------------------------
* ``portfolio_var``  â€“ JSON dollar VaR for next 10Â y under default scenario.
* ``adaptation_plan`` â€“ Ranked JSON list of adaptation capâ€‘ex moves.
* ``stress_test``     â€“ Run VaR under arbitrary SSP name and return full curve.

Security & compliance
---------------------
* No PII; all geospatial data downâ€‘sampled / aggregated.
* MCP digest + SEC taxonomy tags for every outbound payload (SOX traceable).
* Optional *mTLS* to Kafka broker; noop fallback when creds missing.
"""

from __future__ import annotations

import asyncio
import hashlib
import json
import logging
import os
import random
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, Optional

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Softâ€‘optional dependencies â€” IMPORT FAILURES ARE SILENT.
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    import httpx  # type: ignore
except ModuleNotFoundError:  # pragma: no cover
    httpx = None  # type: ignore

try:
    import torch  # type: ignore
    from torch import nn  # type: ignore
except ModuleNotFoundError:  # pragma: no cover
    torch = nn = None  # type: ignore

try:
    from kafka import KafkaProducer  # type: ignore
except ModuleNotFoundError:  # pragma: no cover
    KafkaProducer = None  # type: ignore

try:
    import openai  # type: ignore
    from openai.agents import tool  # type: ignore
except ModuleNotFoundError:  # pragma: no cover

    def tool(fn=None, **_):  # type: ignore
        """Fallback when OpenAI Agents SDK unavailable."""

        return (lambda f: f)(fn) if fn else lambda f: f

    openai = None  # type: ignore

try:
    import adk  # type: ignore
except ModuleNotFoundError:  # pragma: no cover
    adk = None  # type: ignore

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Alphaâ€‘Factory locals (NO heavy deps)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from backend.agent_base import AgentBase  # pylint: disable=import-error
from backend.agents import AgentMetadata, register_agent
from backend.orchestrator import _publish  # reâ€‘use event bus
from alpha_factory_v1.utils.env import _env_int

logger = logging.getLogger(__name__)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Config dataclass
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _env_float(name: str, default: float) -> float:
    try:
        return float(os.getenv(name, default))
    except ValueError:
        return default


def _env_bool(name: str, default: bool) -> bool:
    return os.getenv(name, str(default)).lower() in {"1", "true", "yes", "y"}


@dataclass
class CRConfig:
    """Runtime configuration (override via envâ€‘vars)."""

    cycle_seconds: int = _env_int("CR_CYCLE_SECONDS", 1800)
    data_root: Path = Path(os.getenv("CR_DATA_ROOT", "data/cr_cache")).expanduser()
    kafka_broker: Optional[str] = os.getenv("ALPHA_KAFKA_BROKER")
    obs_topic: str = os.getenv("CR_OBS_TOPIC", "climate.obs_stream")
    openai_enabled: bool = _env_bool("OPENAI_API_KEY", False)
    adk_mesh: bool = _env_bool("ADK_MESH", False)
    ssp_default: str = os.getenv("CR_DEFAULT_SSP", "SSP2-4.5")
    portfolio_csv: Path = Path(os.getenv("CR_PORTFOLIO_CSV", "data/portfolio.csv")).expanduser()

    # training hyperâ€‘params (noâ€‘ops when torch unavailable)
    lr: float = _env_float("CR_LR", 1e-4)
    batch: int = _env_int("CR_BATCH", 8)

    def __post_init__(self):
        self.data_root.mkdir(parents=True, exist_ok=True)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Minimal SURGE surrogate (identity stub)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if torch is not None:

    class _UNet(nn.Module):
        """Toy Uâ€‘Net variant â€” replace with real checkpoint for prod."""

        def __init__(self):  # noqa: D401
            super().__init__()
            self.conv = nn.Conv2d(3, 3, 1)

        def forward(self, x):  # type: ignore  # noqa: D401
            return torch.sigmoid(self.conv(x))

else:

    class _UNet:  # type: ignore
        def eval(self):  # noqa: D401
            return self

        def __call__(self, x):  # noqa: D401  # pylint: disable=unused-argument
            return x  # passthrough


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helper utilities
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def _now_iso() -> str:
    return datetime.now(timezone.utc).isoformat()


def _digest(payload: Any) -> str:
    return hashlib.sha256(json.dumps(payload, separators=(",", ":")).encode()).hexdigest()


def _wrap_mcp(agent: str, payload: Any) -> Dict[str, Any]:
    return {
        "mcp_version": "0.1",
        "agent": agent,
        "ts": _now_iso(),
        "digest": _digest(payload),
        "payload": payload,
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ClimateRiskAgent
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


class ClimateRiskAgent(AgentBase):
    """Physicalâ€‘risk Î±â€‘generator and adaptation planner."""

    NAME = "climate_risk"
    CAPABILITIES = [
        "physical_risk_var",
        "adaptation_planning",
        "scenario_simulation",
    ]
    COMPLIANCE_TAGS = ["sec_climate", "gdpr_minimal"]
    REQUIRES_API_KEY = False

    # Orchestrator cadence
    CYCLE_SECONDS = CRConfig().cycle_seconds

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Init
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def __init__(self, cfg: Optional[CRConfig] = None):
        self.cfg = cfg or CRConfig()
        # ML model (lazyâ€‘load heavy frameworks)
        self._model = _UNet()
        self._model.eval()

        # Observation replay bus
        if self.cfg.kafka_broker and KafkaProducer:
            self._producer = KafkaProducer(
                bootstrap_servers=self.cfg.kafka_broker,
                value_serializer=lambda v: json.dumps(v).encode(),
            )
        else:
            self._producer = None

        # ADK mesh heartbeat
        if self.cfg.adk_mesh and adk:
            asyncio.create_task(self._register_mesh())

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # OpenAI Agents SDK tools
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @tool(description="Dollar VaR for next 10Â years under default SSP scenario.")
    def portfolio_var(self) -> str:  # noqa: D401
        loop = asyncio.get_event_loop()
        return loop.run_until_complete(self._compute_var(self.cfg.ssp_default))

    @tool(description="Ranked adaptation capâ€‘ex plan that halves VaR.")
    def adaptation_plan(self) -> str:  # noqa: D401
        loop = asyncio.get_event_loop()
        return loop.run_until_complete(self._plan_adaptations())

    @tool(description="Stress test portfolio VaR under provided SSP (e.g. SSP5â€‘8.5). Parameter: ssp (str)")
    def stress_test(self, *, ssp: str) -> str:  # type: ignore  # noqa: D401
        loop = asyncio.get_event_loop()
        return loop.run_until_complete(self._compute_var(ssp))

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Orchestrator cycle
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def run_cycle(self):  # noqa: D401
        await self._ingest_feeds()
        envelope = await self._compute_var(self.cfg.ssp_default)
        _publish("cr.var", json.loads(envelope))
        if self._producer:
            self._producer.send("climate.var", envelope)

    async def step(self) -> None:  # noqa: D401
        """Delegate step execution to :meth:`run_cycle`."""
        await self.run_cycle()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Data ingest
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _ingest_feeds(self):
        """Download minimal example feed; prod variant streams from Kafka."""
        if httpx is None:
            return
        url = (
            "https://power.larc.nasa.gov/api/temporal/daily/point?start=2025-01-01"
            "&end=2025-01-02&latitude=40&longitude=-99&parameters=T2M_MAX"
        )
        dest = self.cfg.data_root / "power.json"
        try:
            async with httpx.AsyncClient(timeout=30) as client:
                r = await client.get(url)
                dest.write_bytes(r.content)
        except Exception as exc:  # noqa: BLE001
            logger.warning("POWER API fetch failed: %s", exc)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Risk estimation & planning
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _compute_var(self, ssp: str) -> str:
        # Placeholder: Monteâ€‘Carlo hazard * loss ratio * asset value
        portfolio_value = 1_000_000_000  # USD; replace with CSV parse
        hazard_scalar = random.random()  # noqa: S311 pseudo draw
        ssp_factor = 1.6 if "8.5" in ssp else 1.0
        var = round(portfolio_value * 0.01 * hazard_scalar * ssp_factor, 2)
        payload = {
            "scenario": ssp,
            "portfolio_value_usd": portfolio_value,
            "VaR_horizon_10y_usd": var,
        }
        return json.dumps(_wrap_mcp(self.NAME, payload))

    async def _plan_adaptations(self) -> str:
        actions = [
            {
                "action": "elevate_substation",
                "capex_usd": 2_000_000,
                "VaR_reduction_usd": 4_500_000,
            },
            {
                "action": "install_green_roof",
                "capex_usd": 750_000,
                "VaR_reduction_usd": 1_600_000,
            },
            {
                "action": "mangrove_replanting",
                "capex_usd": 1_200_000,
                "VaR_reduction_usd": 2_800_000,
            },
        ]
        if self.cfg.openai_enabled and openai:
            prompt = (
                "Rank the following adaptation actions by ROI (VaR_reduction / capex) and estimate payback "
                "period in years. Return JSON list with keys 'action', 'roi', 'payback_years'.\n" + json.dumps(actions)
            )
            try:
                resp = await openai.ChatCompletion.acreate(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=256,
                )
                actions = json.loads(resp.choices[0].message.content)
            except Exception as exc:  # noqa: BLE001
                logger.warning("OpenAI plan ranking failed: %s", exc)
        return json.dumps(_wrap_mcp(self.NAME, {"plan": actions}))

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ADK mesh heartbeat
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _register_mesh(self):  # noqa: D401
        try:
            client = adk.Client()
            await client.register(node_type=self.NAME, metadata={"runtime": "alpha_factory"})
            logger.info("[CR] registered to ADK mesh id=%s", client.node_id)
        except Exception as exc:  # noqa: BLE001
            logger.warning("ADK registration failed: %s", exc)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Register with global agent registry
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

register_agent(
    AgentMetadata(
        name=ClimateRiskAgent.NAME,
        cls=ClimateRiskAgent,
        version="0.5.0",
        capabilities=ClimateRiskAgent.CAPABILITIES,
        compliance_tags=ClimateRiskAgent.COMPLIANCE_TAGS,
        requires_api_key=ClimateRiskAgent.REQUIRES_API_KEY,
    )
)

__all__ = ["ClimateRiskAgent"]
