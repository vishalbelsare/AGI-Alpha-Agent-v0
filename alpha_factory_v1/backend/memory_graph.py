"""
alpha_factory_v1.backend.memory_graph
=====================================

ðŸ•¸ï¸  *Causal-Graph Memory Fabric* â€“ durable, observable, failure-proof
---------------------------------------------------------------------
Primary store   : **Neo4j**           (ACID, highly-connected, Cypher)  
Fallback store  : **NetworkX in-RAM** (zero-dep, ultra-portable)  
Last-resort     : **Minimal stub**    (guaranteed uptime, any Python)

Why youâ€™ll â¤ï¸ it
----------------
1. **Graceful degradation.**  Runs *anywhere* â€“ cloud, edge ARM, air-gapped lab â€“
   even if Neo4j or NetworkX arenâ€™t installed.
2. **Observability first.**  Prometheus counters, gauges & latency histogram
   are built-in; dashboards light up automatically.
3. **Thread-safe & async-friendly.**  A global re-entrant lock serialises writes
   while allowing concurrent reads â€“ perfect for multi-agent concurrency.
4. **Developer delight.**  A single, elegant API (`add`, `batch_add`, `query`,
   `find_path`, `neighbours`, `export_graphml`, `import_graphml`) hides all
   backend quirks so agent authors stay focused on domain logic.
5. **No hard crashes â€“ ever.**  All optional libs are soft-imported, connection
   retries use exponential back-off, and every public call is exception-tamed.

Quick-start
-----------
>>> from alpha_factory_v1.backend.memory_graph import GraphMemory
>>> g = GraphMemory()                                     # auto-connects if env set
>>> g.add("EnergySpike", "CAUSES", "PriceJump", {"delta_alpha": 1_200_000})
>>> print(g.find_path("EnergySpike", "PriceJump"))
['EnergySpike', 'PriceJump']

CLI smoke-test (works off-grid):
$ python -m alpha_factory_v1.backend.memory_graph --verbose
"""
from __future__ import annotations

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ stdlib & typing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import json
import logging
import os
import pathlib
import random
import threading
import time
from contextlib import contextmanager
from typing import Any, Dict, Iterable, List, Optional, Sequence, Tuple

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ optional third-party imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    from neo4j import GraphDatabase, basic_auth  # type: ignore
    _HAS_NEO = True
except Exception:  # pragma: no cover
    _HAS_NEO = False

try:
    import networkx as nx  # type: ignore
    _HAS_NX = True
except Exception:  # pragma: no cover
    _HAS_NX = False

try:
    from prometheus_client import Counter, Gauge, Histogram  # type: ignore
    _PM = True
except Exception:  # pragma: no cover
    _PM = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ logging setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_log = logging.getLogger("alpha_factory.memory_graph")
if not _log.handlers:
    _hdl = logging.StreamHandler()
    _hdl.setFormatter(logging.Formatter("%(asctime)s %(levelname)s  %(message)s"))
    _log.addHandler(_hdl)
_log.setLevel(os.getenv("LOGLEVEL", "INFO"))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Prometheus metrics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if _PM:
    _MET_REL_ADD = Counter("af_graph_rel_add_total", "Relations inserted")
    _MET_NODE_UPS = Counter("af_graph_node_upsert_total", "Nodes upserted")
    _MET_QRY_CNT  = Counter("af_graph_query_total", "Queries executed")
    _MET_QRY_LAT  = Histogram("af_graph_query_seconds", "Query latency (s)")
    _MET_NODE_G   = Gauge("af_graph_nodes", "Node count")
    _MET_EDGE_G   = Gauge("af_graph_edges", "Edge count")
else:  # pragma: no cover
    class _No:                       # pylint: disable=too-few-public-methods
        def __getattr__(self, *_a):   # type: ignore
            return lambda *a, **k: None
    _MET_REL_ADD = _MET_NODE_UPS = _MET_QRY_CNT = _MET_QRY_LAT = _MET_NODE_G = _MET_EDGE_G = _No()  # type: ignore

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ global state â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_LOCK   = threading.RLock()
_JITTER = random.Random(42)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• helper utilities â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def _sleep_backoff(attempt: int) -> None:
    time.sleep(min(2 ** attempt, 8) * 0.05 + _JITTER.random() * 0.03)


@contextmanager
def _neo_session(driver, database: str):
    """Neo4j session with 3-retry exponential back-off."""
    for attempt in range(3):
        try:
            with driver.session(database=database) as sess:
                yield sess
                return
        except Exception as exc:                       # pragma: no cover
            _log.warning("Neo4j error (%s) â€“ retry %d/3", exc, attempt + 1)
            _sleep_backoff(attempt)
    raise RuntimeError("Neo4j unreachable after 3 attempts")


def _to_int(val: Any, default: int = 0) -> int:        # noqa: D401
    try:
        return int(val)
    except Exception:
        return default


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• GraphMemory class â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class GraphMemory:
    """
    Unified causal-graph memory layer.

    Parameters
    ----------
    uri / user / password :
        Explicit Neo4j credentials. If **any** are missing *or* the neo4j driver
        is absent, the class silently falls back to an in-memory graph.
    database :
        Neo4j DB name (default ``neo4j``).
    """

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ init â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def __init__(
        self,
        uri: Optional[str] = None,
        user: Optional[str] = None,
        password: Optional[str] = None,
        *,
        database: str | None = None,
    ) -> None:
        uri      = uri      or os.getenv("NEO4J_URI")
        user     = user     or os.getenv("NEO4J_USER")
        password = password or os.getenv("NEO4J_PASS")
        self._db = database or os.getenv("NEO4J_DATABASE", "neo4j")

        self._driver = None
        self._g      = None   # in-memory graph (NetworkX or stub)

        # Try Neo4j first
        if _HAS_NEO and uri and user and password:
            try:
                self._driver = GraphDatabase.driver(
                    uri,
                    auth=basic_auth(user, password),
                    max_connection_pool_size=16,
                )
                self._ensure_schema()
                _log.info("GraphMemory connected to Neo4j @ %s", uri)
            except Exception as exc:                   # pragma: no cover
                _log.warning("Neo4j connect failed (%s), falling back", exc)
                self._driver = None

        # Fallback : NetworkX
        if self._driver is None:
            if _HAS_NX:
                self._g = nx.MultiDiGraph()
            else:
                # Minimal always-available stub
                class _Stub:                           # pylint: disable=too-few-public-methods
                    nodes: set[str] = set()
                    edges: list[tuple[str, str, str, dict[str, Any]]] = []

                    def add_node(self, n):             # noqa: D401
                        self.nodes.add(n)

                    def add_edge(self, u, v, key=None, **d):
                        self.edges.append((u, v, key, d))

                    def number_of_nodes(self):
                        return len(self.nodes)

                    def number_of_edges(self):
                        return len(self.edges)

                    def out_edges(self, n, keys=True, data=True):
                        return [(u, v, k, d) for u, v, k, d in self.edges if u == n]

                    def successors(self, n):
                        return [v for u, v, *_ in self.edges if u == n]

                self._g = _Stub()      # type: ignore
            _log.warning("GraphMemory using *in-memory* backend â€“ data not persisted")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ public API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def add(
        self,
        src: str,
        rel: str,
        dst: str,
        props: Optional[Dict[str, Any]] = None,
    ) -> None:
        """
        Insert (or merge) a **directed** relation ``src -[rel]-> dst``.

        Notes
        -----
        * ``src`` & ``dst`` nodes are auto-created if absent.
        * ``props`` (dict) may store arbitrary JSON-serialisable metadata
          (e.g. ``{"delta_alpha": 42, "agent": "Finance"}``).
        """
        props = props or {}
        with _LOCK:
            self._upsert_node(src)
            self._upsert_node(dst)
            if self._driver:                               # Neo4j path
                cy = (
                    "MATCH (a:Entity {name:$src}), (b:Entity {name:$dst}) "
                    f"MERGE (a)-[r:{rel}]->(b) "
                    "SET r += $props"
                )
                with _neo_session(self._driver, self._db) as s:
                    s.run(cy, src=src, dst=dst, props=props)
                self._refresh_gauges()
            else:                                          # NX / stub
                self._g.add_edge(src, dst, key=rel, **props)  # type: ignore[arg-type]
                self._refresh_gauges_nx()
        _MET_REL_ADD.inc()

    # ------------------------------------------------------------------
    def batch_add(
        self,
        triples: Iterable[Tuple[str, str, str]],
        default_props: Optional[Dict[str, Any]] = None,
    ) -> None:
        """
        Bulk-insert many ``(src, rel, dst)`` triples **efficiently**.

        All triples share ``default_props`` â€“ handy for timestamping events.
        """
        default_props = default_props or {}
        triples = list(triples)          # may be generator
        if not triples:
            return
        with _LOCK:
            if self._driver:
                # group by rel to avoid dynamic rel-type in UNWIND
                buckets: Dict[str, List[Tuple[str, str, str]]] = {}
                for s, r, d in triples:
                    buckets.setdefault(r, []).append((s, r, d))
                with _neo_session(self._driver, self._db) as sess:
                    for rel, rows in buckets.items():
                        cy = (
                            "UNWIND $rows AS row "
                            "MERGE (a:Entity {name:row[0]}) "
                            "MERGE (b:Entity {name:row[2]}) "
                            f"MERGE (a)-[r:{rel}]->(b) "
                            "SET r += $props"
                        )
                        sess.run(cy, rows=[list(t) for t in rows], props=default_props)
                self._refresh_gauges()
            else:
                for s, r, d in triples:
                    self._g.add_edge(s, d, key=r, **default_props)  # type: ignore[arg-type]
                self._refresh_gauges_nx()
        _MET_REL_ADD.inc(len(triples))

    # ------------------------------------------------------------------
    @_MET_QRY_LAT.time()  # type: ignore[arg-type]
    def query(self, cypher: str, **params: Any) -> List[Tuple[Any, ...]]:
        """Run raw **Cypher** â€“ or fallback heuristic filter if offline."""
        _MET_QRY_CNT.inc()
        if self._driver:
            with _neo_session(self._driver, self._db) as s:
                recs = s.run(cypher, **params)
                return [tuple(r.values()) for r in recs]
        # â†“ ultra-primitive fallback â€“ recognises a couple patterns
        return self._fallback_query(cypher)

    # ------------------------------------------------------------------
    def find_path(self, src: str, dst: str, max_depth: int = 4) -> List[str]:
        """Shortest node-name path ``src â†’ dst`` (â‰¤ *max_depth*)."""
        if self._driver:
            cy = (
                f"MATCH p=shortestPath((a:Entity {{name:$s}})-[*..{max_depth}]->"
                "(b:Entity {name:$d})) RETURN [n IN nodes(p) | n.name] LIMIT 1"
            )
            res = self.query(cy, s=src, d=dst)
            return res[0][0] if res else []
        if _HAS_NX and hasattr(self._g, "shortest_path"):  # type: ignore[attr-defined]
            try:
                return nx.shortest_path(self._g, src, dst)  # type: ignore[arg-type]
            except Exception:
                return []
        return []

    # ------------------------------------------------------------------
    def neighbours(self, node: str, *, rel: str | None = None) -> List[str]:
        """Outgoing neighbours (optionally filter by relation)."""
        if self._driver:
            if rel:
                cy = f"MATCH (:Entity {{name:$n}})-[:{rel}]->(m) RETURN m.name"
            else:
                cy = "MATCH (:Entity {name:$n})-->(m) RETURN DISTINCT m.name"
            return [r[0] for r in self.query(cy, n=node)]
        # NX / stub
        if rel:
            return [
                v for _, v, k, _ in self._g.out_edges(node, keys=True, data=True)  # type: ignore[attr-defined]
                if k == rel
            ]
        return list(self._g.successors(node))  # type: ignore[attr-defined]

    # ------------------------------------------------------------------
    def export_graphml(self, path: str | pathlib.Path) -> None:
        """Save **GraphML** snapshot â€“ works in all backends."""
        p = pathlib.Path(path)
        if self._driver and _HAS_NX:
            g_tmp = nx.MultiDiGraph()  # type: ignore[arg-type]
            for n, in self.query("MATCH (n) RETURN n.name"):
                g_tmp.add_node(n)
            for s, r, d in self.query("MATCH (a)-[r]->(b) RETURN a.name,r,b.name"):
                g_tmp.add_edge(s, d, key=r)
            nx.write_graphml(g_tmp, p)
        elif _HAS_NX:
            nx.write_graphml(self._g, p)  # type: ignore[arg-type]
        else:
            raise RuntimeError("GraphML export requires NetworkX")
        _log.info("Graph exported â†’ %s", p)

    def import_graphml(self, path: str | pathlib.Path) -> None:
        """Load GraphML into current graph (additive)."""
        if not _HAS_NX:
            raise RuntimeError("GraphML import requires NetworkX installed")
        g_in = nx.read_graphml(pathlib.Path(path))  # type: ignore[arg-type]
        triples = [(u, d["key"], v) for u, v, d in g_in.edges(data=True)]
        self.batch_add(triples)
        _log.info("Graph imported from %s (%d triples)", path, len(triples))

    # ------------------------------------------------------------------
    def __len__(self) -> int:
        if self._driver:
            return _to_int(self.query("MATCH ()-[r]->() RETURN count(r)")[0][0])
        return self._g.number_of_edges()  # type: ignore[attr-defined]

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• internal helpers (private) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def _upsert_node(self, name: str) -> None:
        _MET_NODE_UPS.inc()
        if self._driver:
            with _neo_session(self._driver, self._db) as s:
                s.run("MERGE (:Entity {name:$n})", n=name)
        else:
            self._g.add_node(name)  # type: ignore[attr-defined]

    def _ensure_schema(self) -> None:
        with _neo_session(self._driver, self._db) as s:
            s.run("CREATE CONSTRAINT IF NOT EXISTS "
                  "FOR (e:Entity) REQUIRE e.name IS UNIQUE")

    def _refresh_gauges(self) -> None:
        n = _to_int(self.query("MATCH (n) RETURN count(n)")[0][0])
        e = _to_int(self.query("MATCH ()-[r]->() RETURN count(r)")[0][0])
        _MET_NODE_G.set(n)
        _MET_EDGE_G.set(e)

    def _refresh_gauges_nx(self) -> None:
        _MET_NODE_G.set(self._g.number_of_nodes())  # type: ignore[attr-defined]
        _MET_EDGE_G.set(self._g.number_of_edges())  # type: ignore[attr-defined]

    # crude pattern-based filter for offline mode
    def _fallback_query(self, cypher: str) -> List[Tuple[Any, ...]]:
        if "delta_alpha" in cypher and ">" in cypher:
            try:
                thresh = float(cypher.split(">")[-1].split()[0])
            except Exception:
                return []
            return [                        # type: ignore
                (u, v, d)
                for u, v, k, d in self._g.edges(data=True, keys=True)  # type: ignore[attr-defined]
                if d.get("delta_alpha", 0) > thresh
            ]
        # default fallback â€“ dump all edges
        return [tuple(e[:3]) for e in self._g.edges(keys=True)]  # type: ignore[attr-defined]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• CLI entry-point â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if __name__ == "__main__":                                    # pragma: no cover
    import argparse
    from pprint import pprint

    ap = argparse.ArgumentParser("graph-memory smoke-test")
    ap.add_argument("--verbose", action="store_true", help="chatty logging")
    ns = ap.parse_args()
    if ns.verbose:
        _log.setLevel(logging.DEBUG)

    g = GraphMemory()
    g.add("AlphaEvent", "CAUSES", "BetaOutcome", {"delta_alpha": 42})
    pprint(g.query("MATCH (a)-[r]->(b) RETURN a.name,r,b.name LIMIT 5"))
    print("Shortest path:", g.find_path("AlphaEvent", "BetaOutcome"))
    print("Graph size:", len(g))
